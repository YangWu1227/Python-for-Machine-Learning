{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4db3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89320fe",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "\n",
    "Here we will build up some of the basic approaches for convolution, from a simple all-for-loop algorithm to an algorithm that uses a single matrix multiplication plus resize operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434d275",
   "metadata": {},
   "source": [
    "### Storage Order Images\n",
    "\n",
    "In the simple fully-connected networks, hidden units are typically simply represented as vectors, i.e., a quantity $z \\in \\mathbb{R}^n$, or when representing an entire minibatch, a matrix $Z \\in \\mathbb{R}^{B \\times n}$.  But when we move to convolutional networks, we need to include additional structure in the hidden unit.  This is typically done by representing each hidden vector as a 3D array, with dimensions `height x width x channels`, or in the minibatch case, with an additional batch dimension.  That is, we could represent a hidden unit as an array:\n",
    "\n",
    "```c++\n",
    "float Z[BATCHES][HEIGHT][WIDTH][CHANNELS];\n",
    "```\n",
    "\n",
    "The format above is referred to as **NHWC format** (number(batch)-height-width-channel).  However, there are other ways we can represent the hidden unit as well.  For example, PyTorch defaults to the **NCHW format** (indexing over channels in the second dimension, then height and width), though it can also support **NHWC** in later versions.  There are subtle but substantial differences in the performance for each different setting: convolutions are typically faster in NHWC format, owing to their ability to better exploit tensor cores; but NCHW format is typically faster for BatchNorm operation (because batch norm for convolutional networks operates over all pixels in an individual channel).\n",
    "\n",
    "### Storage Order Kernels\n",
    "\n",
    "Although less commonly discussed, there is a similar trade-off to be had when it comes to storing the convolutional weights (filter) as well.  Convolutional filters are specified by their kernel size (which can technically be different over different height and width dimensions, but this is quite uncommon), their input channels, and their output channels.  We'll store these weights in the form:\n",
    "\n",
    "```c++\n",
    "float weights[KERNEL_SIZE][KERNEL_SIZE][IN_CHANNELS][OUT_CHANNELS];\n",
    "```\n",
    "\n",
    "Again, PyTorch does things a bit differently here (for no good reason, it was just done that way historically), storing weight in the order `OUT_CHANNELS x IN_CHANNELS x KERNELS_SIZE x KERNEL_SIZE`.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72704412",
   "metadata": {},
   "source": [
    "## Convolutions with Simple Loops\n",
    "\n",
    "Let's begin by implementing a simple convolutional operator.  We're going to implement a simple version, which allows for different kernel sizes but which *doesn't* have any built-in padding: to implement padding, you'd just explicitly form a new `ndarray` with the padding built in. This means that if we have an $H \\times W$ input image and convolution with kernel size $K$, we'll end up with a $(H - K + 1) \\times (W - K + 1)$ image.\n",
    "\n",
    "We use PyTorch as a reference implementation of convolution that we will check against. However, since PyTorch, as mentioned above, uses the **NCHW format** (and stores the convolutional weights in a different ordering as well), and we'll use the **NHWC format** and the weights ordering stated above, we will need to swap things around for our reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bb47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_reference(Z: np.ndarray, weight: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reference implementation of convolution operation using PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : np.ndarray\n",
    "        The input to the convolutional layer.\n",
    "    weight : np.ndarray\n",
    "        The weights of the convolutional layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The output of the convolutional layer.\n",
    "    \"\"\"\n",
    "    # Convert NHWC to NCHW for PyTorch, returning a view of the original tensor input with its dimensions permuted\n",
    "    z_torch = torch.tensor(Z).permute(0, 3, 1, 2)\n",
    "\n",
    "    # Convert KKIO to OIKK where K is the kernel size, O is the number of output channels, and I is the number of input channels\n",
    "    weight_torch = torch.tensor(weight).permute(3, 2, 0, 1)\n",
    "\n",
    "    out = nn.functional.conv2d(z_torch, weight_torch, stride=1, padding=0)\n",
    "\n",
    "    # Convert back to NHWC, returning a contiguous in memory tensor containing the same data as self tensor\n",
    "    return out.permute(0, 2, 3, 1).contiguous().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede64bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30, 30, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch of 10 images of size 32 x 32 with 8 channels\n",
    "Z = np.random.randn(10, 32, 32, 8)\n",
    "# Kernel size of 3 x 3 with 8 input channels and 16 output channels\n",
    "W = np.random.randn(3, 3, 8, 16)\n",
    "\n",
    "out = conv_reference(Z, W)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356903e6",
   "metadata": {},
   "source": [
    "- The input is a batch of 10 images, each of which is $32 \\times 32$ pixels with 8 channels.\n",
    "  \n",
    "- The kernel is a $3 \\times 3$ matrix with 8 input channels and 16 output channels.\n",
    "  \n",
    "- The stride is assumed to be 1 (which is a common default), meaning the kernel moves 1 pixel at a time.\n",
    "  \n",
    "- The padding is assumed to be 0 , meaning no additional pixels are added to the border of the image.\n",
    "  \n",
    "Given these parameters, the dimensions of the output can be calculated as follows:\n",
    "\n",
    "1. Height and Width: Since the kernel is $3 \\times 3$ and the stride is 1 , the kernel can slide $((I - F) / 1) + 1=(32-3+1)$ $=30$ positions along both the width and the height, resulting in an output size of $30 \\times 30$. This reduction in size is because the kernel cannot slide over the full image without going out of the image boundaries (unless padding is used).\n",
    "   \n",
    "2. Depth: The depth of the output is determined by the number of output channels in the kernel, which is 16 in this case.\n",
    "   \n",
    "3. Batch Size: The batch size remains the same, so the output includes results for all 10 input images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac177dd",
   "metadata": {},
   "source": [
    "Simplest possible implementation of a convolution using for loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42551005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_naive(Z: np.ndarray, weight: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Naive implementation of convolution operation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : np.ndarray\n",
    "        The input to the convolutional layer.\n",
    "    weight : np.ndarray\n",
    "        The weights of the convolutional layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The output of the convolutional layer.\n",
    "    \"\"\"\n",
    "    # Shapes of input and weight\n",
    "    N, H, W, C_in = Z.shape\n",
    "    K, _, _, C_out = weight.shape\n",
    "\n",
    "    # Initialize output\n",
    "    out = np.zeros((N, H - K + 1, W - K + 1, C_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        for c_in in range(C_in):\n",
    "            for c_out in range(C_out):\n",
    "                # Loop over the height of the output feature map\n",
    "                for y in range(H - K + 1):\n",
    "                    # Loop over the width of the output feature map\n",
    "                    for x in range(W - K + 1):\n",
    "                        for i in range(K):\n",
    "                            for j in range(K):\n",
    "                                out[n, y, x, c_out] += (\n",
    "                                    Z[n, y + i, x + j, c_in] * weight[i, j, c_in, c_out]\n",
    "                                )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f5bf9",
   "metadata": {},
   "source": [
    "We can check to make sure this implementation works by comparing to the PyTorch reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f78a898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2281529924016432e-12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2 = conv_naive(Z, W)\n",
    "\n",
    "np.linalg.norm(out - out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f20587",
   "metadata": {},
   "source": [
    "The implementation works, but not surprisingly, the 7-fold loop in interpreted code is much slower than the PyTorch implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8242fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.4 s ± 1.47 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out_2 = conv_naive(Z, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0ec811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 ms ± 462 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = conv_reference(Z, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb297e2",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Convolutions as Matrix Multiplications\n",
    "\n",
    "Another way to implement convolution is to perform it as a sequence of matrix multiplications.  Remember that a kernel size $K = 1$ convolution is equivalent to performing matrix multiplication over the channel dimensions.  That is, suppose we have the following convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e2e745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A kernel size of 1 x 1 with 8 input channels and 16 output channels\n",
    "W_1 = np.random.randn(1, 1, 8, 16)\n",
    "out = conv_reference(Z, W_1)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95507425",
   "metadata": {},
   "source": [
    "Then we could implement the convolution using a _single_ matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75717085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8c2aa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.72678468389406e-15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W_1[0, 0] is a 8 x 16 matrix\n",
    "out_2 = Z @ W_1[0, 0]\n",
    "\n",
    "np.linalg.norm(out - out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfef70",
   "metadata": {},
   "source": [
    "We're here exploiting the nicety that in numpy, when you compute a matrix multiplication by a multi-dimensional array (a rank 4 tensor in $Z$), it will treat the leading dimensions of $Z$ all as rows of a matrix. That is, the above operation would be equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb755b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.72678468389406e-15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2 = (Z.reshape(-1, 8) @ W_1[0, 0]).reshape(\n",
    "    Z.shape[0], Z.shape[1], Z.shape[2], W_1.shape[3]\n",
    ")\n",
    "np.linalg.norm(out - out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f33c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have reshape Z from (10, 32, 32, 8) to (10240, 8) in order to perform a matrix multiplication of it with (8, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"We have reshape Z from {Z.shape} to {(Z.reshape(-1, 8)).shape} in order to perform a matrix multiplication of it with {W_1[0, 0].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4572a4",
   "metadata": {},
   "source": [
    "This strategy immediately motivates a very natural approach to convolution: we can iterate over just the kernel dimensions $i$ and $j$, and use matrix multiplication to perform the convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f057d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_matrix_mult(Z: np.ndarray, weight: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implementation of convolution operation using matrix multiplication.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : np.ndarray\n",
    "        The input to the convolutional layer.\n",
    "    weight : np.ndarray\n",
    "        The weights of the convolutional layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The output of the convolutional layer.\n",
    "    \"\"\"\n",
    "    # Shapes of input and weight\n",
    "    N, H, W, C_in = Z.shape\n",
    "    K, _, _, C_out = weight.shape\n",
    "\n",
    "    # Initialize output\n",
    "    out = np.zeros((N, H - K + 1, W - K + 1, C_out))\n",
    "\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            # Each weight[i, j] is a C_in x C_out matrix\n",
    "            out += Z[:, i : (i + H - K + 1), j : (j + W - K + 1), :] @ weight[i, j]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8748edf",
   "metadata": {},
   "source": [
    "The `[:, i:(i + H - K + 1), j:(j + W - K + 1), :]` line is where we are sliding the window over patches of the input $Z$ where\n",
    "\n",
    "* $H - K + 1$ is the height of the output feature map\n",
    "\n",
    "* $W - K + 1$ is the width of the output feature map\n",
    "\n",
    "**All assuming that stride equals 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26d0b31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.149296845152869e-12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A batch of 100 images of size 32 x 32 with 8 channels\n",
    "Z = np.random.randn(100, 32, 32, 8)\n",
    "# Kernel size of 3 x 3 with 8 input channels and 16 output channels\n",
    "W = np.random.randn(3, 3, 8, 16)\n",
    "\n",
    "out = conv_reference(Z, W)\n",
    "out_2 = conv_matrix_mult(Z, W)\n",
    "\n",
    "np.linalg.norm(out - out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45785e",
   "metadata": {},
   "source": [
    "This works as well, as (as expected) is _much_ faster, starting to be competitive even with the PyTorch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fa8aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.7 ms ± 14.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = conv_reference(Z, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02ee7f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.8 ms ± 7.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = conv_matrix_mult(Z, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b64d34",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Manipulating Matrices via Strides\n",
    "\n",
    "Before implementing convolutions via **im2col**, which is a technique to rearrange discrete image blocks of size m-by-n into columns, we consider an example that actually has nothing to do with convolution. Instead, we consider the efficient matrix multiplication operations where we think of storing a matrix as a 2D array:\n",
    "\n",
    "```c++\n",
    "float A[M][N];\n",
    "```\n",
    "\n",
    "In the typical **row-major format**, this will store each N-dimensional row vector of the matrix one after another in memory. However, recall that in order to make better use of the caches and vector operations in modern CPUs, it was beneficial to lay our our matrix memory groups by individual small \"tiles\", so that the CPU vector operations could efficiently access operators\n",
    "\n",
    "```c++\n",
    "float A[M/TILE][N/TILE][TILE][TILE];\n",
    "```    \n",
    "\n",
    "where `TILE` is some small constant (like 4), which allows the CPU to use its vector processor to perform very efficient operations on `TILE x TILE` blocks. Importantly, what enables this to be so efficient is that in the standard memory ordering for an ND array, this grouping would locate all `TILE x TILE` block consecutively in memory, so they could quickly be loaded in and out of cache / registers / etc.\n",
    "\n",
    "How exactly would we convert a matrix to this form? We can use the function `np.lib.stride_tricks.as_strided()`, which lets us create new matrices by manually manipulating the strides of a matrix while *not* changing the underlying data. We can then use `np.ascontiguousarray()` to lay out the memory sequentially. These sets of tricks let us rearrange matrices fairly efficiently in just one or two lines of `numpy` code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecde2d0",
   "metadata": {},
   "source": [
    "### An Example: A 6x6 2D Array\n",
    "\n",
    "To see how this works, let's consider an example 6x6 numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62e3c376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15., 16., 17.],\n",
       "       [18., 19., 20., 21., 22., 23.],\n",
       "       [24., 25., 26., 27., 28., 29.],\n",
       "       [30., 31., 32., 33., 34., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 6\n",
    "\n",
    "A = np.arange(n**2, dtype=np.float32).reshape(n, n)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce404302",
   "metadata": {},
   "source": [
    "#### Row-Major Format\n",
    "\n",
    "This array is layed out in memory by row.  It's actually a bit of a pain to access the underlying raw memory of a numpy array in Python (numpy goes to great lengths to try to *prevent* us from doing this, but we can see how the array is layed out using the following code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65f9ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35.], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "\n",
    "np.frombuffer(\n",
    "    ctypes.string_at(A.ctypes.data, size=A.nbytes), dtype=A.dtype, count=A.size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f748f9",
   "metadata": {},
   "source": [
    "* `numpy.ndarray.nbytes` is an attribute that shows the total bytes consumed by the elements of the array. Note that this does not include memory consumed by non-element attributes of the array object.\n",
    "\n",
    "* `_ctypes.data` is a pointer to the memory area of the array as a Python integer.\n",
    "\n",
    "* `ctypes.string_at(address, size=-1)` is a function that returns the C string starting at memory address `address` as a bytes object. If size is specified, it is used as `size``, otherwise the string is assumed to be zero-terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a3222",
   "metadata": {},
   "source": [
    "#### Strides\n",
    "\n",
    "The `strides` structure can be a way to lay out n-dimensional arrays in memory. In order to access the `A[i][j]` element of a 2D array, for instance, we would access the memory location at:\n",
    "\n",
    "```c++\n",
    "A.bytes[i * strides[0] + j * strides[1]];\n",
    "```\n",
    "    \n",
    "The same can be done e.g., with a 3D tensor, accessing `A[i][j][k]` at memory location:\n",
    "\n",
    "```c++\n",
    "A.bytes[i * strides[0] + j * strides[1] + k * strides[2]];\n",
    "```\n",
    "\n",
    "For an array in row-major format, we would thus have\n",
    "\n",
    "```c++\n",
    "strides[0] = num_cols;\n",
    "strides[1] = 1;\n",
    "```\n",
    "\n",
    "We can look at the strides of the array we have created using the `.strides` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d86b784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d0a63",
   "metadata": {},
   "source": [
    "Note that numpy, somewhat unconventionally, actually uses strides equal to the total number of *bytes*, so these numbers are all multiplied by 4 from the above, because a `float32` type takes up 4 bytes. The `strides` attribute returns a tuple of bytes to step in each dimension when traversing an array.\n",
    "\n",
    "For example, the byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n",
    "\n",
    "```python\n",
    "offset = sum(np.array(i) * a.strides)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc515547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "28\n",
      "56\n",
      "84\n",
      "112\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    print(np.sum(np.array(i) * A.strides))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c96203",
   "metadata": {},
   "source": [
    "The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but $6 \\times 4 = 24$ bytes (6 values) to get to the same position in the next row. As such, the strides for the array x will be `(24, 4)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ea6f3",
   "metadata": {},
   "source": [
    "### Tiling a Matrix using Strides\n",
    "\n",
    "For simplicity, assume we want to tile into $2 \\times 2$ blocks, and thus we want to convert `A`, which is $6 \\times 6$, into a `3 x 3 x 2 x 2` array.  What would the strides be in this case?  In other words, if we accessed the element `A[i][j][k][l]`, how would this index into a memory location in the array as layed out above?  \n",
    "\n",
    "1. Incrementing the first index, `i`, would move down *two* rows in the matrix with 6 rows since \n",
    "   \n",
    "   * each block of the tile is $2 \\times 2$ \n",
    "   * `tile = 2`, `num_rows = 6`, and `num_rows / tile = 3`\n",
    "\n",
    "   Therefore, incrementing the first index by 1 actually skips `strides[0] = 12` elements (two rows) \n",
    "\n",
    "2. Similarly, incrementing the second index `j` would move over two columns, so `strides[1] = 2` elements (two columns) in row-major format\n",
    "   \n",
    "3. Things get a bit tricker next, but are still fairly straightforward: incrementing the next index `k` (the height index within a tile) moves down one row in the tile matrix, so `strides[2] = 6` elements or 1 row, which is half of the amount bytes we have to skip for incrementing `i` \n",
    "   \n",
    "4. Finally incrementing the last index `l` just moves us over one column, so `strides[3] = 1` element\n",
    "\n",
    "The `np.lib.stride_tricks.as_strided()` function lets us specify the shape and stride of a new matrix, created from the same memory as the old matrix. That is, it doesn't do any memory copies, so it's very efficient. But we also have to be careful when we use it, since it is directly creating a new view of an existing array, and without proper care we could e.g., go outside the bounds of the array.\n",
    "\n",
    "To create the tiled view of the matrix `A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59dd9f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15., 16., 17.],\n",
       "       [18., 19., 20., 21., 22., 23.],\n",
       "       [24., 25., 26., 27., 28., 29.],\n",
       "       [30., 31., 32., 33., 34., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8eafcce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  1.],\n",
       "         [ 6.,  7.]],\n",
       "\n",
       "        [[ 2.,  3.],\n",
       "         [ 8.,  9.]],\n",
       "\n",
       "        [[ 4.,  5.],\n",
       "         [10., 11.]]],\n",
       "\n",
       "\n",
       "       [[[12., 13.],\n",
       "         [18., 19.]],\n",
       "\n",
       "        [[14., 15.],\n",
       "         [20., 21.]],\n",
       "\n",
       "        [[16., 17.],\n",
       "         [22., 23.]]],\n",
       "\n",
       "\n",
       "       [[[24., 25.],\n",
       "         [30., 31.]],\n",
       "\n",
       "        [[26., 27.],\n",
       "         [32., 33.]],\n",
       "\n",
       "        [[28., 29.],\n",
       "         [34., 35.]]]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note we need to multiple the strides by 4 since each element is a float32 which is 4 bytes\n",
    "B = np.lib.stride_tricks.as_strided(\n",
    "    A, shape=(3, 3, 2, 2), strides=np.array((12, 2, 6, 1)) * 4\n",
    ")\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d590f9d",
   "metadata": {},
   "source": [
    "Parsing numpy output for ND array isn't the most intuitive thing, but if we look closely then we can see that the array above basically lay out each 2x2 block of the matrix `A` as desired. However, we can also see that this call didn't change the actual memory layout by again inspecting the raw memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21a5f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(\n",
    "    np.frombuffer(ctypes.string_at(B.ctypes.data, size=B.nbytes), B.dtype, B.size),\n",
    "    np.frombuffer(ctypes.string_at(A.ctypes.data, size=A.nbytes), A.dtype, A.size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "213372de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 8, 24, 4)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.strides\n",
    "B.strides == tuple((12, 2, 6, 1) * np.array(np.dtype(np.float32).itemsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ccd26",
   "metadata": {},
   "source": [
    "In order to reorder the memory so that the underlying matrix is contiguous/compact (which is what we need for making the matrix multiplication efficient), we can use the `np.ascontinugousarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "02d505b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  6.,  7.,  2.,  3.,  8.,  9.,  4.,  5., 10., 11., 12.,\n",
       "       13., 18., 19., 14., 15., 20., 21., 16., 17., 22., 23., 24., 25.,\n",
       "       30., 31., 26., 27., 32., 33., 28., 29., 34., 35.], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.ascontiguousarray(B)\n",
    "\n",
    "np.frombuffer(ctypes.string_at(C.ctypes.data, size=C.nbytes), C.dtype, C.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10c7af",
   "metadata": {},
   "source": [
    "As you can see, the `C` array is layed out in compact order.  This can also be verified by looking as it's `.strides` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cd024d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 16, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(C.strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dba8dd",
   "metadata": {},
   "source": [
    "## Convolutions via im2col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef2ea7",
   "metadata": {},
   "source": [
    "Let's consider finally the \"real\" way to implement convolutions, which will end up being about as fast as PyTorch's implementation. Essentially, we want to bundle all the computation needed for convolution into a *single* matrix multiplication, which will then leverage all the optimizations that we can implement for normal matrix multiplication.\n",
    "\n",
    "The key approach to doing this is called the `im2col` operator, which \"unfolds\" a 4D array (rank 4 tensor) into exactly the form needed to perform multiplication via convolution.  Let's see an example of how this works using a simple 2D array, before we move to the 4D case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a46fbe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15., 16., 17.],\n",
       "       [18., 19., 20., 21., 22., 23.],\n",
       "       [24., 25., 26., 27., 28., 29.],\n",
       "       [30., 31., 32., 33., 34., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.arange(n**2, dtype=np.float32).reshape(n, n)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f38e4",
   "metadata": {},
   "source": [
    "A 3x3 filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8407b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.],\n",
       "       [6., 7., 8.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.arange(9, dtype=np.float32).reshape(3, 3)\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b9f26",
   "metadata": {},
   "source": [
    "Recall that a convolution will multiply this filter element-wise with every $3 \\times 3$ block in the image. \n",
    "\n",
    "So how can we extract every such $3 \\times 3$ blocks from the matrix `A`? \n",
    "\n",
    "The key will be to form a $(H - K + 1) \\times (W - K + 1) \\times K \\times K$ array that contains all of these blocks, then flatten it to a matrix we can multiply by the filter. To create this array of all blocks, short of manual copying, we can use the `as_strided()` function.\n",
    "\n",
    "Specifically, if we create a new view into the tiled array of size `(6 - 3 + 1 = 4, 6 - 3 + 1 = 4, 3, 3)`, how can we use `as_strided()` to return the matrix we want? \n",
    "\n",
    "Note that the first two dimensions or indices will have strides of `6` elements and `1` element:\n",
    "\n",
    "1. Incrementing the first index by `1` will move to the next row since we assume a stride of 1 vertically\n",
    "   \n",
    "2. Incrementing the next index by `1` will move to the next column since we assume a stride of 1 horizontally\n",
    "   \n",
    "Interestingly (and this is the \"trick\"), the third and fourth dimensions *also* have strides of `6` and `1`, respectively. This is because incrementing the third index by one *also* moves to the next row, and similarly, for the fourth index, moves to the next column. Again, this is all assuming a stride of 1 both vertically and horizontally within each tile of $3 \\times 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "51b2c67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 3, 3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  1.,  2.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [12., 13., 14.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[ 2.,  3.,  4.],\n",
       "         [ 8.,  9., 10.],\n",
       "         [14., 15., 16.]],\n",
       "\n",
       "        [[ 3.,  4.,  5.],\n",
       "         [ 9., 10., 11.],\n",
       "         [15., 16., 17.]]],\n",
       "\n",
       "\n",
       "       [[[ 6.,  7.,  8.],\n",
       "         [12., 13., 14.],\n",
       "         [18., 19., 20.]],\n",
       "\n",
       "        [[ 7.,  8.,  9.],\n",
       "         [13., 14., 15.],\n",
       "         [19., 20., 21.]],\n",
       "\n",
       "        [[ 8.,  9., 10.],\n",
       "         [14., 15., 16.],\n",
       "         [20., 21., 22.]],\n",
       "\n",
       "        [[ 9., 10., 11.],\n",
       "         [15., 16., 17.],\n",
       "         [21., 22., 23.]]],\n",
       "\n",
       "\n",
       "       [[[12., 13., 14.],\n",
       "         [18., 19., 20.],\n",
       "         [24., 25., 26.]],\n",
       "\n",
       "        [[13., 14., 15.],\n",
       "         [19., 20., 21.],\n",
       "         [25., 26., 27.]],\n",
       "\n",
       "        [[14., 15., 16.],\n",
       "         [20., 21., 22.],\n",
       "         [26., 27., 28.]],\n",
       "\n",
       "        [[15., 16., 17.],\n",
       "         [21., 22., 23.],\n",
       "         [27., 28., 29.]]],\n",
       "\n",
       "\n",
       "       [[[18., 19., 20.],\n",
       "         [24., 25., 26.],\n",
       "         [30., 31., 32.]],\n",
       "\n",
       "        [[19., 20., 21.],\n",
       "         [25., 26., 27.],\n",
       "         [31., 32., 33.]],\n",
       "\n",
       "        [[20., 21., 22.],\n",
       "         [26., 27., 28.],\n",
       "         [32., 33., 34.]],\n",
       "\n",
       "        [[21., 22., 23.],\n",
       "         [27., 28., 29.],\n",
       "         [33., 34., 35.]]]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.lib.stride_tricks.as_strided(\n",
    "    A, shape=(4, 4, 3, 3), strides=(np.array((6, 1, 6, 1))) * 4\n",
    ")\n",
    "B.shape\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab9d21fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35.], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.frombuffer(ctypes.string_at(B.ctypes.data, size=A.nbytes), B.dtype, A.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39c25b",
   "metadata": {},
   "source": [
    "This is exactly the 4D array we need.  Now, if we want to compute the convolution as a \"single\" matrix multiplication, we can simply \n",
    "\n",
    "1. Flatten this array to a $(4 \\cdot 4 = 16) \\times (3 \\cdot 3 = 9)$ matrix\n",
    "   \n",
    "2. Reshape the weights to a $9$ dimensional vector (the weights will become a matrix again for the case of multi-channel convolutions)\n",
    "\n",
    "3. Perform the matrix multiplication  \n",
    "   \n",
    "4. Finally, reshape the resulting vector back into a $4 \\times 4$ array to perform the convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cfaa6a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  6.,  7.,  8., 12., 13., 14.],\n",
       "       [ 1.,  2.,  3.,  7.,  8.,  9., 13., 14., 15.],\n",
       "       [ 2.,  3.,  4.,  8.,  9., 10., 14., 15., 16.],\n",
       "       [ 3.,  4.,  5.,  9., 10., 11., 15., 16., 17.],\n",
       "       [ 6.,  7.,  8., 12., 13., 14., 18., 19., 20.],\n",
       "       [ 7.,  8.,  9., 13., 14., 15., 19., 20., 21.],\n",
       "       [ 8.,  9., 10., 14., 15., 16., 20., 21., 22.],\n",
       "       [ 9., 10., 11., 15., 16., 17., 21., 22., 23.],\n",
       "       [12., 13., 14., 18., 19., 20., 24., 25., 26.],\n",
       "       [13., 14., 15., 19., 20., 21., 25., 26., 27.],\n",
       "       [14., 15., 16., 20., 21., 22., 26., 27., 28.],\n",
       "       [15., 16., 17., 21., 22., 23., 27., 28., 29.],\n",
       "       [18., 19., 20., 24., 25., 26., 30., 31., 32.],\n",
       "       [19., 20., 21., 25., 26., 27., 31., 32., 33.],\n",
       "       [20., 21., 22., 26., 27., 28., 32., 33., 34.],\n",
       "       [21., 22., 23., 27., 28., 29., 33., 34., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = B.reshape(16, 9)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db4ce8",
   "metadata": {},
   "source": [
    "In matrix $C$, every row is a flattened version of the $3 \\times 3$ block of the original input $A$, simulating a sliding window over $A$. This can then be multiplied by a flattened $W$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d630499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 366.,  402.,  438.,  474.],\n",
       "       [ 582.,  618.,  654.,  690.],\n",
       "       [ 798.,  834.,  870.,  906.],\n",
       "       [1014., 1050., 1086., 1122.]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    C\n",
    "    @ W.reshape(\n",
    "        9,\n",
    "    )\n",
    ").reshape(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08c03a",
   "metadata": {},
   "source": [
    "#### A Critical Note on Memory Efficiency\n",
    "\n",
    "There is a _very_ crucial point to make regarding memory efficiency of this operation. While reshaping `W` into an array (or what will be a matrix for multi-channel convolutions) is \"free\" in that it doesn't allocate any new memory, reshaping the `B` matrix above is very much *not* a free operation. \n",
    "\n",
    "Specifically, while the strided form of `B` uses the same memory as `A`, once we actually convert `B` into a 2D matrix with `reshape`, there is no way to represent this data using any kind of strides, and we have to just allocate the entire matrix. This means we actually need to *form* the full `im2col` matrix, which requires $O(K^2)$ more memory than the original image, which can be quite costly for large kernel sizes.\n",
    "\n",
    "For this reason, in practice it's often the case that the best modern implementations *won't* actually instantiate the full `im2col` matrix, and will instead perform a kind of \"lazy\" formation, or specialize the matrix operation natively to `im2col` matrices in their native strided form. These are all fairly advanced topics; for our purposes, it will be sufficient to just allocate this matrix and then quickly de-allocate it after we perform the convolution (remember that we aren't e.g., doing back-propagation through the `im2col` operation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91503a67",
   "metadata": {},
   "source": [
    "### Using im2col for Multi-Channel Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358af2ab",
   "metadata": {},
   "source": [
    "So how do we actually implement an `im2col` operation for real multi-channel, mini-batched convolutions? \n",
    "\n",
    "Instead of forming a 4D $(H - K + 1) \\times (W - K + 1) \\times K \\times K$ array, we form a 6D $N \\times (H - K + 1) \\times (W - K + 1) \\times K \\times K \\times C$ array (leaving the mini-batch and channel dimensions untouched). \n",
    "\n",
    "After thinking about it for a bit, it should be pretty clear that we can apply the same trick by just repeating the strides for dimensions 1 and 2 (the height and width) for dimensions 3 and 4 (the $K \\times K$ blocks), and leave the strides for the mini-batch and channels unchanged. Furthermore, we don't even need to worry about manually computing the strides manually: we can just use the strides of the $Z$ input and repeat whatever they are.\n",
    "\n",
    "To compute the convolution, \n",
    "\n",
    "1. Flatten the `im2col` matrix to a $(N \\cdot (H - K + 1) \\cdot (W - K + 1)) \\times (K \\cdot K \\cdot C)$ matrix (remember, this operation is highly memory inefficient)\n",
    "   * Also note that this is exactly how we reshaped the 4D strided tensor $((H - K + 1) \\times (W - K + 1)) \\times (K \\times K)$ earlier except we now include the batch and the channel dimensions since we have a 6D tensor\n",
    "2. Flatten the weights array to a $(K \\cdot K \\cdot C) \\times C_{out}$ matrix so that dimensions of these two matrices are matching\n",
    "3. Perform the multiplication\n",
    "4. Resize back to the desired size of the final 4D array output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b4a00e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_im2col(Z: np.ndarray, weight: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implementation of convolution operation using im2col.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : np.ndarray\n",
    "        The input to the convolutional layer.\n",
    "    weight : np.ndarray\n",
    "        The weights of the convolutional layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The output of the convolutional layer.\n",
    "    \"\"\"\n",
    "    # Shapes of input and weight\n",
    "    N, H, W, C_in = Z.shape\n",
    "    K, _, _, C_out = weight.shape\n",
    "    # Strides of the input\n",
    "    Ns, Hs, Ws, Cs = Z.strides\n",
    "    # The output (column) dimension of the im2col matrix\n",
    "    inner_dim = K * K * C_in\n",
    "    # The im2col matrix\n",
    "    A = np.lib.stride_tricks.as_strided(\n",
    "        Z, shape=(N, H - K + 1, W - K + 1, K, K, C_in), strides=(Ns, Hs, Ws, Hs, Ws, Cs)\n",
    "    ).reshape(-1, inner_dim)\n",
    "\n",
    "    # A is a N * (H - K + 1) * (W - K + 1) x (K * K * C_in) matrix\n",
    "    # Reshaped weight is a (K * K * C_in) x C_out matrix\n",
    "    out = A @ weight.reshape(-1, C_out)\n",
    "\n",
    "    # Reshape to output shape\n",
    "    return out.reshape(N, H - K + 1, W - K + 1, C_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3955e0",
   "metadata": {},
   "source": [
    "Again, we can check that this version produces the same output as the PyTorch reference (or our other implementations, at this point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d7df0666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A batch of 100 images of size 32 x 32 with 8 channels\n",
    "Z = np.random.randn(100, 32, 32, 8)\n",
    "# Kernel size of 3 x 3 with 8 input channels and 16 output channels\n",
    "W = np.random.randn(3, 3, 8, 16)\n",
    "\n",
    "out = conv_reference(Z, W)\n",
    "out_2 = conv_im2col(Z, W)\n",
    "\n",
    "np.linalg.norm(out - out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f888dd",
   "metadata": {},
   "source": [
    "Runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "10bcfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.7 ms ± 15.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out_3 = conv_im2col(Z, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0c826",
   "metadata": {},
   "source": [
    "This outperforms the implementation using matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bef70539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.6 ms ± 8.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = conv_matrix_mult(Z, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1d7ac",
   "metadata": {},
   "source": [
    "However, the PyTorch implementation is still the fastest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4d446458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7 ms ± 11.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out_3 = conv_reference(Z, W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
