{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Version 1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Interactive\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Standard library\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Custom transformers\n",
    "import transformers as tfs\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    HalvingRandomSearchCV,\n",
    "    ParameterGrid,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "# Machine Learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"XGB Version\", xgb.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state\n",
    "seed = 12\n",
    "rs = np.random.RandomState(seed)\n",
    "\n",
    "# Train and test data paths\n",
    "train_path = \"../data/train_test/\"\n",
    "test_path = \"../data/train_test/\"\n",
    "\n",
    "# Other paths\n",
    "model_path = \"../outputs/models/\"\n",
    "plot_path = \"../outputs/plots/\"\n",
    "\n",
    "# K-fold\n",
    "folds = 5\n",
    "\n",
    "# Top x important features to visualize\n",
    "top_num_features = 20\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = (\n",
    "    pd.read_parquet(train_path + \"train_X.parquet\"),\n",
    "    pd.read_parquet(train_path + \"train_y.parquet\").to_numpy().ravel(),\n",
    ")\n",
    "test_X, test_y = (\n",
    "    pd.read_parquet(test_path + \"test_X.parquet\"),\n",
    "    pd.read_parquet(test_path + \"test_y.parquet\").to_numpy().ravel(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32950, 20), (32950,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8238, 20), (8238,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "We create the following pipelines:\n",
    "\n",
    "* There are no explicit missing values in both the training and test data; in addition, xgboost can handle missing values by default. However, if we expect future unseen data to contain missing values that need special handling, then we may need to invest in writing and testing additional custom transformers to include in the preprocessing steps.\n",
    "\n",
    "* Because the learners are trees, it isn't necessary to perform feature scaling or normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"drop_duration\", tfs.ColumnDropperTransformer([\"duration\"])),\n",
    "        (\n",
    "            \"cat_feature_engineer\",\n",
    "            FunctionTransformer(tfs.cat_feature_engineer, validate=False),\n",
    "        ),  # One hyperparameter: encode_type\n",
    "        (\n",
    "            \"num_feature_engineer\",\n",
    "            FunctionTransformer(tfs.num_feature_engineer, validate=False),\n",
    "        ),  # One hyperparameter: switch\n",
    "        (\n",
    "            \"recursive_feature_selection\",\n",
    "            RFE(\n",
    "                DecisionTreeClassifier(random_state=rs),\n",
    "                n_features_to_select=0.5,\n",
    "                step=0.2,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write preprocessor and label encoder to disk for later use\n",
    "joblib.dump(preprocessor, \"../outputs/pipeline/preprocessor.joblib\")\n",
    "joblib.dump(label_encoder, \"../outputs/pipeline/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = label_encoder.fit_transform(train_y)\n",
    "test_y = label_encoder.transform(test_y)\n",
    "train_y, test_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct a final modeling pipeline that includes the gradient-boosting classifier, which we can pass into grid search. Note that the `eval_metric` parameter below is assumed to be a cost function and by default XGBoost will minimize the result during early stopping. This is not the same the `scoring` parameter commonly used in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/modeling_pipeline.joblib']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;drop_duration&#x27;,\n",
       "                                  ColumnDropperTransformer(columns=[&#x27;duration&#x27;])),\n",
       "                                 (&#x27;cat_feature_engineer&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function cat_feature_engineer at 0x171ace040&gt;)),\n",
       "                                 (&#x27;num_feature_engineer&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function num_feature_engineer at 0x171ace280&gt;)),\n",
       "                                 (&#x27;recursive_feature_selection&#x27;,\n",
       "                                  RFE(estimator=De...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=1601311818, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;drop_duration&#x27;,\n",
       "                                  ColumnDropperTransformer(columns=[&#x27;duration&#x27;])),\n",
       "                                 (&#x27;cat_feature_engineer&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function cat_feature_engineer at 0x171ace040&gt;)),\n",
       "                                 (&#x27;num_feature_engineer&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function num_feature_engineer at 0x171ace280&gt;)),\n",
       "                                 (&#x27;recursive_feature_selection&#x27;,\n",
       "                                  RFE(estimator=De...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=1601311818, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;drop_duration&#x27;,\n",
       "                 ColumnDropperTransformer(columns=[&#x27;duration&#x27;])),\n",
       "                (&#x27;cat_feature_engineer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function cat_feature_engineer at 0x171ace040&gt;)),\n",
       "                (&#x27;num_feature_engineer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function num_feature_engineer at 0x171ace280&gt;)),\n",
       "                (&#x27;recursive_feature_selection&#x27;,\n",
       "                 RFE(estimator=DecisionTreeClassifier(random_state=RandomState(MT19937) at 0x172596540),\n",
       "                     n_features_to_select=0.5, step=0.2))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnDropperTransformer(columns=[&#x27;duration&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function cat_feature_engineer at 0x171ace040&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function num_feature_engineer at 0x171ace280&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">recursive_feature_selection: RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=DecisionTreeClassifier(random_state=RandomState(MT19937) at 0x172596540),\n",
       "    n_features_to_select=0.5, step=0.2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=RandomState(MT19937) at 0x172596540)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=RandomState(MT19937) at 0x172596540)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=make_scorer(log_loss, labels=[0, 1]),\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=None, predictor=None, random_state=1907932429, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 Pipeline(steps=[('drop_duration',\n",
       "                                  ColumnDropperTransformer(columns=['duration'])),\n",
       "                                 ('cat_feature_engineer',\n",
       "                                  FunctionTransformer(func=<function cat_feature_engineer at 0x171ace040>)),\n",
       "                                 ('num_feature_engineer',\n",
       "                                  FunctionTransformer(func=<function num_feature_engineer at 0x171ace280>)),\n",
       "                                 ('recursive_feature_selection',\n",
       "                                  RFE(estimator=De...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=1505292720, ...))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will fix these xgboost classifier parameters\n",
    "fixed_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"verbosity\": 1,\n",
    "    \"random_state\": rs,\n",
    "    \"n_jobs\": -1,\n",
    "    \"eval_metric\": make_scorer(\n",
    "        log_loss, labels=[0, 1]\n",
    "    ),  # More robust to imbalance, used for monitoring the training result and early stopping\n",
    "}\n",
    "\n",
    "modeling_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"preprocessor\",\n",
    "            preprocessor,\n",
    "        ),  # This step is in and of itself a pipeline (nested) which needs special handling in GridSearchCV\n",
    "        (\"classifier\", xgb.XGBClassifier(**fixed_params)),\n",
    "    ]\n",
    ")\n",
    "joblib.dump(modeling_pipe, \"../outputs/pipeline/modeling_pipeline.joblib\")\n",
    "modeling_pipe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nested nature of the pipeline, it will be easier to see the entire list of parameters with their tags, so we can select the hyperparameter we need to include in a grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = sorted(modeling_pipe.get_params().keys())\n",
    "len(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier',\n",
       " 'classifier__base_score',\n",
       " 'classifier__booster',\n",
       " 'classifier__callbacks',\n",
       " 'classifier__colsample_bylevel',\n",
       " 'classifier__colsample_bynode',\n",
       " 'classifier__colsample_bytree',\n",
       " 'classifier__early_stopping_rounds',\n",
       " 'classifier__enable_categorical',\n",
       " 'classifier__eval_metric',\n",
       " 'classifier__feature_types',\n",
       " 'classifier__gamma',\n",
       " 'classifier__gpu_id',\n",
       " 'classifier__grow_policy',\n",
       " 'classifier__importance_type',\n",
       " 'classifier__interaction_constraints',\n",
       " 'classifier__learning_rate',\n",
       " 'classifier__max_bin',\n",
       " 'classifier__max_cat_threshold',\n",
       " 'classifier__max_cat_to_onehot',\n",
       " 'classifier__max_delta_step',\n",
       " 'classifier__max_depth',\n",
       " 'classifier__max_leaves',\n",
       " 'classifier__min_child_weight',\n",
       " 'classifier__missing',\n",
       " 'classifier__monotone_constraints',\n",
       " 'classifier__n_estimators',\n",
       " 'classifier__n_jobs',\n",
       " 'classifier__num_parallel_tree',\n",
       " 'classifier__objective',\n",
       " 'classifier__predictor',\n",
       " 'classifier__random_state',\n",
       " 'classifier__reg_alpha',\n",
       " 'classifier__reg_lambda',\n",
       " 'classifier__sampling_method',\n",
       " 'classifier__scale_pos_weight',\n",
       " 'classifier__subsample',\n",
       " 'classifier__tree_method',\n",
       " 'classifier__use_label_encoder',\n",
       " 'classifier__validate_parameters',\n",
       " 'classifier__verbosity',\n",
       " 'memory',\n",
       " 'preprocessor',\n",
       " 'preprocessor__cat_feature_engineer',\n",
       " 'preprocessor__cat_feature_engineer__accept_sparse',\n",
       " 'preprocessor__cat_feature_engineer__check_inverse',\n",
       " 'preprocessor__cat_feature_engineer__feature_names_out',\n",
       " 'preprocessor__cat_feature_engineer__func',\n",
       " 'preprocessor__cat_feature_engineer__inv_kw_args',\n",
       " 'preprocessor__cat_feature_engineer__inverse_func',\n",
       " 'preprocessor__cat_feature_engineer__kw_args',\n",
       " 'preprocessor__cat_feature_engineer__validate',\n",
       " 'preprocessor__drop_duration',\n",
       " 'preprocessor__drop_duration__columns',\n",
       " 'preprocessor__memory',\n",
       " 'preprocessor__num_feature_engineer',\n",
       " 'preprocessor__num_feature_engineer__accept_sparse',\n",
       " 'preprocessor__num_feature_engineer__check_inverse',\n",
       " 'preprocessor__num_feature_engineer__feature_names_out',\n",
       " 'preprocessor__num_feature_engineer__func',\n",
       " 'preprocessor__num_feature_engineer__inv_kw_args',\n",
       " 'preprocessor__num_feature_engineer__inverse_func',\n",
       " 'preprocessor__num_feature_engineer__kw_args',\n",
       " 'preprocessor__num_feature_engineer__validate',\n",
       " 'preprocessor__recursive_feature_selection',\n",
       " 'preprocessor__recursive_feature_selection__estimator',\n",
       " 'preprocessor__recursive_feature_selection__estimator__ccp_alpha',\n",
       " 'preprocessor__recursive_feature_selection__estimator__class_weight',\n",
       " 'preprocessor__recursive_feature_selection__estimator__criterion',\n",
       " 'preprocessor__recursive_feature_selection__estimator__max_depth',\n",
       " 'preprocessor__recursive_feature_selection__estimator__max_features',\n",
       " 'preprocessor__recursive_feature_selection__estimator__max_leaf_nodes',\n",
       " 'preprocessor__recursive_feature_selection__estimator__min_impurity_decrease',\n",
       " 'preprocessor__recursive_feature_selection__estimator__min_samples_leaf',\n",
       " 'preprocessor__recursive_feature_selection__estimator__min_samples_split',\n",
       " 'preprocessor__recursive_feature_selection__estimator__min_weight_fraction_leaf',\n",
       " 'preprocessor__recursive_feature_selection__estimator__random_state',\n",
       " 'preprocessor__recursive_feature_selection__estimator__splitter',\n",
       " 'preprocessor__recursive_feature_selection__importance_getter',\n",
       " 'preprocessor__recursive_feature_selection__n_features_to_select',\n",
       " 'preprocessor__recursive_feature_selection__step',\n",
       " 'preprocessor__recursive_feature_selection__verbose',\n",
       " 'preprocessor__steps',\n",
       " 'preprocessor__verbose',\n",
       " 'steps',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "We will first use halving grid search cv to try to find the best combination of hyperparameter for the gradient boosting classifier. Note again, this is done without any over or under-sampling. We will conduct another CV to validate our model once we have solidified a list of parameters to use for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of hyperparameter values\n",
    "param_grid = {\n",
    "    # XGBoost hyperparameter to tune\n",
    "    \"classifier__learning_rate\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"classifier__n_estimators\": list(range(50, 350, 50)),  # Number of trees\n",
    "    \"classifier__max_depth\": list(range(3, 11, 2)),  # Tree size\n",
    "    \"classifier__gamma\": [0, 3],  # Regularization complexity\n",
    "    \"classifier__colsample_bytree\": [\n",
    "        0.4,\n",
    "        0.6,\n",
    "        0.8,\n",
    "        1.0,\n",
    "    ],  # Subsample ratio of columns (features) when constructing each tree\n",
    "    \"classifier__subsample\": [\n",
    "        0.5,\n",
    "        0.75,\n",
    "        1.0,\n",
    "    ],  # Subsample ratio of the rows (training instances) to safeguard against overfitting\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of models that could be trained is $k$ (k fold csv) times total number of parameters (product of all values in the grid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11520"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ParameterGrid(param_grid=param_grid)) * folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomized halving grid search uses successive halving to reduce the training time. Note that the `XGBClassifier` estimator has its own `score` method, which would be used if no `scoring` argument is specified below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 7\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 7\n",
      "min_resources_: 20\n",
      "max_resources_: 32950\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1647\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 1647 candidates, totalling 8235 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 549\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 549 candidates, totalling 2745 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 183\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 183 candidates, totalling 915 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 61\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 61 candidates, totalling 305 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 21\n",
      "n_resources: 1620\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 7\n",
      "n_resources: 4860\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 3\n",
      "n_resources: 14580\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "search = HalvingRandomSearchCV(\n",
    "    estimator=modeling_pipe,\n",
    "    param_distributions=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=folds),\n",
    "    scoring=make_scorer(\n",
    "        f1_score, average=\"weighted\", labels=[0, 1], zero_division=0\n",
    "    ),  # Alters 'macro f1' to be more robust to class imbalance\n",
    "    refit=True,  # Get best estimator upon completion\n",
    "    random_state=rs,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all processors\n",
    ").fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../outputs/models/baseline_model.joblib.dat']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save base model to disk\n",
    "joblib.dump(\n",
    "    search.best_estimator_[\"classifier\"], model_path + \"baseline_model.joblib.dat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/tuned_pipeline_trained.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save stored pipeline\n",
    "joblib.dump(search, \"../outputs/pipeline/tuned_pipeline_trained.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(xgboost.sklearn.XGBClassifier,\n",
       " sklearn.pipeline.Pipeline,\n",
       " sklearn.feature_selection._rfe.RFE)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model whose parameters we will use to run manual k-fold cross validation\n",
    "model = search.best_estimator_[\"classifier\"]\n",
    "# Preprocessor trained on training data, which we can use to transform test data\n",
    "preprocessor_trained = search.best_estimator_[\"preprocessor\"]\n",
    "# Trained rfe for getting the feature names\n",
    "rfe_trained = search.best_estimator_[\"preprocessor\"][\"recursive_feature_selection\"]\n",
    "type(model), type(preprocessor_trained), type(rfe_trained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Evaluation\n",
    "\n",
    "We can examine the `model` returned by the randomized halving grid search. We are not evaluating the model in a robust way (via CV) just yet, but we can get a preliminary sense of how this model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5854556818717864"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced = balanced_accuracy_score(\n",
    "    y_true=test_y,\n",
    "    y_pred=model.predict(preprocessor_trained.transform(test_X)),\n",
    "    adjusted=False,\n",
    ")\n",
    "balanced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can set adjusted to true. With `adjusted=True`, balanced accuracy reports the relative increase from balanced accuracy.\n",
    "\n",
    "* When true, the result is adjusted for chance, so that random performance would score 0, while keeping perfect performance at a score of 1. \n",
    "  \n",
    "* In the binary case, this is also known as *Youden’s J statistic*, or informedness. \n",
    "\n",
    "* Instead of taking values from 0 to 1, setting `adjusted=True` rescales the range of the score from $\\frac{1}{1-\\text{number of classes}}=-1$ (number of classes is 2 in our case) to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17091136374357285"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_adj = balanced_accuracy_score(\n",
    "    y_true=test_y,\n",
    "    y_pred=model.predict(preprocessor_trained.transform(test_X)),\n",
    "    adjusted=True,\n",
    ")\n",
    "balanced_adj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these to the simple accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898761835396941"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true=test_y,\n",
    "    y_pred=model.predict(preprocessor_trained.transform(test_X)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898761835396941"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the estimator's own scoring function\n",
    "model.score(X=preprocessor_trained.transform(test_X), y=test_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare this to the zero rule benchmark which simply predicts the most frequently occurring classification in a set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A classifier that always predicts the majority class (0)\n",
    "test_y_zeror = np.zeros_like(test_y)\n",
    "test_y_zeror.sum()\n",
    "test_y_zeror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy (majority class classifier): 0.5 \n",
      "Balanced accuracy (boosted tree): 0.5855 \n",
      "Balanced accuracy (majority class classifier adjusted for chance): 0.0 \n",
      "Balanced accuracy (boosted tree adjusted for change): 0.1709\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Balanced accuracy (majority class classifier): {balanced_accuracy_score(y_true=test_y, y_pred=test_y_zeror, adjusted=False)}\",\n",
    "    f\"\\nBalanced accuracy (boosted tree): {balanced.round(4)}\",\n",
    "    f\"\\nBalanced accuracy (majority class classifier adjusted for chance): {balanced_accuracy_score(y_true=test_y, y_pred=test_y_zeror, adjusted=True)}\",\n",
    "    f\"\\nBalanced accuracy (boosted tree adjusted for change): {balanced_adj.round(4)}\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, our model outperforms that zero rule, but perhaps only slightly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Feature Importance\n",
    "\n",
    "We would like to examine the feature importance plot to evaluate how successful our feature engineering was. Below, we plot the top 20 importance features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>gains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>poutcome_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>previous_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>month_last</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>euribor3m_min</td>\n",
       "      <td>0.004959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>0.005317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>day_of_week_last</td>\n",
       "      <td>0.005543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>loan_std</td>\n",
       "      <td>0.005954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>euribor3m_last</td>\n",
       "      <td>0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>contact_mean</td>\n",
       "      <td>0.006070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>month_mean</td>\n",
       "      <td>0.006326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.006419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>campaign_max</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>emp_var_rate_std</td>\n",
       "      <td>0.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>education_std</td>\n",
       "      <td>0.006599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>day_of_week_std</td>\n",
       "      <td>0.006609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>campaign_last</td>\n",
       "      <td>0.006697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>day_of_week_mean</td>\n",
       "      <td>0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cons_price_idx_mean</td>\n",
       "      <td>0.006965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>campaign_std</td>\n",
       "      <td>0.007020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loan_mean</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>job_std</td>\n",
       "      <td>0.007499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>housing_mean</td>\n",
       "      <td>0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>education_mean</td>\n",
       "      <td>0.008073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cons_price_idx_last</td>\n",
       "      <td>0.008115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>housing_std</td>\n",
       "      <td>0.008129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>campaign_mean</td>\n",
       "      <td>0.008503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cons_conf_idx_last</td>\n",
       "      <td>0.008672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>job_mean</td>\n",
       "      <td>0.008913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>cons_conf_idx_mean</td>\n",
       "      <td>0.009368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.009450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.009636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>marital_mean</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>marital_std</td>\n",
       "      <td>0.010934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nr_employed_std</td>\n",
       "      <td>0.011057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>emp_var_rate_mean</td>\n",
       "      <td>0.012128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cons_price_idx</td>\n",
       "      <td>0.012387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>month_std</td>\n",
       "      <td>0.012575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.012639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cons_conf_idx_std</td>\n",
       "      <td>0.017683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cons_price_idx_std</td>\n",
       "      <td>0.019092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>default</td>\n",
       "      <td>0.019846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pdays_mean</td>\n",
       "      <td>0.025157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>previous_std</td>\n",
       "      <td>0.029019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cons_conf_idx</td>\n",
       "      <td>0.031965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month</td>\n",
       "      <td>0.038059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.042168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.047819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>emp_var_rate</td>\n",
       "      <td>0.066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.068651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nr_employed</td>\n",
       "      <td>0.292123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat_name     gains\n",
       "1               marital  0.000000\n",
       "42         poutcome_std  0.000000\n",
       "41         previous_max  0.000000\n",
       "31           month_last  0.000000\n",
       "4               housing  0.003098\n",
       "51        euribor3m_min  0.004959\n",
       "2             education  0.005317\n",
       "34     day_of_week_last  0.005543\n",
       "0                   job  0.005660\n",
       "27             loan_std  0.005954\n",
       "52       euribor3m_last  0.006007\n",
       "28         contact_mean  0.006070\n",
       "29           month_mean  0.006326\n",
       "5                  loan  0.006419\n",
       "37         campaign_max  0.006507\n",
       "44     emp_var_rate_std  0.006568\n",
       "23        education_std  0.006599\n",
       "33      day_of_week_std  0.006609\n",
       "38        campaign_last  0.006697\n",
       "32     day_of_week_mean  0.006962\n",
       "45  cons_price_idx_mean  0.006965\n",
       "36         campaign_std  0.007020\n",
       "26            loan_mean  0.007477\n",
       "19              job_std  0.007499\n",
       "24         housing_mean  0.007855\n",
       "22       education_mean  0.008073\n",
       "47  cons_price_idx_last  0.008115\n",
       "25          housing_std  0.008129\n",
       "9              campaign  0.008351\n",
       "35        campaign_mean  0.008503\n",
       "50   cons_conf_idx_last  0.008672\n",
       "18             job_mean  0.008913\n",
       "48   cons_conf_idx_mean  0.009368\n",
       "11             previous  0.009450\n",
       "8           day_of_week  0.009636\n",
       "20         marital_mean  0.010754\n",
       "21          marital_std  0.010934\n",
       "53      nr_employed_std  0.011057\n",
       "43    emp_var_rate_mean  0.012128\n",
       "14       cons_price_idx  0.012387\n",
       "30            month_std  0.012575\n",
       "6               contact  0.012639\n",
       "49    cons_conf_idx_std  0.017683\n",
       "46   cons_price_idx_std  0.019092\n",
       "3               default  0.019846\n",
       "39           pdays_mean  0.025157\n",
       "40         previous_std  0.029019\n",
       "15        cons_conf_idx  0.031965\n",
       "7                 month  0.038059\n",
       "12             poutcome  0.042168\n",
       "10                pdays  0.047819\n",
       "13         emp_var_rate  0.066625\n",
       "16            euribor3m  0.068651\n",
       "17          nr_employed  0.292123"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = pd.DataFrame(\n",
    "    {\n",
    "        \"feat_name\": rfe_trained.get_feature_names_out(),\n",
    "        \"gains\": model.feature_importances_,\n",
    "    }\n",
    ")\n",
    "feat_imp.sort_values(by=\"gains\", ascending=True, inplace=True)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='feat_name'>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x936 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "feat_imp.iloc[-top_num_features:].plot(\n",
    "    kind=\"barh\", x=\"feat_name\", y=\"gains\", figsize=(15, 13), legend=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our engineered features certainly made it up the list. For instance, we can compute the percentage of engineered features among the top 20 most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45% of the top 20 features are engineered from numerical features, not including count of categorical features\n"
     ]
    }
   ],
   "source": [
    "top_names = feat_imp.iloc[-top_num_features:].feat_name.to_list()\n",
    "num_eng_feat = len(\n",
    "    [\n",
    "        name\n",
    "        for name in top_names\n",
    "        if any(map(name.__contains__, [\"_mean\", \"_std\", \"_last\", \"_max\", \"_min\"]))\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    f\"{int(((num_eng_feat / len(top_names)) * 100))}% of the top {top_num_features} features are engineered from numerical features, not including count of categorical features\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40fc6ebffc74793621f684cf09d9f3d0a501c91440a6f462aebac8d38ed47133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
