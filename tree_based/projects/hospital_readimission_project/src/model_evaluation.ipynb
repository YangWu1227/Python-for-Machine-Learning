{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Version 1.7.2\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Standard library\n",
    "from functools import reduce\n",
    "from math import ceil\n",
    "from typing import Dict\n",
    "\n",
    "# Custom modules and other\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "print(\"XGB Version\", xgb.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 27\n",
    "rs = np.random.RandomState(seed)\n",
    "\n",
    "# Folds\n",
    "folds = 5\n",
    "\n",
    "# Paths\n",
    "data_path = \"../data/train_test/\"\n",
    "model_path = \"../outputs/models/\"\n",
    "pipe_path = \"../outputs/pipeline/\"\n",
    "plot_path = \"../outputs/plots/\"\n",
    "\n",
    "top_num_features = 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = (\n",
    "    pd.read_parquet(data_path + \"train_X.parquet\"),\n",
    "    pd.read_parquet(data_path + \"train_y.parquet\")\n",
    "    .to_numpy()\n",
    "    .reshape(\n",
    "        -1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81412, 49), (81412,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Using Bayesian Optimization\n",
    "\n",
    "The models with default parameters suffer from severe overfitting. We need to optimize the hyperparameter to reduce the variance. We will use Bayesian optimization to search through the hyperparameter search space. The `hyperopt` package's implementation of the Tree-structured Parzen Estimator algorithm is what we will use.\n",
    "\n",
    "* First, define the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space\n",
    "search_space = {\n",
    "    # Booster parameters\n",
    "    \"booster_params\": {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 3,\n",
    "        \"learning_rate\": hp.uniform(\n",
    "            \"learning_rate\", 0.001, 0.3\n",
    "        ),  # Range: [0, 1], larger eta shrinks the feature weights more to make the boosting process more conservative, i.e., fewer trees (regularizer)\n",
    "        \"gamma\": hp.randint(\n",
    "            \"gamma\", 0, 9\n",
    "        ),  # Range: [0, inf], the larger the more conservative the algorithm (regularizer)\n",
    "        \"max_delta_step\": hp.randint(\n",
    "            \"max_delta_step\", 1, 10\n",
    "        ),  # Range: [0, inf], values from 1-10 might help control the update for imbalanced data (regularizer)\n",
    "        \"lambda\": hp.choice(\n",
    "            \"lambda\", [1, 10, 100]\n",
    "        ),  # Range: [0, inf], L2 regularization term on weights, the larger the more conservative the algorithm (regularizer)\n",
    "        \"alpha\": hp.choice(\n",
    "            \"alpha\", [1, 10, 100]\n",
    "        ),  # Range: [0, inf], L1 regularization term on weights, the larger the more conservative the algorithm (regularizer)\n",
    "        \"colsample_bylevel\": hp.choice(\n",
    "            \"colsample_bylevel\", np.linspace(0.5, 1, 6).tolist()\n",
    "        ),\n",
    "        \"colsample_bynode\": hp.choice(\n",
    "            \"colsample_bynode\", np.linspace(0.5, 1, 6).tolist()\n",
    "        ),\n",
    "        \"colsample_bytree\": hp.choice(\n",
    "            \"colsample_bytree\", np.linspace(0.5, 1, 6).tolist()\n",
    "        ),  # Range: (0, 1], subsample ratio of columns when constructing each tree, the smaller the more conservative the algorithm (regularizer)\n",
    "        \"subsample\": hp.choice(\n",
    "            \"subsample\", np.linspace(0.5, 1, 6).tolist()\n",
    "        ),  # Range: (0, 1], subsample ratio of the training instances every boosting iteration, the smaller the more conservative the algorithm (regularizer)\n",
    "        \"max_depth\": hp.choice(\n",
    "            \"max_depth\", np.arange(3, 12, dtype=np.int16).tolist()\n",
    "        ),  # Range: [0, inf], deep trees boost predictive power but are more likely to overfit (bias reducer)\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"predictor\": \"cpu_predictor\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "    },\n",
    "    # Non-booster parameters\n",
    "    \"num_feat\": hp.choice(\"num_feat\", [50, 60, 70, 80]),\n",
    "    \"step\": hp.choice(\"step\", [0.1, 0.2, 0.3]),\n",
    "    \"k_neighbors\": hp.choice(\"k_neighbors\", [5, 10, 15, 20, 25, 30]),\n",
    "    \"num_boost_round\": hp.randint(\n",
    "        \"num_boost_round\", 500, 2000\n",
    "    ),  # Range: [0, inf], number of boosting iterations, the larger the more likely to overfit (bias reducer)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we define the objective function, which contains our cross-validation logic and returns the loss value we wish to minimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params: Dict):\n",
    "    # Create copies since we passed mutable objects\n",
    "    train_X, train_y = (\n",
    "        pd.read_parquet(\"../data/train_test/train_X.parquet\"),\n",
    "        pd.read_parquet(\"../data/train_test/train_y.parquet\")\n",
    "        .to_numpy()\n",
    "        .reshape(\n",
    "            -1,\n",
    "        ),\n",
    "    )\n",
    "    folds = 3\n",
    "    seed = 1227\n",
    "\n",
    "    print(params)\n",
    "\n",
    "    # Stratified K-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    losses = np.empty(folds)\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_X, train_y)):\n",
    "        # Train and validation sets\n",
    "        fold_train_X, fold_train_y = train_X.iloc[train_idx], train_y[train_idx]\n",
    "        fold_val_X, fold_val_y = train_X.iloc[val_idx], train_y[val_idx]\n",
    "\n",
    "        # Processing using fresh copies for every fold\n",
    "        print(f\"Start processing fold {fold + 1}...\")\n",
    "        preprocessor = joblib.load(pipe_path + \"preprocessor.joblib\")\n",
    "        label_encoder = joblib.load(pipe_path + \"label_encoder.joblib\")\n",
    "        # Fit and transform on training data\n",
    "        fold_train_X = preprocessor.fit_transform(fold_train_X)\n",
    "        fold_train_y = label_encoder.fit_transform(fold_train_y)\n",
    "        # Transform validation data\n",
    "        fold_val_X = preprocessor.transform(fold_val_X)\n",
    "        fold_val_y = label_encoder.transform(fold_val_y)\n",
    "\n",
    "        # Feature selection (tuning number of features and step size)\n",
    "        selector = RFE(\n",
    "            estimator=DecisionTreeClassifier(random_state=seed),\n",
    "            n_features_to_select=int(params[\"num_feat\"]),\n",
    "            step=float(params[\"step\"]),\n",
    "        )\n",
    "        fold_train_X = selector.fit_transform(fold_train_X, fold_train_y)\n",
    "        fold_val_X = selector.transform(fold_val_X)\n",
    "\n",
    "        # Computing sample instance weights\n",
    "        print(\"Class distribution:\", np.unique(fold_train_y, return_counts=True))\n",
    "        instance_weights = compute_sample_weight(\"balanced\", fold_train_y)\n",
    "        print(\n",
    "            \"Class instance weights:\", np.unique(instance_weights, return_counts=True)\n",
    "        )\n",
    "\n",
    "        # Model (tuning hyperparameters)\n",
    "        print(f\"Start training model for fold {fold + 1}...\")\n",
    "        feature_names = selector.get_feature_names_out().tolist()\n",
    "        # Apply weights to training and not validation data\n",
    "        dtrain = xgb.DMatrix(\n",
    "            data=fold_train_X,\n",
    "            label=fold_train_y,\n",
    "            feature_names=feature_names,\n",
    "            weight=instance_weights,\n",
    "        )\n",
    "        dvalid = xgb.DMatrix(\n",
    "            data=fold_val_X, label=fold_val_y, feature_names=feature_names\n",
    "        )\n",
    "        model = xgb.train(\n",
    "            params=params[\"booster_params\"],\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=int(params[\"num_boost_round\"]),\n",
    "            early_stopping_rounds=400,\n",
    "            evals=[(dtrain, \"train\"), (dvalid, \"validate\")],\n",
    "            verbose_eval=200,\n",
    "        )\n",
    "\n",
    "        # Out-of-fold prediction for the current fold\n",
    "        print(f\"Predicting for fold {fold + 1}...\")\n",
    "        oof_pred = model.predict(data=dvalid)\n",
    "        losses[fold] = log_loss(y_true=fold_val_y, y_pred=oof_pred)\n",
    "\n",
    "    mean_log_loss = np.mean(losses)\n",
    "\n",
    "    print(f\"Average log loss: {mean_log_loss}\")\n",
    "\n",
    "    return {\"loss\": mean_log_loss, \"status\": STATUS_OK}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minimize the objective function with the optimal value (multi-class log-loss) with respect to the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 100, 'learning_rate': 0.13624554527758775, 'max_delta_step': 2, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1844, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                             \n",
      "Class distribution:                                    \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))       \n",
      "Class instance weights:                                \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))\n",
      "Start training model for fold 1...                     \n",
      "[0]\ttrain-mlogloss:1.07293\tvalidate-mlogloss:1.06972   \n",
      "[200]\ttrain-mlogloss:0.90347\tvalidate-mlogloss:0.89122 \n",
      "[400]\ttrain-mlogloss:0.90347\tvalidate-mlogloss:0.89122 \n",
      "[461]\ttrain-mlogloss:0.90347\tvalidate-mlogloss:0.89122 \n",
      "Predicting for fold 1...                               \n",
      "Start processing fold 2...                             \n",
      "Class distribution:                                    \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))       \n",
      "Class instance weights:                                \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))\n",
      "Start training model for fold 2...                     \n",
      "[0]\ttrain-mlogloss:1.07499\tvalidate-mlogloss:1.07105   \n",
      "[200]\ttrain-mlogloss:0.89828\tvalidate-mlogloss:0.89654 \n",
      "[400]\ttrain-mlogloss:0.89828\tvalidate-mlogloss:0.89654 \n",
      "[588]\ttrain-mlogloss:0.89828\tvalidate-mlogloss:0.89654 \n",
      "Predicting for fold 2...                               \n",
      "Start processing fold 3...                             \n",
      "Class distribution:                                    \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))       \n",
      "Class instance weights:                                \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))\n",
      "Start training model for fold 3...                     \n",
      "[0]\ttrain-mlogloss:1.07232\tvalidate-mlogloss:1.07213   \n",
      "[200]\ttrain-mlogloss:0.89345\tvalidate-mlogloss:0.89891 \n",
      "[400]\ttrain-mlogloss:0.89345\tvalidate-mlogloss:0.89891 \n",
      "[464]\ttrain-mlogloss:0.89345\tvalidate-mlogloss:0.89891 \n",
      "Predicting for fold 3...                               \n",
      "Average log loss: 0.8955559056560096                   \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 100, 'learning_rate': 0.27236008498615155, 'max_delta_step': 1, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 1769, 'num_feat': 80, 'step': 0.1}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.05017\tvalidate-mlogloss:1.04723                               \n",
      "[200]\ttrain-mlogloss:0.87569\tvalidate-mlogloss:0.87454                             \n",
      "[400]\ttrain-mlogloss:0.87226\tvalidate-mlogloss:0.87562                             \n",
      "[600]\ttrain-mlogloss:0.87005\tvalidate-mlogloss:0.87509                             \n",
      "[606]\ttrain-mlogloss:0.86992\tvalidate-mlogloss:0.87437                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.04942\tvalidate-mlogloss:1.04864                               \n",
      "[200]\ttrain-mlogloss:0.87231\tvalidate-mlogloss:0.88619                             \n",
      "[400]\ttrain-mlogloss:0.87035\tvalidate-mlogloss:0.88470                             \n",
      "[600]\ttrain-mlogloss:0.86937\tvalidate-mlogloss:0.88440                             \n",
      "[800]\ttrain-mlogloss:0.86864\tvalidate-mlogloss:0.88486                             \n",
      "[1000]\ttrain-mlogloss:0.86824\tvalidate-mlogloss:0.88409                            \n",
      "[1200]\ttrain-mlogloss:0.86748\tvalidate-mlogloss:0.88382                            \n",
      "[1400]\ttrain-mlogloss:0.86668\tvalidate-mlogloss:0.88478                            \n",
      "[1494]\ttrain-mlogloss:0.86653\tvalidate-mlogloss:0.88428                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.04810\tvalidate-mlogloss:1.04705                               \n",
      "[200]\ttrain-mlogloss:0.87202\tvalidate-mlogloss:0.88336                             \n",
      "[400]\ttrain-mlogloss:0.86827\tvalidate-mlogloss:0.88223                             \n",
      "[600]\ttrain-mlogloss:0.86745\tvalidate-mlogloss:0.88360                             \n",
      "[779]\ttrain-mlogloss:0.86699\tvalidate-mlogloss:0.88392                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8806197990037968                                               \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 100, 'learning_rate': 0.04982670375110064, 'max_delta_step': 5, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1536, 'num_feat': 50, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08912\tvalidate-mlogloss:1.08903                               \n",
      "[200]\ttrain-mlogloss:0.90164\tvalidate-mlogloss:0.89838                             \n",
      "[400]\ttrain-mlogloss:0.89988\tvalidate-mlogloss:0.89695                             \n",
      "[600]\ttrain-mlogloss:0.89988\tvalidate-mlogloss:0.89695                             \n",
      "[657]\ttrain-mlogloss:0.89988\tvalidate-mlogloss:0.89695                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08981\tvalidate-mlogloss:1.08941                               \n",
      "[200]\ttrain-mlogloss:0.89904\tvalidate-mlogloss:0.90418                             \n",
      "[400]\ttrain-mlogloss:0.89704\tvalidate-mlogloss:0.90233                             \n",
      "[600]\ttrain-mlogloss:0.89704\tvalidate-mlogloss:0.90233                             \n",
      "[635]\ttrain-mlogloss:0.89704\tvalidate-mlogloss:0.90233                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08886\tvalidate-mlogloss:1.08822                               \n",
      "[200]\ttrain-mlogloss:0.89605\tvalidate-mlogloss:0.88975                             \n",
      "[400]\ttrain-mlogloss:0.89420\tvalidate-mlogloss:0.88828                             \n",
      "[600]\ttrain-mlogloss:0.89420\tvalidate-mlogloss:0.88828                             \n",
      "[646]\ttrain-mlogloss:0.89420\tvalidate-mlogloss:0.88828                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8958512843699289                                               \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 1, 'learning_rate': 0.1729510539367629, 'max_delta_step': 4, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1761, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06613\tvalidate-mlogloss:1.06536                               \n",
      "[200]\ttrain-mlogloss:0.90691\tvalidate-mlogloss:0.89397                             \n",
      "[400]\ttrain-mlogloss:0.90677\tvalidate-mlogloss:0.89356                             \n",
      "[600]\ttrain-mlogloss:0.90668\tvalidate-mlogloss:0.89369                             \n",
      "[655]\ttrain-mlogloss:0.90659\tvalidate-mlogloss:0.89346                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06775\tvalidate-mlogloss:1.06748                               \n",
      "[200]\ttrain-mlogloss:0.90335\tvalidate-mlogloss:0.90116                             \n",
      "[400]\ttrain-mlogloss:0.90280\tvalidate-mlogloss:0.90099                             \n",
      "[600]\ttrain-mlogloss:0.90248\tvalidate-mlogloss:0.90073                             \n",
      "[800]\ttrain-mlogloss:0.90245\tvalidate-mlogloss:0.90084                             \n",
      "[1000]\ttrain-mlogloss:0.90236\tvalidate-mlogloss:0.90068                            \n",
      "[1200]\ttrain-mlogloss:0.90229\tvalidate-mlogloss:0.90056                            \n",
      "[1400]\ttrain-mlogloss:0.90179\tvalidate-mlogloss:0.90055                            \n",
      "[1600]\ttrain-mlogloss:0.90176\tvalidate-mlogloss:0.90057                            \n",
      "[1646]\ttrain-mlogloss:0.90176\tvalidate-mlogloss:0.90058                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.06959\tvalidate-mlogloss:1.06990                               \n",
      "[200]\ttrain-mlogloss:0.90093\tvalidate-mlogloss:0.90081                             \n",
      "[400]\ttrain-mlogloss:0.90058\tvalidate-mlogloss:0.90060                             \n",
      "[600]\ttrain-mlogloss:0.90046\tvalidate-mlogloss:0.90036                             \n",
      "[800]\ttrain-mlogloss:0.90036\tvalidate-mlogloss:0.90021                             \n",
      "[805]\ttrain-mlogloss:0.90036\tvalidate-mlogloss:0.90021                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8980836628813437                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 1, 'learning_rate': 0.16725993252827023, 'max_delta_step': 9, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 517, 'num_feat': 50, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06714\tvalidate-mlogloss:1.06426                               \n",
      "[200]\ttrain-mlogloss:0.89424\tvalidate-mlogloss:0.88828                             \n",
      "[400]\ttrain-mlogloss:0.89228\tvalidate-mlogloss:0.88669                             \n",
      "[516]\ttrain-mlogloss:0.89093\tvalidate-mlogloss:0.88578                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06883\tvalidate-mlogloss:1.06771                               \n",
      "[200]\ttrain-mlogloss:0.88795\tvalidate-mlogloss:0.89544                             \n",
      "[400]\ttrain-mlogloss:0.88588\tvalidate-mlogloss:0.89379                             \n",
      "[516]\ttrain-mlogloss:0.88513\tvalidate-mlogloss:0.89332                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07414\tvalidate-mlogloss:1.07147                               \n",
      "[200]\ttrain-mlogloss:0.88681\tvalidate-mlogloss:0.89171                             \n",
      "[400]\ttrain-mlogloss:0.88479\tvalidate-mlogloss:0.89005                             \n",
      "[516]\ttrain-mlogloss:0.88429\tvalidate-mlogloss:0.88915                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8894152655692867                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 1, 'learning_rate': 0.048716639252872423, 'max_delta_step': 9, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 752, 'num_feat': 80, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08926\tvalidate-mlogloss:1.08788                               \n",
      "[200]\ttrain-mlogloss:0.86916\tvalidate-mlogloss:0.87545                             \n",
      "[400]\ttrain-mlogloss:0.85655\tvalidate-mlogloss:0.86954                             \n",
      "[600]\ttrain-mlogloss:0.85205\tvalidate-mlogloss:0.86824                             \n",
      "[751]\ttrain-mlogloss:0.84975\tvalidate-mlogloss:0.86723                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08953\tvalidate-mlogloss:1.08934                               \n",
      "[200]\ttrain-mlogloss:0.86324\tvalidate-mlogloss:0.88213                             \n",
      "[400]\ttrain-mlogloss:0.84987\tvalidate-mlogloss:0.87635                             \n",
      "[600]\ttrain-mlogloss:0.84709\tvalidate-mlogloss:0.87542                             \n",
      "[751]\ttrain-mlogloss:0.84535\tvalidate-mlogloss:0.87481                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08888\tvalidate-mlogloss:1.08953                               \n",
      "[200]\ttrain-mlogloss:0.86220\tvalidate-mlogloss:0.88416                             \n",
      "[400]\ttrain-mlogloss:0.84901\tvalidate-mlogloss:0.87927                             \n",
      "[600]\ttrain-mlogloss:0.84526\tvalidate-mlogloss:0.87788                             \n",
      "[751]\ttrain-mlogloss:0.84339\tvalidate-mlogloss:0.87784                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8732905462324277                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 10, 'learning_rate': 0.29638586632771785, 'max_delta_step': 1, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1275, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.04104\tvalidate-mlogloss:1.03830                               \n",
      "[200]\ttrain-mlogloss:0.79893\tvalidate-mlogloss:0.86387                             \n",
      "[400]\ttrain-mlogloss:0.76494\tvalidate-mlogloss:0.86124                             \n",
      "[600]\ttrain-mlogloss:0.74189\tvalidate-mlogloss:0.85914                             \n",
      "[800]\ttrain-mlogloss:0.72791\tvalidate-mlogloss:0.85660                             \n",
      "[1000]\ttrain-mlogloss:0.71658\tvalidate-mlogloss:0.85530                            \n",
      "[1200]\ttrain-mlogloss:0.70831\tvalidate-mlogloss:0.85475                            \n",
      "[1274]\ttrain-mlogloss:0.70530\tvalidate-mlogloss:0.85479                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.04338\tvalidate-mlogloss:1.04151                               \n",
      "[200]\ttrain-mlogloss:0.79545\tvalidate-mlogloss:0.87772                             \n",
      "[400]\ttrain-mlogloss:0.76140\tvalidate-mlogloss:0.87670                             \n",
      "[600]\ttrain-mlogloss:0.74099\tvalidate-mlogloss:0.87334                             \n",
      "[800]\ttrain-mlogloss:0.72752\tvalidate-mlogloss:0.87292                             \n",
      "[1000]\ttrain-mlogloss:0.71956\tvalidate-mlogloss:0.87146                            \n",
      "[1200]\ttrain-mlogloss:0.71211\tvalidate-mlogloss:0.87140                            \n",
      "[1274]\ttrain-mlogloss:0.70945\tvalidate-mlogloss:0.86992                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.03983\tvalidate-mlogloss:1.03942                               \n",
      "[200]\ttrain-mlogloss:0.78938\tvalidate-mlogloss:0.88223                             \n",
      "[400]\ttrain-mlogloss:0.75435\tvalidate-mlogloss:0.88342                             \n",
      "[600]\ttrain-mlogloss:0.73593\tvalidate-mlogloss:0.88328                             \n",
      "[800]\ttrain-mlogloss:0.72234\tvalidate-mlogloss:0.88015                             \n",
      "[911]\ttrain-mlogloss:0.71670\tvalidate-mlogloss:0.88055                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8684187283584425                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 10, 'learning_rate': 0.13210392933854104, 'max_delta_step': 1, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1340, 'num_feat': 60, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06831\tvalidate-mlogloss:1.06728                               \n",
      "[200]\ttrain-mlogloss:0.64484\tvalidate-mlogloss:0.84067                             \n",
      "[400]\ttrain-mlogloss:0.50098\tvalidate-mlogloss:0.83492                             \n",
      "[600]\ttrain-mlogloss:0.39918\tvalidate-mlogloss:0.83850                             \n",
      "[787]\ttrain-mlogloss:0.32905\tvalidate-mlogloss:0.84701                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06796\tvalidate-mlogloss:1.07036                               \n",
      "[200]\ttrain-mlogloss:0.64578\tvalidate-mlogloss:0.85431                             \n",
      "[400]\ttrain-mlogloss:0.50144\tvalidate-mlogloss:0.84454                             \n",
      "[600]\ttrain-mlogloss:0.39890\tvalidate-mlogloss:0.84977                             \n",
      "[763]\ttrain-mlogloss:0.33772\tvalidate-mlogloss:0.85822                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.06842\tvalidate-mlogloss:1.07098                               \n",
      "[200]\ttrain-mlogloss:0.64571\tvalidate-mlogloss:0.85742                             \n",
      "[400]\ttrain-mlogloss:0.50169\tvalidate-mlogloss:0.84999                             \n",
      "[600]\ttrain-mlogloss:0.39965\tvalidate-mlogloss:0.85282                             \n",
      "[781]\ttrain-mlogloss:0.33183\tvalidate-mlogloss:0.85909                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8547716166055056                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.9, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 1, 'learning_rate': 0.23097959494929016, 'max_delta_step': 9, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1909, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.05356\tvalidate-mlogloss:1.05249                               \n",
      "[200]\ttrain-mlogloss:0.88041\tvalidate-mlogloss:0.87745                             \n",
      "[400]\ttrain-mlogloss:0.87976\tvalidate-mlogloss:0.87726                             \n",
      "[600]\ttrain-mlogloss:0.87954\tvalidate-mlogloss:0.87719                             \n",
      "[800]\ttrain-mlogloss:0.87922\tvalidate-mlogloss:0.87700                             \n",
      "[1000]\ttrain-mlogloss:0.87913\tvalidate-mlogloss:0.87657                            \n",
      "[1200]\ttrain-mlogloss:0.87847\tvalidate-mlogloss:0.87623                            \n",
      "[1400]\ttrain-mlogloss:0.87834\tvalidate-mlogloss:0.87609                            \n",
      "[1600]\ttrain-mlogloss:0.87827\tvalidate-mlogloss:0.87638                            \n",
      "[1800]\ttrain-mlogloss:0.87821\tvalidate-mlogloss:0.87629                            \n",
      "[1908]\ttrain-mlogloss:0.87794\tvalidate-mlogloss:0.87596                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.05214\tvalidate-mlogloss:1.05223                               \n",
      "[200]\ttrain-mlogloss:0.87787\tvalidate-mlogloss:0.89329                             \n",
      "[400]\ttrain-mlogloss:0.87686\tvalidate-mlogloss:0.89512                             \n",
      "[467]\ttrain-mlogloss:0.87684\tvalidate-mlogloss:0.89527                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.05293\tvalidate-mlogloss:1.05553                               \n",
      "[200]\ttrain-mlogloss:0.87612\tvalidate-mlogloss:0.89217                             \n",
      "[400]\ttrain-mlogloss:0.87585\tvalidate-mlogloss:0.89197                             \n",
      "[600]\ttrain-mlogloss:0.87534\tvalidate-mlogloss:0.89144                             \n",
      "[800]\ttrain-mlogloss:0.87507\tvalidate-mlogloss:0.89156                             \n",
      "[1000]\ttrain-mlogloss:0.87487\tvalidate-mlogloss:0.89153                            \n",
      "[1095]\ttrain-mlogloss:0.87485\tvalidate-mlogloss:0.89185                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8876271537176667                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 1, 'learning_rate': 0.06582627070278273, 'max_delta_step': 6, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1229, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08360\tvalidate-mlogloss:1.08352                               \n",
      "[200]\ttrain-mlogloss:0.81687\tvalidate-mlogloss:0.86594                             \n",
      "[400]\ttrain-mlogloss:0.81687\tvalidate-mlogloss:0.86594                             \n",
      "[525]\ttrain-mlogloss:0.81687\tvalidate-mlogloss:0.86594                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08254\tvalidate-mlogloss:1.08348                               \n",
      "[200]\ttrain-mlogloss:0.81132\tvalidate-mlogloss:0.87574                             \n",
      "[400]\ttrain-mlogloss:0.81132\tvalidate-mlogloss:0.87574                             \n",
      "[542]\ttrain-mlogloss:0.81132\tvalidate-mlogloss:0.87574                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08301\tvalidate-mlogloss:1.08427                               \n",
      "[200]\ttrain-mlogloss:0.81106\tvalidate-mlogloss:0.87641                             \n",
      "[400]\ttrain-mlogloss:0.81106\tvalidate-mlogloss:0.87641                             \n",
      "[524]\ttrain-mlogloss:0.81106\tvalidate-mlogloss:0.87641                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8726935821250682                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.21253524736628426, 'max_delta_step': 6, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1079, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.04303\tvalidate-mlogloss:1.05254                                \n",
      "[200]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                              \n",
      "[400]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                              \n",
      "[600]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                              \n",
      "[800]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                              \n",
      "[1000]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                             \n",
      "[1078]\ttrain-mlogloss:0.68535\tvalidate-mlogloss:0.84693                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.04614\tvalidate-mlogloss:1.05458                                \n",
      "[200]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                              \n",
      "[400]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                              \n",
      "[600]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                              \n",
      "[800]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                              \n",
      "[1000]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                             \n",
      "[1078]\ttrain-mlogloss:0.67945\tvalidate-mlogloss:0.85421                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.04324\tvalidate-mlogloss:1.05349                                \n",
      "[200]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                              \n",
      "[400]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                              \n",
      "[600]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                              \n",
      "[800]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                              \n",
      "[1000]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                             \n",
      "[1078]\ttrain-mlogloss:0.67929\tvalidate-mlogloss:0.85964                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8535920409830867                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.7, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.21432045723309712, 'max_delta_step': 2, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1850, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.05535\tvalidate-mlogloss:1.05372                                \n",
      "[200]\ttrain-mlogloss:0.70087\tvalidate-mlogloss:0.85596                              \n",
      "[400]\ttrain-mlogloss:0.61327\tvalidate-mlogloss:0.85355                              \n",
      "[600]\ttrain-mlogloss:0.56191\tvalidate-mlogloss:0.84996                              \n",
      "[800]\ttrain-mlogloss:0.52950\tvalidate-mlogloss:0.85080                              \n",
      "[1000]\ttrain-mlogloss:0.50845\tvalidate-mlogloss:0.85008                             \n",
      "[1050]\ttrain-mlogloss:0.50419\tvalidate-mlogloss:0.85071                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06128\tvalidate-mlogloss:1.05869                                \n",
      "[200]\ttrain-mlogloss:0.69335\tvalidate-mlogloss:0.87178                              \n",
      "[400]\ttrain-mlogloss:0.60427\tvalidate-mlogloss:0.86822                              \n",
      "[600]\ttrain-mlogloss:0.55503\tvalidate-mlogloss:0.86447                              \n",
      "[800]\ttrain-mlogloss:0.52508\tvalidate-mlogloss:0.86435                              \n",
      "[1000]\ttrain-mlogloss:0.50541\tvalidate-mlogloss:0.86591                             \n",
      "[1076]\ttrain-mlogloss:0.49936\tvalidate-mlogloss:0.86435                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05371\tvalidate-mlogloss:1.05512                                \n",
      "[200]\ttrain-mlogloss:0.69365\tvalidate-mlogloss:0.86942                              \n",
      "[400]\ttrain-mlogloss:0.60672\tvalidate-mlogloss:0.86749                              \n",
      "[600]\ttrain-mlogloss:0.55582\tvalidate-mlogloss:0.86746                              \n",
      "[800]\ttrain-mlogloss:0.52466\tvalidate-mlogloss:0.86412                              \n",
      "[1000]\ttrain-mlogloss:0.50394\tvalidate-mlogloss:0.86357                             \n",
      "[1200]\ttrain-mlogloss:0.48871\tvalidate-mlogloss:0.86642                             \n",
      "[1253]\ttrain-mlogloss:0.48560\tvalidate-mlogloss:0.86676                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.860603441214713                                                 \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 1.0, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 10, 'learning_rate': 0.25263483667202163, 'max_delta_step': 7, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1990, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.04227\tvalidate-mlogloss:1.04337                                \n",
      "[200]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                              \n",
      "[400]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                              \n",
      "[600]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                              \n",
      "[800]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                              \n",
      "[1000]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "[1200]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "[1400]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "[1600]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "[1800]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "[1989]\ttrain-mlogloss:0.81525\tvalidate-mlogloss:0.86641                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.04231\tvalidate-mlogloss:1.04559                                \n",
      "[200]\ttrain-mlogloss:0.81182\tvalidate-mlogloss:0.87913                              \n",
      "[400]\ttrain-mlogloss:0.81182\tvalidate-mlogloss:0.87913                              \n",
      "[425]\ttrain-mlogloss:0.81182\tvalidate-mlogloss:0.87913                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.04120\tvalidate-mlogloss:1.04728                                \n",
      "[200]\ttrain-mlogloss:0.81044\tvalidate-mlogloss:0.88092                              \n",
      "[400]\ttrain-mlogloss:0.81044\tvalidate-mlogloss:0.88092                              \n",
      "[587]\ttrain-mlogloss:0.81044\tvalidate-mlogloss:0.88092                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8754878364836424                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 10, 'learning_rate': 0.0864195210543403, 'max_delta_step': 7, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 838, 'num_feat': 70, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08001\tvalidate-mlogloss:1.07897                                \n",
      "[200]\ttrain-mlogloss:0.81456\tvalidate-mlogloss:0.86118                              \n",
      "[400]\ttrain-mlogloss:0.79969\tvalidate-mlogloss:0.85850                              \n",
      "[600]\ttrain-mlogloss:0.79087\tvalidate-mlogloss:0.85729                              \n",
      "[800]\ttrain-mlogloss:0.78530\tvalidate-mlogloss:0.85635                              \n",
      "[837]\ttrain-mlogloss:0.78445\tvalidate-mlogloss:0.85600                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08117\tvalidate-mlogloss:1.08124                                \n",
      "[200]\ttrain-mlogloss:0.81453\tvalidate-mlogloss:0.87318                              \n",
      "[400]\ttrain-mlogloss:0.80091\tvalidate-mlogloss:0.86986                              \n",
      "[600]\ttrain-mlogloss:0.79408\tvalidate-mlogloss:0.86853                              \n",
      "[800]\ttrain-mlogloss:0.79028\tvalidate-mlogloss:0.86832                              \n",
      "[837]\ttrain-mlogloss:0.78975\tvalidate-mlogloss:0.86812                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07966\tvalidate-mlogloss:1.08094                                \n",
      "[200]\ttrain-mlogloss:0.80974\tvalidate-mlogloss:0.87845                              \n",
      "[400]\ttrain-mlogloss:0.79526\tvalidate-mlogloss:0.87442                              \n",
      "[600]\ttrain-mlogloss:0.78733\tvalidate-mlogloss:0.87296                              \n",
      "[800]\ttrain-mlogloss:0.78261\tvalidate-mlogloss:0.87321                              \n",
      "[837]\ttrain-mlogloss:0.78186\tvalidate-mlogloss:0.87307                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8657269267662607                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 1.0, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 10, 'learning_rate': 0.09595713639926717, 'max_delta_step': 8, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1597, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08049\tvalidate-mlogloss:1.07862                                \n",
      "[200]\ttrain-mlogloss:0.89389\tvalidate-mlogloss:0.88096                              \n",
      "[400]\ttrain-mlogloss:0.89102\tvalidate-mlogloss:0.87951                              \n",
      "[600]\ttrain-mlogloss:0.88930\tvalidate-mlogloss:0.87841                              \n",
      "[800]\ttrain-mlogloss:0.88822\tvalidate-mlogloss:0.87808                              \n",
      "[1000]\ttrain-mlogloss:0.88760\tvalidate-mlogloss:0.87706                             \n",
      "[1200]\ttrain-mlogloss:0.88639\tvalidate-mlogloss:0.87646                             \n",
      "[1400]\ttrain-mlogloss:0.88601\tvalidate-mlogloss:0.87655                             \n",
      "[1596]\ttrain-mlogloss:0.88541\tvalidate-mlogloss:0.87645                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08147\tvalidate-mlogloss:1.08042                                \n",
      "[200]\ttrain-mlogloss:0.88919\tvalidate-mlogloss:0.89437                              \n",
      "[400]\ttrain-mlogloss:0.88599\tvalidate-mlogloss:0.89416                              \n",
      "[600]\ttrain-mlogloss:0.88414\tvalidate-mlogloss:0.89325                              \n",
      "[800]\ttrain-mlogloss:0.88328\tvalidate-mlogloss:0.89340                              \n",
      "[1000]\ttrain-mlogloss:0.88277\tvalidate-mlogloss:0.89352                             \n",
      "[1146]\ttrain-mlogloss:0.88214\tvalidate-mlogloss:0.89343                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07964\tvalidate-mlogloss:1.07941                                \n",
      "[200]\ttrain-mlogloss:0.88645\tvalidate-mlogloss:0.89602                              \n",
      "[400]\ttrain-mlogloss:0.88310\tvalidate-mlogloss:0.89517                              \n",
      "[600]\ttrain-mlogloss:0.88188\tvalidate-mlogloss:0.89425                              \n",
      "[800]\ttrain-mlogloss:0.88091\tvalidate-mlogloss:0.89512                              \n",
      "[1000]\ttrain-mlogloss:0.87996\tvalidate-mlogloss:0.89479                             \n",
      "[1011]\ttrain-mlogloss:0.87993\tvalidate-mlogloss:0.89497                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8882534897710633                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 1.0, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 10, 'learning_rate': 0.0016991977990888669, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1226, 'num_feat': 80, 'step': 0.3}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09817\tvalidate-mlogloss:1.09821                                \n",
      "[200]\ttrain-mlogloss:1.02436\tvalidate-mlogloss:1.02982                              \n",
      "[400]\ttrain-mlogloss:0.97282\tvalidate-mlogloss:0.98423                              \n",
      "[600]\ttrain-mlogloss:0.93566\tvalidate-mlogloss:0.95291                              \n",
      "[800]\ttrain-mlogloss:0.90737\tvalidate-mlogloss:0.93055                              \n",
      "[1000]\ttrain-mlogloss:0.88520\tvalidate-mlogloss:0.91434                             \n",
      "[1200]\ttrain-mlogloss:0.86746\tvalidate-mlogloss:0.90221                             \n",
      "[1225]\ttrain-mlogloss:0.86548\tvalidate-mlogloss:0.90088                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09816\tvalidate-mlogloss:1.09820                                \n",
      "[200]\ttrain-mlogloss:1.02274\tvalidate-mlogloss:1.03174                              \n",
      "[400]\ttrain-mlogloss:0.96998\tvalidate-mlogloss:0.98697                              \n",
      "[600]\ttrain-mlogloss:0.93229\tvalidate-mlogloss:0.95644                              \n",
      "[800]\ttrain-mlogloss:0.90384\tvalidate-mlogloss:0.93483                              \n",
      "[1000]\ttrain-mlogloss:0.88162\tvalidate-mlogloss:0.91899                             \n",
      "[1200]\ttrain-mlogloss:0.86408\tvalidate-mlogloss:0.90723                             \n",
      "[1225]\ttrain-mlogloss:0.86209\tvalidate-mlogloss:0.90598                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09814\tvalidate-mlogloss:1.09822                                \n",
      "[200]\ttrain-mlogloss:1.02159\tvalidate-mlogloss:1.03319                              \n",
      "[400]\ttrain-mlogloss:0.96844\tvalidate-mlogloss:0.98966                              \n",
      "[600]\ttrain-mlogloss:0.93025\tvalidate-mlogloss:0.95968                              \n",
      "[800]\ttrain-mlogloss:0.90153\tvalidate-mlogloss:0.93841                              \n",
      "[1000]\ttrain-mlogloss:0.87947\tvalidate-mlogloss:0.92307                             \n",
      "[1200]\ttrain-mlogloss:0.86175\tvalidate-mlogloss:0.91169                             \n",
      "[1225]\ttrain-mlogloss:0.85977\tvalidate-mlogloss:0.91046                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.9057722708241979                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 10, 'learning_rate': 0.09298811302483101, 'max_delta_step': 4, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1371, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07899\tvalidate-mlogloss:1.07895                                \n",
      "[200]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                              \n",
      "[400]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                              \n",
      "[600]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                              \n",
      "[800]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                              \n",
      "[1000]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                             \n",
      "[1012]\ttrain-mlogloss:0.89040\tvalidate-mlogloss:0.88453                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07948\tvalidate-mlogloss:1.07923                                \n",
      "[200]\ttrain-mlogloss:0.88841\tvalidate-mlogloss:0.89413                              \n",
      "[400]\ttrain-mlogloss:0.88841\tvalidate-mlogloss:0.89413                              \n",
      "[600]\ttrain-mlogloss:0.88841\tvalidate-mlogloss:0.89413                              \n",
      "[671]\ttrain-mlogloss:0.88841\tvalidate-mlogloss:0.89413                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.08017\tvalidate-mlogloss:1.08024                                \n",
      "[200]\ttrain-mlogloss:0.88771\tvalidate-mlogloss:0.89658                              \n",
      "[400]\ttrain-mlogloss:0.88771\tvalidate-mlogloss:0.89658                              \n",
      "[600]\ttrain-mlogloss:0.88771\tvalidate-mlogloss:0.89658                              \n",
      "[669]\ttrain-mlogloss:0.88771\tvalidate-mlogloss:0.89658                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8917466317813734                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 1.0, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 10, 'learning_rate': 0.27941315845648657, 'max_delta_step': 8, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1572, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.04027\tvalidate-mlogloss:1.03978                                \n",
      "[200]\ttrain-mlogloss:0.85057\tvalidate-mlogloss:0.87033                              \n",
      "[400]\ttrain-mlogloss:0.84148\tvalidate-mlogloss:0.86772                              \n",
      "[600]\ttrain-mlogloss:0.83633\tvalidate-mlogloss:0.86704                              \n",
      "[800]\ttrain-mlogloss:0.83368\tvalidate-mlogloss:0.86696                              \n",
      "[1000]\ttrain-mlogloss:0.82937\tvalidate-mlogloss:0.86418                             \n",
      "[1200]\ttrain-mlogloss:0.82769\tvalidate-mlogloss:0.86258                             \n",
      "[1400]\ttrain-mlogloss:0.82551\tvalidate-mlogloss:0.86145                             \n",
      "[1571]\ttrain-mlogloss:0.82314\tvalidate-mlogloss:0.86131                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.03736\tvalidate-mlogloss:1.03932                                \n",
      "[200]\ttrain-mlogloss:0.84147\tvalidate-mlogloss:0.89292                              \n",
      "[400]\ttrain-mlogloss:0.83491\tvalidate-mlogloss:0.89250                              \n",
      "[600]\ttrain-mlogloss:0.83049\tvalidate-mlogloss:0.89097                              \n",
      "[800]\ttrain-mlogloss:0.82694\tvalidate-mlogloss:0.88904                              \n",
      "[1000]\ttrain-mlogloss:0.82509\tvalidate-mlogloss:0.88740                             \n",
      "[1200]\ttrain-mlogloss:0.82304\tvalidate-mlogloss:0.88621                             \n",
      "[1400]\ttrain-mlogloss:0.82095\tvalidate-mlogloss:0.88717                             \n",
      "[1571]\ttrain-mlogloss:0.81982\tvalidate-mlogloss:0.88681                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.03865\tvalidate-mlogloss:1.04017                                \n",
      "[200]\ttrain-mlogloss:0.84347\tvalidate-mlogloss:0.88842                              \n",
      "[400]\ttrain-mlogloss:0.83526\tvalidate-mlogloss:0.88425                              \n",
      "[600]\ttrain-mlogloss:0.83070\tvalidate-mlogloss:0.88255                              \n",
      "[800]\ttrain-mlogloss:0.82752\tvalidate-mlogloss:0.88198                              \n",
      "[1000]\ttrain-mlogloss:0.82559\tvalidate-mlogloss:0.88151                             \n",
      "[1200]\ttrain-mlogloss:0.82357\tvalidate-mlogloss:0.88280                             \n",
      "[1400]\ttrain-mlogloss:0.82136\tvalidate-mlogloss:0.88249                             \n",
      "[1443]\ttrain-mlogloss:0.82073\tvalidate-mlogloss:0.88218                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8767667555191939                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 1, 'learning_rate': 0.22036608505028193, 'max_delta_step': 5, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1180, 'num_feat': 50, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.06184\tvalidate-mlogloss:1.05921                                \n",
      "[200]\ttrain-mlogloss:0.90240\tvalidate-mlogloss:0.89980                              \n",
      "[400]\ttrain-mlogloss:0.89934\tvalidate-mlogloss:0.89777                              \n",
      "[600]\ttrain-mlogloss:0.89736\tvalidate-mlogloss:0.89768                              \n",
      "[800]\ttrain-mlogloss:0.89580\tvalidate-mlogloss:0.89649                              \n",
      "[1000]\ttrain-mlogloss:0.89498\tvalidate-mlogloss:0.89514                             \n",
      "[1179]\ttrain-mlogloss:0.89368\tvalidate-mlogloss:0.89431                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06436\tvalidate-mlogloss:1.06247                                \n",
      "[200]\ttrain-mlogloss:0.89978\tvalidate-mlogloss:0.90295                              \n",
      "[400]\ttrain-mlogloss:0.89740\tvalidate-mlogloss:0.90024                              \n",
      "[600]\ttrain-mlogloss:0.89538\tvalidate-mlogloss:0.89975                              \n",
      "[800]\ttrain-mlogloss:0.89427\tvalidate-mlogloss:0.89907                              \n",
      "[1000]\ttrain-mlogloss:0.89325\tvalidate-mlogloss:0.89911                             \n",
      "[1179]\ttrain-mlogloss:0.89294\tvalidate-mlogloss:0.89981                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.06096\tvalidate-mlogloss:1.05943                                \n",
      "[200]\ttrain-mlogloss:0.89703\tvalidate-mlogloss:0.88941                              \n",
      "[400]\ttrain-mlogloss:0.89434\tvalidate-mlogloss:0.88813                              \n",
      "[600]\ttrain-mlogloss:0.89290\tvalidate-mlogloss:0.88757                              \n",
      "[800]\ttrain-mlogloss:0.89104\tvalidate-mlogloss:0.88598                              \n",
      "[1000]\ttrain-mlogloss:0.89034\tvalidate-mlogloss:0.88465                             \n",
      "[1179]\ttrain-mlogloss:0.88955\tvalidate-mlogloss:0.88500                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8930388837096642                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.9, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 1, 'learning_rate': 0.06989637985617067, 'max_delta_step': 3, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 882, 'num_feat': 50, 'step': 0.3}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08361\tvalidate-mlogloss:1.08367                                \n",
      "[200]\ttrain-mlogloss:0.88125\tvalidate-mlogloss:0.88189                              \n",
      "[400]\ttrain-mlogloss:0.87680\tvalidate-mlogloss:0.88017                              \n",
      "[600]\ttrain-mlogloss:0.87405\tvalidate-mlogloss:0.87891                              \n",
      "[800]\ttrain-mlogloss:0.87264\tvalidate-mlogloss:0.87860                              \n",
      "[881]\ttrain-mlogloss:0.87180\tvalidate-mlogloss:0.87818                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08254\tvalidate-mlogloss:1.08345                                \n",
      "[200]\ttrain-mlogloss:0.87499\tvalidate-mlogloss:0.89051                              \n",
      "[400]\ttrain-mlogloss:0.87111\tvalidate-mlogloss:0.88885                              \n",
      "[600]\ttrain-mlogloss:0.86903\tvalidate-mlogloss:0.88721                              \n",
      "[800]\ttrain-mlogloss:0.86769\tvalidate-mlogloss:0.88766                              \n",
      "[881]\ttrain-mlogloss:0.86704\tvalidate-mlogloss:0.88677                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.08454\tvalidate-mlogloss:1.08496                                \n",
      "[200]\ttrain-mlogloss:0.87470\tvalidate-mlogloss:0.89104                              \n",
      "[400]\ttrain-mlogloss:0.87043\tvalidate-mlogloss:0.88914                              \n",
      "[600]\ttrain-mlogloss:0.86880\tvalidate-mlogloss:0.88931                              \n",
      "[800]\ttrain-mlogloss:0.86721\tvalidate-mlogloss:0.88905                              \n",
      "[806]\ttrain-mlogloss:0.86718\tvalidate-mlogloss:0.88901                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.884691775800824                                                 \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 10, 'learning_rate': 0.13087634919783453, 'max_delta_step': 6, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1206, 'num_feat': 60, 'step': 0.3}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07550\tvalidate-mlogloss:1.07501                                \n",
      "[200]\ttrain-mlogloss:0.87561\tvalidate-mlogloss:0.88567                              \n",
      "[400]\ttrain-mlogloss:0.85834\tvalidate-mlogloss:0.88044                              \n",
      "[600]\ttrain-mlogloss:0.84616\tvalidate-mlogloss:0.87590                              \n",
      "[800]\ttrain-mlogloss:0.83561\tvalidate-mlogloss:0.87278                              \n",
      "[1000]\ttrain-mlogloss:0.82675\tvalidate-mlogloss:0.86933                             \n",
      "[1200]\ttrain-mlogloss:0.81941\tvalidate-mlogloss:0.86603                             \n",
      "[1205]\ttrain-mlogloss:0.81928\tvalidate-mlogloss:0.86655                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07492\tvalidate-mlogloss:1.07744                                \n",
      "[200]\ttrain-mlogloss:0.87295\tvalidate-mlogloss:0.90005                              \n",
      "[400]\ttrain-mlogloss:0.85592\tvalidate-mlogloss:0.89432                              \n",
      "[600]\ttrain-mlogloss:0.84388\tvalidate-mlogloss:0.89018                              \n",
      "[800]\ttrain-mlogloss:0.83367\tvalidate-mlogloss:0.88622                              \n",
      "[1000]\ttrain-mlogloss:0.82470\tvalidate-mlogloss:0.88363                             \n",
      "[1200]\ttrain-mlogloss:0.81680\tvalidate-mlogloss:0.88142                             \n",
      "[1205]\ttrain-mlogloss:0.81669\tvalidate-mlogloss:0.88157                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07795\tvalidate-mlogloss:1.07771                                \n",
      "[200]\ttrain-mlogloss:0.87351\tvalidate-mlogloss:0.89710                              \n",
      "[400]\ttrain-mlogloss:0.85686\tvalidate-mlogloss:0.89288                              \n",
      "[600]\ttrain-mlogloss:0.84486\tvalidate-mlogloss:0.88929                              \n",
      "[800]\ttrain-mlogloss:0.83488\tvalidate-mlogloss:0.88783                              \n",
      "[1000]\ttrain-mlogloss:0.82612\tvalidate-mlogloss:0.88582                             \n",
      "[1200]\ttrain-mlogloss:0.81862\tvalidate-mlogloss:0.88421                             \n",
      "[1205]\ttrain-mlogloss:0.81834\tvalidate-mlogloss:0.88399                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8773667664704132                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.19108773508200538, 'max_delta_step': 1, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1661, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.05763\tvalidate-mlogloss:1.06013                                \n",
      "[200]\ttrain-mlogloss:0.60593\tvalidate-mlogloss:0.84388                              \n",
      "[400]\ttrain-mlogloss:0.54318\tvalidate-mlogloss:0.83768                              \n",
      "[600]\ttrain-mlogloss:0.51918\tvalidate-mlogloss:0.83579                              \n",
      "[800]\ttrain-mlogloss:0.50511\tvalidate-mlogloss:0.83584                              \n",
      "[1000]\ttrain-mlogloss:0.49532\tvalidate-mlogloss:0.83664                             \n",
      "[1051]\ttrain-mlogloss:0.49368\tvalidate-mlogloss:0.83684                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.05574\tvalidate-mlogloss:1.05998                                \n",
      "[200]\ttrain-mlogloss:0.60248\tvalidate-mlogloss:0.85000                              \n",
      "[400]\ttrain-mlogloss:0.54094\tvalidate-mlogloss:0.84249                              \n",
      "[600]\ttrain-mlogloss:0.51594\tvalidate-mlogloss:0.84223                              \n",
      "[800]\ttrain-mlogloss:0.50323\tvalidate-mlogloss:0.84244                              \n",
      "[943]\ttrain-mlogloss:0.49719\tvalidate-mlogloss:0.84217                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05746\tvalidate-mlogloss:1.05742                                \n",
      "[200]\ttrain-mlogloss:0.60243\tvalidate-mlogloss:0.84324                              \n",
      "[400]\ttrain-mlogloss:0.54032\tvalidate-mlogloss:0.83901                              \n",
      "[600]\ttrain-mlogloss:0.51547\tvalidate-mlogloss:0.83854                              \n",
      "[800]\ttrain-mlogloss:0.50207\tvalidate-mlogloss:0.83748                              \n",
      "[1000]\ttrain-mlogloss:0.49341\tvalidate-mlogloss:0.83845                             \n",
      "[1200]\ttrain-mlogloss:0.48672\tvalidate-mlogloss:0.83913                             \n",
      "[1206]\ttrain-mlogloss:0.48665\tvalidate-mlogloss:0.83908                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8393530623936671                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.19701957976305542, 'max_delta_step': 6, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1087, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.05364\tvalidate-mlogloss:1.05664                                \n",
      "[200]\ttrain-mlogloss:0.56465\tvalidate-mlogloss:0.83829                              \n",
      "[400]\ttrain-mlogloss:0.50488\tvalidate-mlogloss:0.83558                              \n",
      "[600]\ttrain-mlogloss:0.48078\tvalidate-mlogloss:0.83462                              \n",
      "[800]\ttrain-mlogloss:0.46842\tvalidate-mlogloss:0.83552                              \n",
      "[868]\ttrain-mlogloss:0.46510\tvalidate-mlogloss:0.83567                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.05280\tvalidate-mlogloss:1.05736                                \n",
      "[200]\ttrain-mlogloss:0.55736\tvalidate-mlogloss:0.84410                              \n",
      "[400]\ttrain-mlogloss:0.49798\tvalidate-mlogloss:0.84224                              \n",
      "[600]\ttrain-mlogloss:0.47610\tvalidate-mlogloss:0.84245                              \n",
      "[800]\ttrain-mlogloss:0.46325\tvalidate-mlogloss:0.84425                              \n",
      "[819]\ttrain-mlogloss:0.46196\tvalidate-mlogloss:0.84432                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05379\tvalidate-mlogloss:1.05570                                \n",
      "[200]\ttrain-mlogloss:0.55893\tvalidate-mlogloss:0.84272                              \n",
      "[400]\ttrain-mlogloss:0.49799\tvalidate-mlogloss:0.83919                              \n",
      "[600]\ttrain-mlogloss:0.47563\tvalidate-mlogloss:0.83849                              \n",
      "[800]\ttrain-mlogloss:0.46283\tvalidate-mlogloss:0.83954                              \n",
      "[961]\ttrain-mlogloss:0.45704\tvalidate-mlogloss:0.83950                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8398148457371016                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 100, 'learning_rate': 0.18618321393271978, 'max_delta_step': 1, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1958, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.06574\tvalidate-mlogloss:1.06349                                \n",
      "[200]\ttrain-mlogloss:0.88688\tvalidate-mlogloss:0.88364                              \n",
      "[400]\ttrain-mlogloss:0.88208\tvalidate-mlogloss:0.88217                              \n",
      "[600]\ttrain-mlogloss:0.87918\tvalidate-mlogloss:0.88133                              \n",
      "[800]\ttrain-mlogloss:0.87767\tvalidate-mlogloss:0.88126                              \n",
      "[1000]\ttrain-mlogloss:0.87661\tvalidate-mlogloss:0.88015                             \n",
      "[1200]\ttrain-mlogloss:0.87552\tvalidate-mlogloss:0.87841                             \n",
      "[1400]\ttrain-mlogloss:0.87432\tvalidate-mlogloss:0.87908                             \n",
      "[1600]\ttrain-mlogloss:0.87348\tvalidate-mlogloss:0.87950                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06705\tvalidate-mlogloss:1.06461                                \n",
      "[200]\ttrain-mlogloss:0.88127\tvalidate-mlogloss:0.89437                              \n",
      "[400]\ttrain-mlogloss:0.87701\tvalidate-mlogloss:0.89541                              \n",
      "[495]\ttrain-mlogloss:0.87611\tvalidate-mlogloss:0.89600                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.06539\tvalidate-mlogloss:1.06421                                \n",
      "[200]\ttrain-mlogloss:0.88042\tvalidate-mlogloss:0.88141                              \n",
      "[400]\ttrain-mlogloss:0.87630\tvalidate-mlogloss:0.87966                              \n",
      "[600]\ttrain-mlogloss:0.87372\tvalidate-mlogloss:0.87875                              \n",
      "[800]\ttrain-mlogloss:0.87249\tvalidate-mlogloss:0.87811                              \n",
      "[1000]\ttrain-mlogloss:0.87145\tvalidate-mlogloss:0.87792                             \n",
      "[1200]\ttrain-mlogloss:0.87007\tvalidate-mlogloss:0.87856                             \n",
      "[1400]\ttrain-mlogloss:0.86931\tvalidate-mlogloss:0.87760                             \n",
      "[1600]\ttrain-mlogloss:0.86845\tvalidate-mlogloss:0.87742                             \n",
      "[1800]\ttrain-mlogloss:0.86783\tvalidate-mlogloss:0.87869                             \n",
      "[1957]\ttrain-mlogloss:0.86710\tvalidate-mlogloss:0.87737                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.884371150335579                                                 \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.1920398099633152, 'max_delta_step': 6, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 647, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.05853\tvalidate-mlogloss:1.06000                                \n",
      "[200]\ttrain-mlogloss:0.65638\tvalidate-mlogloss:0.84844                              \n",
      "[400]\ttrain-mlogloss:0.59740\tvalidate-mlogloss:0.84209                              \n",
      "[600]\ttrain-mlogloss:0.56916\tvalidate-mlogloss:0.83832                              \n",
      "[646]\ttrain-mlogloss:0.56507\tvalidate-mlogloss:0.83870                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06090\tvalidate-mlogloss:1.06151                                \n",
      "[200]\ttrain-mlogloss:0.65028\tvalidate-mlogloss:0.85504                              \n",
      "[400]\ttrain-mlogloss:0.59138\tvalidate-mlogloss:0.84545                              \n",
      "[600]\ttrain-mlogloss:0.56664\tvalidate-mlogloss:0.84315                              \n",
      "[646]\ttrain-mlogloss:0.56356\tvalidate-mlogloss:0.84359                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05967\tvalidate-mlogloss:1.06033                                \n",
      "[200]\ttrain-mlogloss:0.64746\tvalidate-mlogloss:0.85237                              \n",
      "[400]\ttrain-mlogloss:0.59315\tvalidate-mlogloss:0.84786                              \n",
      "[600]\ttrain-mlogloss:0.56537\tvalidate-mlogloss:0.84455                              \n",
      "[646]\ttrain-mlogloss:0.56221\tvalidate-mlogloss:0.84559                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8426234941789407                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.2509188324386218, 'max_delta_step': 3, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 653, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.04244\tvalidate-mlogloss:1.04614                                \n",
      "[200]\ttrain-mlogloss:0.53629\tvalidate-mlogloss:0.84087                              \n",
      "[400]\ttrain-mlogloss:0.48644\tvalidate-mlogloss:0.84125                              \n",
      "[600]\ttrain-mlogloss:0.46580\tvalidate-mlogloss:0.84055                              \n",
      "[649]\ttrain-mlogloss:0.46230\tvalidate-mlogloss:0.84074                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.04139\tvalidate-mlogloss:1.04704                                \n",
      "[200]\ttrain-mlogloss:0.53346\tvalidate-mlogloss:0.84795                              \n",
      "[400]\ttrain-mlogloss:0.48214\tvalidate-mlogloss:0.84654                              \n",
      "[600]\ttrain-mlogloss:0.46326\tvalidate-mlogloss:0.84846                              \n",
      "[637]\ttrain-mlogloss:0.46068\tvalidate-mlogloss:0.84895                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.04262\tvalidate-mlogloss:1.04505                                \n",
      "[200]\ttrain-mlogloss:0.53582\tvalidate-mlogloss:0.84406                              \n",
      "[400]\ttrain-mlogloss:0.48079\tvalidate-mlogloss:0.84277                              \n",
      "[600]\ttrain-mlogloss:0.46366\tvalidate-mlogloss:0.84329                              \n",
      "[652]\ttrain-mlogloss:0.45980\tvalidate-mlogloss:0.84371                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8445260555841667                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.14944879172392989, 'max_delta_step': 6, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1992, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.06382\tvalidate-mlogloss:1.06766                                \n",
      "[200]\ttrain-mlogloss:0.59728\tvalidate-mlogloss:0.84197                              \n",
      "[400]\ttrain-mlogloss:0.52396\tvalidate-mlogloss:0.83733                              \n",
      "[600]\ttrain-mlogloss:0.49610\tvalidate-mlogloss:0.83573                              \n",
      "[800]\ttrain-mlogloss:0.48260\tvalidate-mlogloss:0.83649                              \n",
      "[954]\ttrain-mlogloss:0.47448\tvalidate-mlogloss:0.83688                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06379\tvalidate-mlogloss:1.06689                                \n",
      "[200]\ttrain-mlogloss:0.59213\tvalidate-mlogloss:0.84671                              \n",
      "[400]\ttrain-mlogloss:0.51970\tvalidate-mlogloss:0.83896                              \n",
      "[600]\ttrain-mlogloss:0.49292\tvalidate-mlogloss:0.83719                              \n",
      "[800]\ttrain-mlogloss:0.47756\tvalidate-mlogloss:0.83745                              \n",
      "[960]\ttrain-mlogloss:0.47056\tvalidate-mlogloss:0.83742                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.06350\tvalidate-mlogloss:1.06491                                \n",
      "[200]\ttrain-mlogloss:0.58948\tvalidate-mlogloss:0.84516                              \n",
      "[400]\ttrain-mlogloss:0.51699\tvalidate-mlogloss:0.83865                              \n",
      "[600]\ttrain-mlogloss:0.49052\tvalidate-mlogloss:0.83700                              \n",
      "[800]\ttrain-mlogloss:0.47650\tvalidate-mlogloss:0.83698                              \n",
      "[1000]\ttrain-mlogloss:0.46700\tvalidate-mlogloss:0.83781                             \n",
      "[1093]\ttrain-mlogloss:0.46360\tvalidate-mlogloss:0.83795                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8374215857520401                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 100, 'learning_rate': 0.1469327896470046, 'max_delta_step': 1, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1772, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07056\tvalidate-mlogloss:1.06992                                \n",
      "[200]\ttrain-mlogloss:0.88100\tvalidate-mlogloss:0.88146                              \n",
      "[400]\ttrain-mlogloss:0.87566\tvalidate-mlogloss:0.87939                              \n",
      "[600]\ttrain-mlogloss:0.87336\tvalidate-mlogloss:0.87898                              \n",
      "[800]\ttrain-mlogloss:0.87152\tvalidate-mlogloss:0.87968                              \n",
      "[1000]\ttrain-mlogloss:0.86966\tvalidate-mlogloss:0.87871                             \n",
      "[1200]\ttrain-mlogloss:0.86851\tvalidate-mlogloss:0.87796                             \n",
      "[1400]\ttrain-mlogloss:0.86744\tvalidate-mlogloss:0.87774                             \n",
      "[1600]\ttrain-mlogloss:0.86617\tvalidate-mlogloss:0.87794                             \n",
      "[1771]\ttrain-mlogloss:0.86550\tvalidate-mlogloss:0.87700                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07218\tvalidate-mlogloss:1.07125                                \n",
      "[200]\ttrain-mlogloss:0.87582\tvalidate-mlogloss:0.89038                              \n",
      "[400]\ttrain-mlogloss:0.87156\tvalidate-mlogloss:0.89199                              \n",
      "[571]\ttrain-mlogloss:0.86931\tvalidate-mlogloss:0.89169                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07073\tvalidate-mlogloss:1.06982                                \n",
      "[200]\ttrain-mlogloss:0.87440\tvalidate-mlogloss:0.88188                              \n",
      "[400]\ttrain-mlogloss:0.87016\tvalidate-mlogloss:0.88196                              \n",
      "[600]\ttrain-mlogloss:0.86842\tvalidate-mlogloss:0.88144                              \n",
      "[800]\ttrain-mlogloss:0.86648\tvalidate-mlogloss:0.87997                              \n",
      "[1000]\ttrain-mlogloss:0.86544\tvalidate-mlogloss:0.87966                             \n",
      "[1200]\ttrain-mlogloss:0.86423\tvalidate-mlogloss:0.88069                             \n",
      "[1400]\ttrain-mlogloss:0.86255\tvalidate-mlogloss:0.88006                             \n",
      "[1600]\ttrain-mlogloss:0.86172\tvalidate-mlogloss:0.87992                             \n",
      "[1631]\ttrain-mlogloss:0.86168\tvalidate-mlogloss:0.88055                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8831257796878701                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 10, 'learning_rate': 0.10875709168973807, 'max_delta_step': 2, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 549, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07452\tvalidate-mlogloss:1.07462                                \n",
      "[200]\ttrain-mlogloss:0.83655\tvalidate-mlogloss:0.87301                              \n",
      "[400]\ttrain-mlogloss:0.82896\tvalidate-mlogloss:0.87062                              \n",
      "[548]\ttrain-mlogloss:0.82538\tvalidate-mlogloss:0.87004                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07374\tvalidate-mlogloss:1.07488                                \n",
      "[200]\ttrain-mlogloss:0.83204\tvalidate-mlogloss:0.88430                              \n",
      "[400]\ttrain-mlogloss:0.82555\tvalidate-mlogloss:0.88247                              \n",
      "[548]\ttrain-mlogloss:0.82269\tvalidate-mlogloss:0.88139                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07354\tvalidate-mlogloss:1.07443                                \n",
      "[200]\ttrain-mlogloss:0.83030\tvalidate-mlogloss:0.87390                              \n",
      "[400]\ttrain-mlogloss:0.82037\tvalidate-mlogloss:0.87114                              \n",
      "[548]\ttrain-mlogloss:0.81841\tvalidate-mlogloss:0.87078                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8740708047597355                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.6, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.15784207758977317, 'max_delta_step': 1, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1661, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07336\tvalidate-mlogloss:1.07049                                \n",
      "[200]\ttrain-mlogloss:0.85398\tvalidate-mlogloss:0.87308                              \n",
      "[400]\ttrain-mlogloss:0.82061\tvalidate-mlogloss:0.86767                              \n",
      "[600]\ttrain-mlogloss:0.79497\tvalidate-mlogloss:0.86451                              \n",
      "[800]\ttrain-mlogloss:0.77340\tvalidate-mlogloss:0.86226                              \n",
      "[1000]\ttrain-mlogloss:0.75474\tvalidate-mlogloss:0.86067                             \n",
      "[1200]\ttrain-mlogloss:0.73814\tvalidate-mlogloss:0.85858                             \n",
      "[1400]\ttrain-mlogloss:0.72301\tvalidate-mlogloss:0.86030                             \n",
      "[1600]\ttrain-mlogloss:0.70912\tvalidate-mlogloss:0.86069                             \n",
      "[1660]\ttrain-mlogloss:0.70535\tvalidate-mlogloss:0.86000                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07363\tvalidate-mlogloss:1.07141                                \n",
      "[200]\ttrain-mlogloss:0.85214\tvalidate-mlogloss:0.89433                              \n",
      "[400]\ttrain-mlogloss:0.81780\tvalidate-mlogloss:0.88466                              \n",
      "[600]\ttrain-mlogloss:0.79172\tvalidate-mlogloss:0.87879                              \n",
      "[800]\ttrain-mlogloss:0.77035\tvalidate-mlogloss:0.87837                              \n",
      "[1000]\ttrain-mlogloss:0.75153\tvalidate-mlogloss:0.87714                             \n",
      "[1200]\ttrain-mlogloss:0.73485\tvalidate-mlogloss:0.87207                             \n",
      "[1400]\ttrain-mlogloss:0.72003\tvalidate-mlogloss:0.86830                             \n",
      "[1600]\ttrain-mlogloss:0.70628\tvalidate-mlogloss:0.86660                             \n",
      "[1660]\ttrain-mlogloss:0.70223\tvalidate-mlogloss:0.86841                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07386\tvalidate-mlogloss:1.07187                                \n",
      "[200]\ttrain-mlogloss:0.84975\tvalidate-mlogloss:0.87866                              \n",
      "[400]\ttrain-mlogloss:0.81632\tvalidate-mlogloss:0.87263                              \n",
      "[600]\ttrain-mlogloss:0.79066\tvalidate-mlogloss:0.87243                              \n",
      "[800]\ttrain-mlogloss:0.76893\tvalidate-mlogloss:0.86910                              \n",
      "[1000]\ttrain-mlogloss:0.75000\tvalidate-mlogloss:0.87193                             \n",
      "[1127]\ttrain-mlogloss:0.73938\tvalidate-mlogloss:0.87136                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8665919343407765                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.7, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 10, 'learning_rate': 0.11936914569795554, 'max_delta_step': 6, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 683, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08129\tvalidate-mlogloss:1.07896                                \n",
      "[200]\ttrain-mlogloss:0.91295\tvalidate-mlogloss:0.89863                              \n",
      "[400]\ttrain-mlogloss:0.90709\tvalidate-mlogloss:0.89485                              \n",
      "[600]\ttrain-mlogloss:0.90440\tvalidate-mlogloss:0.89326                              \n",
      "[682]\ttrain-mlogloss:0.90357\tvalidate-mlogloss:0.89282                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08096\tvalidate-mlogloss:1.07980                                \n",
      "[200]\ttrain-mlogloss:0.90891\tvalidate-mlogloss:0.90597                              \n",
      "[400]\ttrain-mlogloss:0.90338\tvalidate-mlogloss:0.90336                              \n",
      "[600]\ttrain-mlogloss:0.90075\tvalidate-mlogloss:0.90183                              \n",
      "[682]\ttrain-mlogloss:0.89988\tvalidate-mlogloss:0.90193                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07923\tvalidate-mlogloss:1.07807                                \n",
      "[200]\ttrain-mlogloss:0.90767\tvalidate-mlogloss:0.89370                              \n",
      "[400]\ttrain-mlogloss:0.90151\tvalidate-mlogloss:0.89038                              \n",
      "[600]\ttrain-mlogloss:0.89905\tvalidate-mlogloss:0.88886                              \n",
      "[682]\ttrain-mlogloss:0.89859\tvalidate-mlogloss:0.88876                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8945053388381111                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.01483780032162127, 'max_delta_step': 5, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 732, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09579\tvalidate-mlogloss:1.09567                                \n",
      "[200]\ttrain-mlogloss:0.92801\tvalidate-mlogloss:0.91541                              \n",
      "[400]\ttrain-mlogloss:0.89983\tvalidate-mlogloss:0.89336                              \n",
      "[600]\ttrain-mlogloss:0.88485\tvalidate-mlogloss:0.88512                              \n",
      "[731]\ttrain-mlogloss:0.87715\tvalidate-mlogloss:0.88146                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09593\tvalidate-mlogloss:1.09578                                \n",
      "[200]\ttrain-mlogloss:0.92664\tvalidate-mlogloss:0.92504                              \n",
      "[400]\ttrain-mlogloss:0.89688\tvalidate-mlogloss:0.90375                              \n",
      "[600]\ttrain-mlogloss:0.88054\tvalidate-mlogloss:0.89611                              \n",
      "[731]\ttrain-mlogloss:0.87271\tvalidate-mlogloss:0.89346                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09579\tvalidate-mlogloss:1.09573                                \n",
      "[200]\ttrain-mlogloss:0.92412\tvalidate-mlogloss:0.91555                              \n",
      "[400]\ttrain-mlogloss:0.89483\tvalidate-mlogloss:0.89314                              \n",
      "[600]\ttrain-mlogloss:0.87914\tvalidate-mlogloss:0.88467                              \n",
      "[731]\ttrain-mlogloss:0.87103\tvalidate-mlogloss:0.88082                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8852487667415079                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.5, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 10, 'learning_rate': 0.24091001705797954, 'max_delta_step': 4, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1296, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.05849\tvalidate-mlogloss:1.05551                                \n",
      "[200]\ttrain-mlogloss:0.90698\tvalidate-mlogloss:0.89642                              \n",
      "[400]\ttrain-mlogloss:0.90471\tvalidate-mlogloss:0.89333                              \n",
      "[600]\ttrain-mlogloss:0.90320\tvalidate-mlogloss:0.89318                              \n",
      "[800]\ttrain-mlogloss:0.90218\tvalidate-mlogloss:0.89262                              \n",
      "[1000]\ttrain-mlogloss:0.90106\tvalidate-mlogloss:0.89143                             \n",
      "[1200]\ttrain-mlogloss:0.90048\tvalidate-mlogloss:0.89079                             \n",
      "[1295]\ttrain-mlogloss:0.90038\tvalidate-mlogloss:0.89146                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.05981\tvalidate-mlogloss:1.05890                                \n",
      "[200]\ttrain-mlogloss:0.90565\tvalidate-mlogloss:0.90515                              \n",
      "[400]\ttrain-mlogloss:0.90220\tvalidate-mlogloss:0.90324                              \n",
      "[600]\ttrain-mlogloss:0.90010\tvalidate-mlogloss:0.90026                              \n",
      "[800]\ttrain-mlogloss:0.89935\tvalidate-mlogloss:0.90043                              \n",
      "[1000]\ttrain-mlogloss:0.89877\tvalidate-mlogloss:0.90036                             \n",
      "[1200]\ttrain-mlogloss:0.89813\tvalidate-mlogloss:0.89964                             \n",
      "[1295]\ttrain-mlogloss:0.89793\tvalidate-mlogloss:0.89813                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05957\tvalidate-mlogloss:1.05836                                \n",
      "[200]\ttrain-mlogloss:0.90129\tvalidate-mlogloss:0.90305                              \n",
      "[400]\ttrain-mlogloss:0.89798\tvalidate-mlogloss:0.90100                              \n",
      "[600]\ttrain-mlogloss:0.89737\tvalidate-mlogloss:0.90167                              \n",
      "[779]\ttrain-mlogloss:0.89656\tvalidate-mlogloss:0.90103                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8968505931282532                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.6, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 100, 'learning_rate': 0.17014745237739565, 'max_delta_step': 3, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 777, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07153\tvalidate-mlogloss:1.06926                                \n",
      "[200]\ttrain-mlogloss:0.90556\tvalidate-mlogloss:0.89248                              \n",
      "[400]\ttrain-mlogloss:0.90296\tvalidate-mlogloss:0.89088                              \n",
      "[600]\ttrain-mlogloss:0.90232\tvalidate-mlogloss:0.89028                              \n",
      "[776]\ttrain-mlogloss:0.90224\tvalidate-mlogloss:0.89000                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07164\tvalidate-mlogloss:1.06946                                \n",
      "[200]\ttrain-mlogloss:0.89980\tvalidate-mlogloss:0.89896                              \n",
      "[400]\ttrain-mlogloss:0.89785\tvalidate-mlogloss:0.89796                              \n",
      "[600]\ttrain-mlogloss:0.89686\tvalidate-mlogloss:0.89692                              \n",
      "[776]\ttrain-mlogloss:0.89636\tvalidate-mlogloss:0.89701                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07214\tvalidate-mlogloss:1.06713                                \n",
      "[200]\ttrain-mlogloss:0.89962\tvalidate-mlogloss:0.89039                              \n",
      "[400]\ttrain-mlogloss:0.89772\tvalidate-mlogloss:0.88962                              \n",
      "[600]\ttrain-mlogloss:0.89728\tvalidate-mlogloss:0.88936                              \n",
      "[652]\ttrain-mlogloss:0.89719\tvalidate-mlogloss:0.88948                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8921652562774306                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.032118930760402675, 'max_delta_step': 7, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 1452, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09166\tvalidate-mlogloss:1.09128                                \n",
      "[200]\ttrain-mlogloss:0.82755\tvalidate-mlogloss:0.87369                              \n",
      "[400]\ttrain-mlogloss:0.77260\tvalidate-mlogloss:0.85940                              \n",
      "[600]\ttrain-mlogloss:0.73128\tvalidate-mlogloss:0.85095                              \n",
      "[800]\ttrain-mlogloss:0.69884\tvalidate-mlogloss:0.84576                              \n",
      "[1000]\ttrain-mlogloss:0.67482\tvalidate-mlogloss:0.84117                             \n",
      "[1200]\ttrain-mlogloss:0.65463\tvalidate-mlogloss:0.83830                             \n",
      "[1400]\ttrain-mlogloss:0.63782\tvalidate-mlogloss:0.83589                             \n",
      "[1451]\ttrain-mlogloss:0.63419\tvalidate-mlogloss:0.83538                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09132\tvalidate-mlogloss:1.09185                                \n",
      "[200]\ttrain-mlogloss:0.82315\tvalidate-mlogloss:0.88321                              \n",
      "[400]\ttrain-mlogloss:0.76739\tvalidate-mlogloss:0.87178                              \n",
      "[600]\ttrain-mlogloss:0.72626\tvalidate-mlogloss:0.86376                              \n",
      "[800]\ttrain-mlogloss:0.69488\tvalidate-mlogloss:0.85865                              \n",
      "[1000]\ttrain-mlogloss:0.67073\tvalidate-mlogloss:0.85404                             \n",
      "[1200]\ttrain-mlogloss:0.65134\tvalidate-mlogloss:0.85033                             \n",
      "[1400]\ttrain-mlogloss:0.63468\tvalidate-mlogloss:0.84702                             \n",
      "[1451]\ttrain-mlogloss:0.63131\tvalidate-mlogloss:0.84686                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09192\tvalidate-mlogloss:1.09255                                \n",
      "[200]\ttrain-mlogloss:0.82389\tvalidate-mlogloss:0.88107                              \n",
      "[400]\ttrain-mlogloss:0.76776\tvalidate-mlogloss:0.86724                              \n",
      "[600]\ttrain-mlogloss:0.72665\tvalidate-mlogloss:0.86155                              \n",
      "[800]\ttrain-mlogloss:0.69549\tvalidate-mlogloss:0.85612                              \n",
      "[1000]\ttrain-mlogloss:0.66980\tvalidate-mlogloss:0.85104                             \n",
      "[1200]\ttrain-mlogloss:0.65049\tvalidate-mlogloss:0.84788                             \n",
      "[1400]\ttrain-mlogloss:0.63405\tvalidate-mlogloss:0.84502                             \n",
      "[1451]\ttrain-mlogloss:0.63037\tvalidate-mlogloss:0.84457                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8422655774621558                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.5, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 10, 'learning_rate': 0.14927109484509418, 'max_delta_step': 1, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1020, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07513\tvalidate-mlogloss:1.07295                                \n",
      "[200]\ttrain-mlogloss:0.91950\tvalidate-mlogloss:0.90084                              \n",
      "[400]\ttrain-mlogloss:0.91855\tvalidate-mlogloss:0.90019                              \n",
      "[600]\ttrain-mlogloss:0.91719\tvalidate-mlogloss:0.89854                              \n",
      "[800]\ttrain-mlogloss:0.91638\tvalidate-mlogloss:0.89855                              \n",
      "[1000]\ttrain-mlogloss:0.91612\tvalidate-mlogloss:0.89784                             \n",
      "[1019]\ttrain-mlogloss:0.91588\tvalidate-mlogloss:0.89726                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07444\tvalidate-mlogloss:1.07429                                \n",
      "[200]\ttrain-mlogloss:0.91701\tvalidate-mlogloss:0.90644                              \n",
      "[400]\ttrain-mlogloss:0.91528\tvalidate-mlogloss:0.90527                              \n",
      "[600]\ttrain-mlogloss:0.91461\tvalidate-mlogloss:0.90375                              \n",
      "[800]\ttrain-mlogloss:0.91365\tvalidate-mlogloss:0.90328                              \n",
      "[1000]\ttrain-mlogloss:0.91314\tvalidate-mlogloss:0.90276                             \n",
      "[1019]\ttrain-mlogloss:0.91305\tvalidate-mlogloss:0.90256                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07310\tvalidate-mlogloss:1.07202                                \n",
      "[200]\ttrain-mlogloss:0.91575\tvalidate-mlogloss:0.91043                              \n",
      "[400]\ttrain-mlogloss:0.91432\tvalidate-mlogloss:0.90901                              \n",
      "[600]\ttrain-mlogloss:0.91326\tvalidate-mlogloss:0.90804                              \n",
      "[800]\ttrain-mlogloss:0.91298\tvalidate-mlogloss:0.90719                              \n",
      "[1000]\ttrain-mlogloss:0.91219\tvalidate-mlogloss:0.90641                             \n",
      "[1019]\ttrain-mlogloss:0.91209\tvalidate-mlogloss:0.90649                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.9021043047380096                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.7, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 100, 'learning_rate': 0.26613418511812154, 'max_delta_step': 2, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1024, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.06182\tvalidate-mlogloss:1.05645                                \n",
      "[200]\ttrain-mlogloss:0.83494\tvalidate-mlogloss:0.86667                              \n",
      "[400]\ttrain-mlogloss:0.79147\tvalidate-mlogloss:0.86398                              \n",
      "[600]\ttrain-mlogloss:0.75791\tvalidate-mlogloss:0.86016                              \n",
      "[800]\ttrain-mlogloss:0.72989\tvalidate-mlogloss:0.86017                              \n",
      "[1000]\ttrain-mlogloss:0.70485\tvalidate-mlogloss:0.85975                             \n",
      "[1023]\ttrain-mlogloss:0.70217\tvalidate-mlogloss:0.85828                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.06183\tvalidate-mlogloss:1.05568                                \n",
      "[200]\ttrain-mlogloss:0.83229\tvalidate-mlogloss:0.88978                              \n",
      "[400]\ttrain-mlogloss:0.78881\tvalidate-mlogloss:0.88172                              \n",
      "[600]\ttrain-mlogloss:0.75487\tvalidate-mlogloss:0.87416                              \n",
      "[800]\ttrain-mlogloss:0.72624\tvalidate-mlogloss:0.87281                              \n",
      "[1000]\ttrain-mlogloss:0.70168\tvalidate-mlogloss:0.86480                             \n",
      "[1023]\ttrain-mlogloss:0.69897\tvalidate-mlogloss:0.86362                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.05801\tvalidate-mlogloss:1.05698                                \n",
      "[200]\ttrain-mlogloss:0.83019\tvalidate-mlogloss:0.87357                              \n",
      "[400]\ttrain-mlogloss:0.78674\tvalidate-mlogloss:0.86961                              \n",
      "[600]\ttrain-mlogloss:0.75320\tvalidate-mlogloss:0.86919                              \n",
      "[704]\ttrain-mlogloss:0.73856\tvalidate-mlogloss:0.86983                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8639094435172968                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 1, 'learning_rate': 0.29828868495086086, 'max_delta_step': 9, 'max_depth': 10, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1493, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.03279\tvalidate-mlogloss:1.03524                                \n",
      "[200]\ttrain-mlogloss:0.75732\tvalidate-mlogloss:0.85942                              \n",
      "[400]\ttrain-mlogloss:0.75154\tvalidate-mlogloss:0.85834                              \n",
      "[600]\ttrain-mlogloss:0.74794\tvalidate-mlogloss:0.85690                              \n",
      "[800]\ttrain-mlogloss:0.74464\tvalidate-mlogloss:0.85595                              \n",
      "[1000]\ttrain-mlogloss:0.74119\tvalidate-mlogloss:0.85550                             \n",
      "[1200]\ttrain-mlogloss:0.73824\tvalidate-mlogloss:0.85504                             \n",
      "[1400]\ttrain-mlogloss:0.73723\tvalidate-mlogloss:0.85488                             \n",
      "[1492]\ttrain-mlogloss:0.73701\tvalidate-mlogloss:0.85512                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.03711\tvalidate-mlogloss:1.04200                                \n",
      "[200]\ttrain-mlogloss:0.75557\tvalidate-mlogloss:0.86958                              \n",
      "[400]\ttrain-mlogloss:0.74875\tvalidate-mlogloss:0.86740                              \n",
      "[600]\ttrain-mlogloss:0.74543\tvalidate-mlogloss:0.86597                              \n",
      "[800]\ttrain-mlogloss:0.74298\tvalidate-mlogloss:0.86588                              \n",
      "[1000]\ttrain-mlogloss:0.73862\tvalidate-mlogloss:0.86390                             \n",
      "[1200]\ttrain-mlogloss:0.73638\tvalidate-mlogloss:0.86328                             \n",
      "[1400]\ttrain-mlogloss:0.73615\tvalidate-mlogloss:0.86353                             \n",
      "[1492]\ttrain-mlogloss:0.73506\tvalidate-mlogloss:0.86302                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.03317\tvalidate-mlogloss:1.04021                                \n",
      "[200]\ttrain-mlogloss:0.74950\tvalidate-mlogloss:0.86300                              \n",
      "[400]\ttrain-mlogloss:0.74399\tvalidate-mlogloss:0.86213                              \n",
      "[600]\ttrain-mlogloss:0.74086\tvalidate-mlogloss:0.86128                              \n",
      "[800]\ttrain-mlogloss:0.73951\tvalidate-mlogloss:0.86126                              \n",
      "[1000]\ttrain-mlogloss:0.73548\tvalidate-mlogloss:0.86097                             \n",
      "[1200]\ttrain-mlogloss:0.73020\tvalidate-mlogloss:0.85944                             \n",
      "[1400]\ttrain-mlogloss:0.72908\tvalidate-mlogloss:0.85938                             \n",
      "[1492]\ttrain-mlogloss:0.72882\tvalidate-mlogloss:0.85894                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8590281688557105                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.11608713292147023, 'max_delta_step': 1, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 748, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07071\tvalidate-mlogloss:1.07154                                \n",
      "[200]\ttrain-mlogloss:0.57164\tvalidate-mlogloss:0.83120                              \n",
      "[400]\ttrain-mlogloss:0.49203\tvalidate-mlogloss:0.82359                              \n",
      "[600]\ttrain-mlogloss:0.46392\tvalidate-mlogloss:0.82202                              \n",
      "[747]\ttrain-mlogloss:0.45264\tvalidate-mlogloss:0.82226                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07118\tvalidate-mlogloss:1.07490                                \n",
      "[200]\ttrain-mlogloss:0.57183\tvalidate-mlogloss:0.83753                              \n",
      "[400]\ttrain-mlogloss:0.49071\tvalidate-mlogloss:0.82901                              \n",
      "[600]\ttrain-mlogloss:0.46266\tvalidate-mlogloss:0.82880                              \n",
      "[747]\ttrain-mlogloss:0.45108\tvalidate-mlogloss:0.82921                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07047\tvalidate-mlogloss:1.07457                                \n",
      "[200]\ttrain-mlogloss:0.57093\tvalidate-mlogloss:0.84206                              \n",
      "[400]\ttrain-mlogloss:0.49064\tvalidate-mlogloss:0.83471                              \n",
      "[600]\ttrain-mlogloss:0.46388\tvalidate-mlogloss:0.83401                              \n",
      "[747]\ttrain-mlogloss:0.45326\tvalidate-mlogloss:0.83348                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.828318964309685                                                 \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 1, 'learning_rate': 0.11381530461241934, 'max_delta_step': 5, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1795, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07766\tvalidate-mlogloss:1.07651                               \n",
      "[200]\ttrain-mlogloss:0.89827\tvalidate-mlogloss:0.88834                             \n",
      "[400]\ttrain-mlogloss:0.89800\tvalidate-mlogloss:0.88820                             \n",
      "[600]\ttrain-mlogloss:0.89755\tvalidate-mlogloss:0.88795                             \n",
      "[800]\ttrain-mlogloss:0.89735\tvalidate-mlogloss:0.88796                             \n",
      "[1000]\ttrain-mlogloss:0.89734\tvalidate-mlogloss:0.88795                            \n",
      "[1200]\ttrain-mlogloss:0.89709\tvalidate-mlogloss:0.88771                            \n",
      "[1400]\ttrain-mlogloss:0.89697\tvalidate-mlogloss:0.88744                            \n",
      "[1600]\ttrain-mlogloss:0.89693\tvalidate-mlogloss:0.88748                            \n",
      "[1794]\ttrain-mlogloss:0.89693\tvalidate-mlogloss:0.88742                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.07794\tvalidate-mlogloss:1.07876                               \n",
      "[200]\ttrain-mlogloss:0.89343\tvalidate-mlogloss:0.89766                             \n",
      "[400]\ttrain-mlogloss:0.89247\tvalidate-mlogloss:0.89715                             \n",
      "[600]\ttrain-mlogloss:0.89218\tvalidate-mlogloss:0.89658                             \n",
      "[800]\ttrain-mlogloss:0.89197\tvalidate-mlogloss:0.89647                             \n",
      "[1000]\ttrain-mlogloss:0.89187\tvalidate-mlogloss:0.89629                            \n",
      "[1200]\ttrain-mlogloss:0.89184\tvalidate-mlogloss:0.89629                            \n",
      "[1400]\ttrain-mlogloss:0.89179\tvalidate-mlogloss:0.89638                            \n",
      "[1600]\ttrain-mlogloss:0.89163\tvalidate-mlogloss:0.89618                            \n",
      "[1794]\ttrain-mlogloss:0.89157\tvalidate-mlogloss:0.89616                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07862\tvalidate-mlogloss:1.07904                               \n",
      "[200]\ttrain-mlogloss:0.89243\tvalidate-mlogloss:0.89764                             \n",
      "[400]\ttrain-mlogloss:0.89210\tvalidate-mlogloss:0.89766                             \n",
      "[600]\ttrain-mlogloss:0.89174\tvalidate-mlogloss:0.89746                             \n",
      "[800]\ttrain-mlogloss:0.89161\tvalidate-mlogloss:0.89721                             \n",
      "[1000]\ttrain-mlogloss:0.89157\tvalidate-mlogloss:0.89716                            \n",
      "[1200]\ttrain-mlogloss:0.89117\tvalidate-mlogloss:0.89689                            \n",
      "[1400]\ttrain-mlogloss:0.89112\tvalidate-mlogloss:0.89690                            \n",
      "[1600]\ttrain-mlogloss:0.89110\tvalidate-mlogloss:0.89686                            \n",
      "[1794]\ttrain-mlogloss:0.89107\tvalidate-mlogloss:0.89702                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8935310904337848                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 10, 'learning_rate': 0.07019521158141884, 'max_delta_step': 4, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1922, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08257\tvalidate-mlogloss:1.08367                               \n",
      "[200]\ttrain-mlogloss:0.81781\tvalidate-mlogloss:0.86430                             \n",
      "[400]\ttrain-mlogloss:0.80914\tvalidate-mlogloss:0.86219                             \n",
      "[600]\ttrain-mlogloss:0.80394\tvalidate-mlogloss:0.86016                             \n",
      "[800]\ttrain-mlogloss:0.80122\tvalidate-mlogloss:0.85970                             \n",
      "[1000]\ttrain-mlogloss:0.79917\tvalidate-mlogloss:0.85858                            \n",
      "[1200]\ttrain-mlogloss:0.79712\tvalidate-mlogloss:0.85792                            \n",
      "[1400]\ttrain-mlogloss:0.79518\tvalidate-mlogloss:0.85806                            \n",
      "[1600]\ttrain-mlogloss:0.79328\tvalidate-mlogloss:0.85728                            \n",
      "[1800]\ttrain-mlogloss:0.79159\tvalidate-mlogloss:0.85677                            \n",
      "[1921]\ttrain-mlogloss:0.79088\tvalidate-mlogloss:0.85680                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08099\tvalidate-mlogloss:1.08308                               \n",
      "[200]\ttrain-mlogloss:0.81892\tvalidate-mlogloss:0.87582                             \n",
      "[400]\ttrain-mlogloss:0.81091\tvalidate-mlogloss:0.87351                             \n",
      "[600]\ttrain-mlogloss:0.80606\tvalidate-mlogloss:0.87209                             \n",
      "[800]\ttrain-mlogloss:0.80359\tvalidate-mlogloss:0.87224                             \n",
      "[1000]\ttrain-mlogloss:0.80167\tvalidate-mlogloss:0.87175                            \n",
      "[1200]\ttrain-mlogloss:0.79862\tvalidate-mlogloss:0.87088                            \n",
      "[1400]\ttrain-mlogloss:0.79698\tvalidate-mlogloss:0.87069                            \n",
      "[1600]\ttrain-mlogloss:0.79510\tvalidate-mlogloss:0.87005                            \n",
      "[1800]\ttrain-mlogloss:0.79328\tvalidate-mlogloss:0.86970                            \n",
      "[1921]\ttrain-mlogloss:0.79253\tvalidate-mlogloss:0.86965                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08227\tvalidate-mlogloss:1.08386                               \n",
      "[200]\ttrain-mlogloss:0.81741\tvalidate-mlogloss:0.87744                             \n",
      "[400]\ttrain-mlogloss:0.80692\tvalidate-mlogloss:0.87452                             \n",
      "[600]\ttrain-mlogloss:0.80290\tvalidate-mlogloss:0.87383                             \n",
      "[800]\ttrain-mlogloss:0.79966\tvalidate-mlogloss:0.87298                             \n",
      "[1000]\ttrain-mlogloss:0.79699\tvalidate-mlogloss:0.87221                            \n",
      "[1200]\ttrain-mlogloss:0.79482\tvalidate-mlogloss:0.87228                            \n",
      "[1400]\ttrain-mlogloss:0.79323\tvalidate-mlogloss:0.87186                            \n",
      "[1600]\ttrain-mlogloss:0.79229\tvalidate-mlogloss:0.87188                            \n",
      "[1800]\ttrain-mlogloss:0.79117\tvalidate-mlogloss:0.87205                            \n",
      "[1921]\ttrain-mlogloss:0.78996\tvalidate-mlogloss:0.87161                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8660223977338267                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 10, 'learning_rate': 0.03536924302878895, 'max_delta_step': 6, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1053, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09074\tvalidate-mlogloss:1.09109                               \n",
      "[200]\ttrain-mlogloss:0.87825\tvalidate-mlogloss:0.88155                             \n",
      "[400]\ttrain-mlogloss:0.87534\tvalidate-mlogloss:0.87957                             \n",
      "[600]\ttrain-mlogloss:0.87444\tvalidate-mlogloss:0.87893                             \n",
      "[800]\ttrain-mlogloss:0.87388\tvalidate-mlogloss:0.87844                             \n",
      "[1000]\ttrain-mlogloss:0.87356\tvalidate-mlogloss:0.87801                            \n",
      "[1052]\ttrain-mlogloss:0.87336\tvalidate-mlogloss:0.87779                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09061\tvalidate-mlogloss:1.09095                               \n",
      "[200]\ttrain-mlogloss:0.87401\tvalidate-mlogloss:0.88907                             \n",
      "[400]\ttrain-mlogloss:0.87116\tvalidate-mlogloss:0.88756                             \n",
      "[600]\ttrain-mlogloss:0.87001\tvalidate-mlogloss:0.88688                             \n",
      "[800]\ttrain-mlogloss:0.86974\tvalidate-mlogloss:0.88702                             \n",
      "[1000]\ttrain-mlogloss:0.86941\tvalidate-mlogloss:0.88678                            \n",
      "[1052]\ttrain-mlogloss:0.86933\tvalidate-mlogloss:0.88672                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09056\tvalidate-mlogloss:1.09098                               \n",
      "[200]\ttrain-mlogloss:0.87207\tvalidate-mlogloss:0.89059                             \n",
      "[400]\ttrain-mlogloss:0.86871\tvalidate-mlogloss:0.88870                             \n",
      "[600]\ttrain-mlogloss:0.86810\tvalidate-mlogloss:0.88791                             \n",
      "[800]\ttrain-mlogloss:0.86756\tvalidate-mlogloss:0.88772                             \n",
      "[1000]\ttrain-mlogloss:0.86726\tvalidate-mlogloss:0.88738                            \n",
      "[1052]\ttrain-mlogloss:0.86724\tvalidate-mlogloss:0.88745                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8839855254200307                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.13587298256919897, 'max_delta_step': 9, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1787, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06364\tvalidate-mlogloss:1.06795                               \n",
      "[200]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                             \n",
      "[400]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                             \n",
      "[600]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                             \n",
      "[800]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                             \n",
      "[1000]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                            \n",
      "[1200]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                            \n",
      "[1400]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                            \n",
      "[1600]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                            \n",
      "[1786]\ttrain-mlogloss:0.68793\tvalidate-mlogloss:0.84456                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06125\tvalidate-mlogloss:1.06764                               \n",
      "[200]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                             \n",
      "[400]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                             \n",
      "[600]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                             \n",
      "[800]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                             \n",
      "[1000]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                            \n",
      "[1200]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                            \n",
      "[1400]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                            \n",
      "[1600]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                            \n",
      "[1786]\ttrain-mlogloss:0.67948\tvalidate-mlogloss:0.85195                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.06260\tvalidate-mlogloss:1.06901                               \n",
      "[200]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                             \n",
      "[400]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                             \n",
      "[600]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                             \n",
      "[800]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                             \n",
      "[1000]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                            \n",
      "[1200]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                            \n",
      "[1400]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                            \n",
      "[1600]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                            \n",
      "[1786]\ttrain-mlogloss:0.68234\tvalidate-mlogloss:0.85921                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8519053902413501                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 1, 'learning_rate': 0.08243933253488539, 'max_delta_step': 1, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1731, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08364\tvalidate-mlogloss:1.08255                               \n",
      "[200]\ttrain-mlogloss:0.89976\tvalidate-mlogloss:0.88503                             \n",
      "[400]\ttrain-mlogloss:0.89544\tvalidate-mlogloss:0.88171                             \n",
      "[600]\ttrain-mlogloss:0.89355\tvalidate-mlogloss:0.87981                             \n",
      "[800]\ttrain-mlogloss:0.89244\tvalidate-mlogloss:0.87950                             \n",
      "[1000]\ttrain-mlogloss:0.89149\tvalidate-mlogloss:0.87811                            \n",
      "[1200]\ttrain-mlogloss:0.89069\tvalidate-mlogloss:0.87735                            \n",
      "[1400]\ttrain-mlogloss:0.88972\tvalidate-mlogloss:0.87689                            \n",
      "[1600]\ttrain-mlogloss:0.88915\tvalidate-mlogloss:0.87726                            \n",
      "[1724]\ttrain-mlogloss:0.88907\tvalidate-mlogloss:0.87695                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08242\tvalidate-mlogloss:1.08218                               \n",
      "[200]\ttrain-mlogloss:0.89537\tvalidate-mlogloss:0.89652                             \n",
      "[400]\ttrain-mlogloss:0.89079\tvalidate-mlogloss:0.89510                             \n",
      "[600]\ttrain-mlogloss:0.88867\tvalidate-mlogloss:0.89303                             \n",
      "[800]\ttrain-mlogloss:0.88748\tvalidate-mlogloss:0.89374                             \n",
      "[1000]\ttrain-mlogloss:0.88676\tvalidate-mlogloss:0.89335                            \n",
      "[1150]\ttrain-mlogloss:0.88634\tvalidate-mlogloss:0.89322                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08281\tvalidate-mlogloss:1.08239                               \n",
      "[200]\ttrain-mlogloss:0.89441\tvalidate-mlogloss:0.89529                             \n",
      "[400]\ttrain-mlogloss:0.89034\tvalidate-mlogloss:0.89332                             \n",
      "[600]\ttrain-mlogloss:0.88897\tvalidate-mlogloss:0.89283                             \n",
      "[800]\ttrain-mlogloss:0.88753\tvalidate-mlogloss:0.89220                             \n",
      "[1000]\ttrain-mlogloss:0.88703\tvalidate-mlogloss:0.89178                            \n",
      "[1200]\ttrain-mlogloss:0.88629\tvalidate-mlogloss:0.89282                            \n",
      "[1400]\ttrain-mlogloss:0.88536\tvalidate-mlogloss:0.89155                            \n",
      "[1600]\ttrain-mlogloss:0.88472\tvalidate-mlogloss:0.89109                            \n",
      "[1730]\ttrain-mlogloss:0.88450\tvalidate-mlogloss:0.89151                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8872671442653232                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 10, 'learning_rate': 0.05250082403023025, 'max_delta_step': 7, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1201, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08773\tvalidate-mlogloss:1.08732                               \n",
      "[200]\ttrain-mlogloss:0.83828\tvalidate-mlogloss:0.86568                             \n",
      "[400]\ttrain-mlogloss:0.79629\tvalidate-mlogloss:0.85489                             \n",
      "[600]\ttrain-mlogloss:0.76717\tvalidate-mlogloss:0.84870                             \n",
      "[800]\ttrain-mlogloss:0.74480\tvalidate-mlogloss:0.84380                             \n",
      "[1000]\ttrain-mlogloss:0.72815\tvalidate-mlogloss:0.84258                            \n",
      "[1200]\ttrain-mlogloss:0.71385\tvalidate-mlogloss:0.83991                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08759\tvalidate-mlogloss:1.08778                               \n",
      "[200]\ttrain-mlogloss:0.83364\tvalidate-mlogloss:0.87812                             \n",
      "[400]\ttrain-mlogloss:0.79206\tvalidate-mlogloss:0.86758                             \n",
      "[600]\ttrain-mlogloss:0.76442\tvalidate-mlogloss:0.86134                             \n",
      "[800]\ttrain-mlogloss:0.74347\tvalidate-mlogloss:0.85967                             \n",
      "[1000]\ttrain-mlogloss:0.72738\tvalidate-mlogloss:0.85610                            \n",
      "[1200]\ttrain-mlogloss:0.71302\tvalidate-mlogloss:0.85363                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08888\tvalidate-mlogloss:1.08889                               \n",
      "[200]\ttrain-mlogloss:0.83627\tvalidate-mlogloss:0.88156                             \n",
      "[400]\ttrain-mlogloss:0.79235\tvalidate-mlogloss:0.87499                             \n",
      "[600]\ttrain-mlogloss:0.76405\tvalidate-mlogloss:0.87174                             \n",
      "[800]\ttrain-mlogloss:0.74237\tvalidate-mlogloss:0.86741                             \n",
      "[1000]\ttrain-mlogloss:0.72574\tvalidate-mlogloss:0.86307                            \n",
      "[1200]\ttrain-mlogloss:0.71139\tvalidate-mlogloss:0.86293                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8521580715206669                                               \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.6, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.17553122809529526, 'max_delta_step': 6, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 984, 'num_feat': 80, 'step': 0.1}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.07010\tvalidate-mlogloss:1.06809                             \n",
      "[200]\ttrain-mlogloss:0.88680\tvalidate-mlogloss:0.89148                           \n",
      "[400]\ttrain-mlogloss:0.87661\tvalidate-mlogloss:0.88674                           \n",
      "[600]\ttrain-mlogloss:0.86978\tvalidate-mlogloss:0.88523                           \n",
      "[800]\ttrain-mlogloss:0.86486\tvalidate-mlogloss:0.88240                           \n",
      "[983]\ttrain-mlogloss:0.86175\tvalidate-mlogloss:0.88199                           \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.07151\tvalidate-mlogloss:1.06971                             \n",
      "[200]\ttrain-mlogloss:0.88260\tvalidate-mlogloss:0.89094                           \n",
      "[400]\ttrain-mlogloss:0.87394\tvalidate-mlogloss:0.88933                           \n",
      "[600]\ttrain-mlogloss:0.86731\tvalidate-mlogloss:0.88536                           \n",
      "[800]\ttrain-mlogloss:0.86215\tvalidate-mlogloss:0.88431                           \n",
      "[983]\ttrain-mlogloss:0.85891\tvalidate-mlogloss:0.88294                           \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.06991\tvalidate-mlogloss:1.06907                             \n",
      "[200]\ttrain-mlogloss:0.88215\tvalidate-mlogloss:0.89551                           \n",
      "[400]\ttrain-mlogloss:0.87260\tvalidate-mlogloss:0.89272                           \n",
      "[600]\ttrain-mlogloss:0.86615\tvalidate-mlogloss:0.89111                           \n",
      "[800]\ttrain-mlogloss:0.86168\tvalidate-mlogloss:0.88976                           \n",
      "[983]\ttrain-mlogloss:0.85852\tvalidate-mlogloss:0.88738                           \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.8841052553262903                                             \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 10, 'learning_rate': 0.10185211482080007, 'max_delta_step': 8, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 1592, 'num_feat': 50, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07867\tvalidate-mlogloss:1.07655                               \n",
      "[200]\ttrain-mlogloss:0.82536\tvalidate-mlogloss:0.86732                             \n",
      "[400]\ttrain-mlogloss:0.77045\tvalidate-mlogloss:0.85913                             \n",
      "[600]\ttrain-mlogloss:0.72590\tvalidate-mlogloss:0.85489                             \n",
      "[800]\ttrain-mlogloss:0.68924\tvalidate-mlogloss:0.85292                             \n",
      "[1000]\ttrain-mlogloss:0.65656\tvalidate-mlogloss:0.85064                            \n",
      "[1200]\ttrain-mlogloss:0.62803\tvalidate-mlogloss:0.85028                            \n",
      "[1400]\ttrain-mlogloss:0.60236\tvalidate-mlogloss:0.85077                            \n",
      "[1437]\ttrain-mlogloss:0.59788\tvalidate-mlogloss:0.85091                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.07636\tvalidate-mlogloss:1.07683                               \n",
      "[200]\ttrain-mlogloss:0.81969\tvalidate-mlogloss:0.87502                             \n",
      "[400]\ttrain-mlogloss:0.76543\tvalidate-mlogloss:0.86727                             \n",
      "[600]\ttrain-mlogloss:0.72193\tvalidate-mlogloss:0.86238                             \n",
      "[800]\ttrain-mlogloss:0.68495\tvalidate-mlogloss:0.85905                             \n",
      "[1000]\ttrain-mlogloss:0.65262\tvalidate-mlogloss:0.85682                            \n",
      "[1200]\ttrain-mlogloss:0.62404\tvalidate-mlogloss:0.85639                            \n",
      "[1400]\ttrain-mlogloss:0.59839\tvalidate-mlogloss:0.85524                            \n",
      "[1591]\ttrain-mlogloss:0.57646\tvalidate-mlogloss:0.85511                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07660\tvalidate-mlogloss:1.07699                               \n",
      "[200]\ttrain-mlogloss:0.81963\tvalidate-mlogloss:0.87821                             \n",
      "[400]\ttrain-mlogloss:0.76606\tvalidate-mlogloss:0.87072                             \n",
      "[600]\ttrain-mlogloss:0.72272\tvalidate-mlogloss:0.86468                             \n",
      "[800]\ttrain-mlogloss:0.68548\tvalidate-mlogloss:0.86153                             \n",
      "[1000]\ttrain-mlogloss:0.65350\tvalidate-mlogloss:0.86058                            \n",
      "[1200]\ttrain-mlogloss:0.62517\tvalidate-mlogloss:0.86019                            \n",
      "[1400]\ttrain-mlogloss:0.59958\tvalidate-mlogloss:0.85974                            \n",
      "[1591]\ttrain-mlogloss:0.57774\tvalidate-mlogloss:0.85905                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8549943419362611                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 10, 'learning_rate': 0.12271172467752282, 'max_delta_step': 2, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1561, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07269\tvalidate-mlogloss:1.07281                               \n",
      "[200]\ttrain-mlogloss:0.86678\tvalidate-mlogloss:0.87861                             \n",
      "[400]\ttrain-mlogloss:0.86678\tvalidate-mlogloss:0.87861                             \n",
      "[461]\ttrain-mlogloss:0.86678\tvalidate-mlogloss:0.87861                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06994\tvalidate-mlogloss:1.07169                               \n",
      "[200]\ttrain-mlogloss:0.86385\tvalidate-mlogloss:0.88792                             \n",
      "[400]\ttrain-mlogloss:0.86385\tvalidate-mlogloss:0.88792                             \n",
      "[464]\ttrain-mlogloss:0.86385\tvalidate-mlogloss:0.88792                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07302\tvalidate-mlogloss:1.07440                               \n",
      "[200]\ttrain-mlogloss:0.86218\tvalidate-mlogloss:0.89049                             \n",
      "[400]\ttrain-mlogloss:0.86218\tvalidate-mlogloss:0.89049                             \n",
      "[461]\ttrain-mlogloss:0.86218\tvalidate-mlogloss:0.89049                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8856773320281555                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.7, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 1, 'learning_rate': 0.20153659083952433, 'max_delta_step': 1, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 972, 'num_feat': 80, 'step': 0.1}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.06105\tvalidate-mlogloss:1.05909                             \n",
      "[200]\ttrain-mlogloss:0.88525\tvalidate-mlogloss:0.88220                           \n",
      "[400]\ttrain-mlogloss:0.88367\tvalidate-mlogloss:0.88161                           \n",
      "[600]\ttrain-mlogloss:0.88273\tvalidate-mlogloss:0.88126                           \n",
      "[800]\ttrain-mlogloss:0.88253\tvalidate-mlogloss:0.88105                           \n",
      "[971]\ttrain-mlogloss:0.88210\tvalidate-mlogloss:0.88076                           \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.06138\tvalidate-mlogloss:1.06006                             \n",
      "[200]\ttrain-mlogloss:0.87945\tvalidate-mlogloss:0.88752                           \n",
      "[400]\ttrain-mlogloss:0.87811\tvalidate-mlogloss:0.88732                           \n",
      "[600]\ttrain-mlogloss:0.87728\tvalidate-mlogloss:0.88644                           \n",
      "[761]\ttrain-mlogloss:0.87716\tvalidate-mlogloss:0.88700                           \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.06076\tvalidate-mlogloss:1.06069                             \n",
      "[200]\ttrain-mlogloss:0.87821\tvalidate-mlogloss:0.88234                           \n",
      "[400]\ttrain-mlogloss:0.87688\tvalidate-mlogloss:0.88201                           \n",
      "[600]\ttrain-mlogloss:0.87597\tvalidate-mlogloss:0.88152                           \n",
      "[800]\ttrain-mlogloss:0.87559\tvalidate-mlogloss:0.88153                           \n",
      "[971]\ttrain-mlogloss:0.87558\tvalidate-mlogloss:0.88167                           \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.8831982659342241                                             \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 10, 'learning_rate': 0.16300962078467265, 'max_delta_step': 9, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1752, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.05861\tvalidate-mlogloss:1.06015                             \n",
      "[200]\ttrain-mlogloss:0.48019\tvalidate-mlogloss:0.83520                           \n",
      "[400]\ttrain-mlogloss:0.40451\tvalidate-mlogloss:0.83621                           \n",
      "[600]\ttrain-mlogloss:0.38272\tvalidate-mlogloss:0.83612                           \n",
      "[645]\ttrain-mlogloss:0.38004\tvalidate-mlogloss:0.83635                           \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.05619\tvalidate-mlogloss:1.06213                             \n",
      "[200]\ttrain-mlogloss:0.47728\tvalidate-mlogloss:0.83625                           \n",
      "[400]\ttrain-mlogloss:0.40301\tvalidate-mlogloss:0.83791                           \n",
      "[600]\ttrain-mlogloss:0.38073\tvalidate-mlogloss:0.84106                           \n",
      "[606]\ttrain-mlogloss:0.38033\tvalidate-mlogloss:0.84111                           \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.06065\tvalidate-mlogloss:1.06406                             \n",
      "[200]\ttrain-mlogloss:0.47943\tvalidate-mlogloss:0.83757                           \n",
      "[400]\ttrain-mlogloss:0.40465\tvalidate-mlogloss:0.83693                           \n",
      "[600]\ttrain-mlogloss:0.38312\tvalidate-mlogloss:0.83815                           \n",
      "[711]\ttrain-mlogloss:0.37519\tvalidate-mlogloss:0.83843                           \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.838643712474171                                              \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 10, 'learning_rate': 0.1435975615249158, 'max_delta_step': 3, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1721, 'num_feat': 50, 'step': 0.3}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.06904\tvalidate-mlogloss:1.06535                             \n",
      "[200]\ttrain-mlogloss:0.89275\tvalidate-mlogloss:0.88589                           \n",
      "[400]\ttrain-mlogloss:0.89186\tvalidate-mlogloss:0.88548                           \n",
      "[600]\ttrain-mlogloss:0.89156\tvalidate-mlogloss:0.88537                           \n",
      "[800]\ttrain-mlogloss:0.89118\tvalidate-mlogloss:0.88549                           \n",
      "[1000]\ttrain-mlogloss:0.89071\tvalidate-mlogloss:0.88434                          \n",
      "[1200]\ttrain-mlogloss:0.89053\tvalidate-mlogloss:0.88406                          \n",
      "[1400]\ttrain-mlogloss:0.89039\tvalidate-mlogloss:0.88429                          \n",
      "[1600]\ttrain-mlogloss:0.89023\tvalidate-mlogloss:0.88427                          \n",
      "[1720]\ttrain-mlogloss:0.89018\tvalidate-mlogloss:0.88376                          \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.06687\tvalidate-mlogloss:1.06799                             \n",
      "[200]\ttrain-mlogloss:0.88647\tvalidate-mlogloss:0.89477                           \n",
      "[400]\ttrain-mlogloss:0.88610\tvalidate-mlogloss:0.89455                           \n",
      "[600]\ttrain-mlogloss:0.88507\tvalidate-mlogloss:0.89318                           \n",
      "[800]\ttrain-mlogloss:0.88477\tvalidate-mlogloss:0.89345                           \n",
      "[1000]\ttrain-mlogloss:0.88466\tvalidate-mlogloss:0.89312                          \n",
      "[1200]\ttrain-mlogloss:0.88458\tvalidate-mlogloss:0.89289                          \n",
      "[1400]\ttrain-mlogloss:0.88420\tvalidate-mlogloss:0.89299                          \n",
      "[1600]\ttrain-mlogloss:0.88378\tvalidate-mlogloss:0.89204                          \n",
      "[1720]\ttrain-mlogloss:0.88362\tvalidate-mlogloss:0.89202                          \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.06772\tvalidate-mlogloss:1.06894                             \n",
      "[200]\ttrain-mlogloss:0.88631\tvalidate-mlogloss:0.89206                           \n",
      "[400]\ttrain-mlogloss:0.88534\tvalidate-mlogloss:0.89141                           \n",
      "[600]\ttrain-mlogloss:0.88509\tvalidate-mlogloss:0.89102                           \n",
      "[800]\ttrain-mlogloss:0.88424\tvalidate-mlogloss:0.89047                           \n",
      "[1000]\ttrain-mlogloss:0.88385\tvalidate-mlogloss:0.88979                          \n",
      "[1200]\ttrain-mlogloss:0.88362\tvalidate-mlogloss:0.89005                          \n",
      "[1400]\ttrain-mlogloss:0.88322\tvalidate-mlogloss:0.88952                          \n",
      "[1600]\ttrain-mlogloss:0.88303\tvalidate-mlogloss:0.88933                          \n",
      "[1720]\ttrain-mlogloss:0.88285\tvalidate-mlogloss:0.88911                          \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.8882988334832062                                             \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.17936693503027043, 'max_delta_step': 6, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 748, 'num_feat': 80, 'step': 0.1}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.07160\tvalidate-mlogloss:1.06994                             \n",
      "[200]\ttrain-mlogloss:0.88423\tvalidate-mlogloss:0.88347                           \n",
      "[400]\ttrain-mlogloss:0.87557\tvalidate-mlogloss:0.87979                           \n",
      "[600]\ttrain-mlogloss:0.86919\tvalidate-mlogloss:0.87642                           \n",
      "[747]\ttrain-mlogloss:0.86604\tvalidate-mlogloss:0.87505                           \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.07121\tvalidate-mlogloss:1.07004                             \n",
      "[200]\ttrain-mlogloss:0.88070\tvalidate-mlogloss:0.89359                           \n",
      "[400]\ttrain-mlogloss:0.87231\tvalidate-mlogloss:0.88993                           \n",
      "[600]\ttrain-mlogloss:0.86617\tvalidate-mlogloss:0.88638                           \n",
      "[747]\ttrain-mlogloss:0.86283\tvalidate-mlogloss:0.88599                           \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.06944\tvalidate-mlogloss:1.06858                             \n",
      "[200]\ttrain-mlogloss:0.88057\tvalidate-mlogloss:0.89337                           \n",
      "[400]\ttrain-mlogloss:0.87143\tvalidate-mlogloss:0.89135                           \n",
      "[600]\ttrain-mlogloss:0.86547\tvalidate-mlogloss:0.89052                           \n",
      "[747]\ttrain-mlogloss:0.86202\tvalidate-mlogloss:0.88948                           \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.8835113212208764                                             \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 10, 'learning_rate': 0.08057289602499507, 'max_delta_step': 4, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1205, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.08478\tvalidate-mlogloss:1.08379                             \n",
      "[200]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                           \n",
      "[400]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                           \n",
      "[600]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                           \n",
      "[800]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                           \n",
      "[1000]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                          \n",
      "[1200]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                          \n",
      "[1204]\ttrain-mlogloss:0.89714\tvalidate-mlogloss:0.88315                          \n",
      "Predicting for fold 1...                                                         \n",
      "Start processing fold 2...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))      \n",
      "Start training model for fold 2...                                               \n",
      "[0]\ttrain-mlogloss:1.08384\tvalidate-mlogloss:1.08347                             \n",
      "[200]\ttrain-mlogloss:0.89275\tvalidate-mlogloss:0.89519                           \n",
      "[400]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                           \n",
      "[600]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                           \n",
      "[800]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                           \n",
      "[1000]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                          \n",
      "[1200]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                          \n",
      "[1204]\ttrain-mlogloss:0.89257\tvalidate-mlogloss:0.89501                          \n",
      "Predicting for fold 2...                                                         \n",
      "Start processing fold 3...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))      \n",
      "Start training model for fold 3...                                               \n",
      "[0]\ttrain-mlogloss:1.08431\tvalidate-mlogloss:1.08392                             \n",
      "[200]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89319                           \n",
      "[400]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                           \n",
      "[600]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                           \n",
      "[800]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                           \n",
      "[1000]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                          \n",
      "[1200]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                          \n",
      "[1204]\ttrain-mlogloss:0.89286\tvalidate-mlogloss:0.89318                          \n",
      "Predicting for fold 3...                                                         \n",
      "Average log loss: 0.8904458336541582                                             \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.7, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 100, 'learning_rate': 0.05450660879287833, 'max_delta_step': 8, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 956, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                       \n",
      "Class distribution:                                                              \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                 \n",
      "Class instance weights:                                                          \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))      \n",
      "Start training model for fold 1...                                               \n",
      "[0]\ttrain-mlogloss:1.08788\tvalidate-mlogloss:1.08684                             \n",
      "[200]\ttrain-mlogloss:0.84861\tvalidate-mlogloss:0.87288                           \n",
      "[400]\ttrain-mlogloss:0.83280\tvalidate-mlogloss:0.86850                           \n",
      "[600]\ttrain-mlogloss:0.82553\tvalidate-mlogloss:0.86715                             \n",
      "[800]\ttrain-mlogloss:0.82172\tvalidate-mlogloss:0.86617                             \n",
      "[955]\ttrain-mlogloss:0.81881\tvalidate-mlogloss:0.86536                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08861\tvalidate-mlogloss:1.08805                               \n",
      "[200]\ttrain-mlogloss:0.84485\tvalidate-mlogloss:0.88143                             \n",
      "[400]\ttrain-mlogloss:0.83095\tvalidate-mlogloss:0.87788                             \n",
      "[600]\ttrain-mlogloss:0.82468\tvalidate-mlogloss:0.87675                             \n",
      "[800]\ttrain-mlogloss:0.82043\tvalidate-mlogloss:0.87644                             \n",
      "[955]\ttrain-mlogloss:0.81814\tvalidate-mlogloss:0.87561                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08720\tvalidate-mlogloss:1.08742                               \n",
      "[200]\ttrain-mlogloss:0.84123\tvalidate-mlogloss:0.88728                             \n",
      "[400]\ttrain-mlogloss:0.82722\tvalidate-mlogloss:0.88384                             \n",
      "[600]\ttrain-mlogloss:0.82038\tvalidate-mlogloss:0.88364                             \n",
      "[800]\ttrain-mlogloss:0.81671\tvalidate-mlogloss:0.88360                             \n",
      "[955]\ttrain-mlogloss:0.81456\tvalidate-mlogloss:0.88391                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8749572852601927                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 10, 'learning_rate': 0.21227075312738372, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1421, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.05281\tvalidate-mlogloss:1.05131                               \n",
      "[200]\ttrain-mlogloss:0.85789\tvalidate-mlogloss:0.87365                             \n",
      "[400]\ttrain-mlogloss:0.84812\tvalidate-mlogloss:0.86721                             \n",
      "[600]\ttrain-mlogloss:0.84231\tvalidate-mlogloss:0.86543                             \n",
      "[800]\ttrain-mlogloss:0.83846\tvalidate-mlogloss:0.86467                             \n",
      "[1000]\ttrain-mlogloss:0.83488\tvalidate-mlogloss:0.86108                            \n",
      "[1200]\ttrain-mlogloss:0.83222\tvalidate-mlogloss:0.86073                            \n",
      "[1400]\ttrain-mlogloss:0.82955\tvalidate-mlogloss:0.85912                            \n",
      "[1420]\ttrain-mlogloss:0.82932\tvalidate-mlogloss:0.85929                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.05218\tvalidate-mlogloss:1.05385                               \n",
      "[200]\ttrain-mlogloss:0.85329\tvalidate-mlogloss:0.87851                             \n",
      "[400]\ttrain-mlogloss:0.84588\tvalidate-mlogloss:0.87778                             \n",
      "[600]\ttrain-mlogloss:0.83972\tvalidate-mlogloss:0.87548                             \n",
      "[800]\ttrain-mlogloss:0.83691\tvalidate-mlogloss:0.87851                             \n",
      "[991]\ttrain-mlogloss:0.83464\tvalidate-mlogloss:0.87670                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.05200\tvalidate-mlogloss:1.05466                               \n",
      "[200]\ttrain-mlogloss:0.85056\tvalidate-mlogloss:0.88137                             \n",
      "[400]\ttrain-mlogloss:0.84220\tvalidate-mlogloss:0.87979                             \n",
      "[600]\ttrain-mlogloss:0.83834\tvalidate-mlogloss:0.88013                             \n",
      "[800]\ttrain-mlogloss:0.83535\tvalidate-mlogloss:0.87912                             \n",
      "[1000]\ttrain-mlogloss:0.83196\tvalidate-mlogloss:0.87798                            \n",
      "[1200]\ttrain-mlogloss:0.82964\tvalidate-mlogloss:0.87889                            \n",
      "[1400]\ttrain-mlogloss:0.82707\tvalidate-mlogloss:0.87805                            \n",
      "[1420]\ttrain-mlogloss:0.82701\tvalidate-mlogloss:0.87792                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8713192412279033                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 10, 'learning_rate': 0.12791711218143634, 'max_delta_step': 7, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 502, 'num_feat': 80, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07330\tvalidate-mlogloss:1.07061                               \n",
      "[200]\ttrain-mlogloss:0.73268\tvalidate-mlogloss:0.85046                             \n",
      "[400]\ttrain-mlogloss:0.63236\tvalidate-mlogloss:0.84165                             \n",
      "[501]\ttrain-mlogloss:0.59353\tvalidate-mlogloss:0.83756                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.07249\tvalidate-mlogloss:1.07261                               \n",
      "[200]\ttrain-mlogloss:0.72801\tvalidate-mlogloss:0.85986                             \n",
      "[400]\ttrain-mlogloss:0.63022\tvalidate-mlogloss:0.84711                             \n",
      "[501]\ttrain-mlogloss:0.59148\tvalidate-mlogloss:0.84326                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07180\tvalidate-mlogloss:1.07321                               \n",
      "[200]\ttrain-mlogloss:0.72765\tvalidate-mlogloss:0.86454                             \n",
      "[400]\ttrain-mlogloss:0.62910\tvalidate-mlogloss:0.84988                             \n",
      "[501]\ttrain-mlogloss:0.59118\tvalidate-mlogloss:0.84722                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8426809516702775                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.02898050024383396, 'max_delta_step': 1, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1040, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09208\tvalidate-mlogloss:1.09199                               \n",
      "[200]\ttrain-mlogloss:0.82321\tvalidate-mlogloss:0.86910                             \n",
      "[400]\ttrain-mlogloss:0.76538\tvalidate-mlogloss:0.85654                             \n",
      "[600]\ttrain-mlogloss:0.71867\tvalidate-mlogloss:0.84924                             \n",
      "[800]\ttrain-mlogloss:0.68150\tvalidate-mlogloss:0.84448                             \n",
      "[1000]\ttrain-mlogloss:0.65143\tvalidate-mlogloss:0.84062                            \n",
      "[1039]\ttrain-mlogloss:0.64607\tvalidate-mlogloss:0.84014                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09265\tvalidate-mlogloss:1.09266                               \n",
      "[200]\ttrain-mlogloss:0.81861\tvalidate-mlogloss:0.87795                             \n",
      "[400]\ttrain-mlogloss:0.76080\tvalidate-mlogloss:0.86536                             \n",
      "[600]\ttrain-mlogloss:0.71443\tvalidate-mlogloss:0.85806                             \n",
      "[800]\ttrain-mlogloss:0.67689\tvalidate-mlogloss:0.85387                             \n",
      "[1000]\ttrain-mlogloss:0.64658\tvalidate-mlogloss:0.85030                            \n",
      "[1039]\ttrain-mlogloss:0.64128\tvalidate-mlogloss:0.84966                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09215\tvalidate-mlogloss:1.09297                               \n",
      "[200]\ttrain-mlogloss:0.81747\tvalidate-mlogloss:0.88319                             \n",
      "[400]\ttrain-mlogloss:0.75865\tvalidate-mlogloss:0.87098                             \n",
      "[600]\ttrain-mlogloss:0.71364\tvalidate-mlogloss:0.86436                             \n",
      "[800]\ttrain-mlogloss:0.67564\tvalidate-mlogloss:0.85883                             \n",
      "[1000]\ttrain-mlogloss:0.64430\tvalidate-mlogloss:0.85495                            \n",
      "[1039]\ttrain-mlogloss:0.63906\tvalidate-mlogloss:0.85435                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8480491183070967                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 10, 'learning_rate': 0.10350706632300065, 'max_delta_step': 6, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1976, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06648\tvalidate-mlogloss:1.07252                               \n",
      "[200]\ttrain-mlogloss:0.65008\tvalidate-mlogloss:0.83741                             \n",
      "[400]\ttrain-mlogloss:0.63574\tvalidate-mlogloss:0.83470                             \n",
      "[600]\ttrain-mlogloss:0.63231\tvalidate-mlogloss:0.83387                             \n",
      "[800]\ttrain-mlogloss:0.62828\tvalidate-mlogloss:0.83314                             \n",
      "[1000]\ttrain-mlogloss:0.62516\tvalidate-mlogloss:0.83251                            \n",
      "[1200]\ttrain-mlogloss:0.62361\tvalidate-mlogloss:0.83212                            \n",
      "[1400]\ttrain-mlogloss:0.62087\tvalidate-mlogloss:0.83160                            \n",
      "[1600]\ttrain-mlogloss:0.62054\tvalidate-mlogloss:0.83160                            \n",
      "[1800]\ttrain-mlogloss:0.61987\tvalidate-mlogloss:0.83144                            \n",
      "[1975]\ttrain-mlogloss:0.61945\tvalidate-mlogloss:0.83136                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06579\tvalidate-mlogloss:1.07310                               \n",
      "[200]\ttrain-mlogloss:0.65036\tvalidate-mlogloss:0.84849                             \n",
      "[400]\ttrain-mlogloss:0.64157\tvalidate-mlogloss:0.84698                             \n",
      "[600]\ttrain-mlogloss:0.63715\tvalidate-mlogloss:0.84577                             \n",
      "[800]\ttrain-mlogloss:0.63530\tvalidate-mlogloss:0.84535                             \n",
      "[1000]\ttrain-mlogloss:0.63314\tvalidate-mlogloss:0.84464                            \n",
      "[1200]\ttrain-mlogloss:0.63078\tvalidate-mlogloss:0.84430                            \n",
      "[1400]\ttrain-mlogloss:0.62923\tvalidate-mlogloss:0.84405                            \n",
      "[1600]\ttrain-mlogloss:0.62817\tvalidate-mlogloss:0.84383                            \n",
      "[1800]\ttrain-mlogloss:0.62555\tvalidate-mlogloss:0.84345                            \n",
      "[1975]\ttrain-mlogloss:0.62533\tvalidate-mlogloss:0.84325                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.06533\tvalidate-mlogloss:1.07302                               \n",
      "[200]\ttrain-mlogloss:0.64619\tvalidate-mlogloss:0.85198                             \n",
      "[400]\ttrain-mlogloss:0.63790\tvalidate-mlogloss:0.85036                             \n",
      "[600]\ttrain-mlogloss:0.63532\tvalidate-mlogloss:0.84960                             \n",
      "[800]\ttrain-mlogloss:0.63244\tvalidate-mlogloss:0.84919                             \n",
      "[1000]\ttrain-mlogloss:0.62833\tvalidate-mlogloss:0.84834                            \n",
      "[1200]\ttrain-mlogloss:0.62720\tvalidate-mlogloss:0.84814                            \n",
      "[1400]\ttrain-mlogloss:0.62560\tvalidate-mlogloss:0.84808                            \n",
      "[1600]\ttrain-mlogloss:0.62508\tvalidate-mlogloss:0.84787                            \n",
      "[1800]\ttrain-mlogloss:0.62412\tvalidate-mlogloss:0.84787                            \n",
      "[1975]\ttrain-mlogloss:0.62359\tvalidate-mlogloss:0.84768                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8407599773319268                                               \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 10, 'learning_rate': 0.1573852681028764, 'max_delta_step': 2, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1331, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07459\tvalidate-mlogloss:1.07046                               \n",
      "[200]\ttrain-mlogloss:0.90829\tvalidate-mlogloss:0.89289                             \n",
      "[400]\ttrain-mlogloss:0.90562\tvalidate-mlogloss:0.89073                             \n",
      "[600]\ttrain-mlogloss:0.90412\tvalidate-mlogloss:0.88905                             \n",
      "[800]\ttrain-mlogloss:0.90317\tvalidate-mlogloss:0.88843                             \n",
      "[1000]\ttrain-mlogloss:0.90228\tvalidate-mlogloss:0.88721                            \n",
      "[1200]\ttrain-mlogloss:0.90183\tvalidate-mlogloss:0.88638                            \n",
      "[1330]\ttrain-mlogloss:0.90154\tvalidate-mlogloss:0.88596                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.07468\tvalidate-mlogloss:1.07308                               \n",
      "[200]\ttrain-mlogloss:0.90509\tvalidate-mlogloss:0.90612                             \n",
      "[400]\ttrain-mlogloss:0.90284\tvalidate-mlogloss:0.90519                             \n",
      "[600]\ttrain-mlogloss:0.90103\tvalidate-mlogloss:0.90497                             \n",
      "[800]\ttrain-mlogloss:0.90015\tvalidate-mlogloss:0.90441                             \n",
      "[1000]\ttrain-mlogloss:0.89953\tvalidate-mlogloss:0.90349                            \n",
      "[1200]\ttrain-mlogloss:0.89924\tvalidate-mlogloss:0.90391                            \n",
      "[1330]\ttrain-mlogloss:0.89888\tvalidate-mlogloss:0.90244                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07334\tvalidate-mlogloss:1.07314                               \n",
      "[200]\ttrain-mlogloss:0.90316\tvalidate-mlogloss:0.90164                             \n",
      "[400]\ttrain-mlogloss:0.90038\tvalidate-mlogloss:0.89950                             \n",
      "[600]\ttrain-mlogloss:0.89921\tvalidate-mlogloss:0.89979                             \n",
      "[800]\ttrain-mlogloss:0.89807\tvalidate-mlogloss:0.89909                             \n",
      "[1000]\ttrain-mlogloss:0.89727\tvalidate-mlogloss:0.89817                            \n",
      "[1200]\ttrain-mlogloss:0.89671\tvalidate-mlogloss:0.89930                            \n",
      "[1330]\ttrain-mlogloss:0.89646\tvalidate-mlogloss:0.89826                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.895553390223605                                                \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.6, 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.22578846734634156, 'max_delta_step': 1, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 997, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06046\tvalidate-mlogloss:1.05705                               \n",
      "[200]\ttrain-mlogloss:0.80313\tvalidate-mlogloss:0.86749                             \n",
      "[400]\ttrain-mlogloss:0.75752\tvalidate-mlogloss:0.86400                             \n",
      "[600]\ttrain-mlogloss:0.72975\tvalidate-mlogloss:0.86109                             \n",
      "[800]\ttrain-mlogloss:0.71070\tvalidate-mlogloss:0.85992                             \n",
      "[996]\ttrain-mlogloss:0.69450\tvalidate-mlogloss:0.85643                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06124\tvalidate-mlogloss:1.06006                               \n",
      "[200]\ttrain-mlogloss:0.79978\tvalidate-mlogloss:0.87591                             \n",
      "[400]\ttrain-mlogloss:0.75498\tvalidate-mlogloss:0.87015                             \n",
      "[600]\ttrain-mlogloss:0.72637\tvalidate-mlogloss:0.86662                             \n",
      "[800]\ttrain-mlogloss:0.70483\tvalidate-mlogloss:0.86636                             \n",
      "[996]\ttrain-mlogloss:0.68939\tvalidate-mlogloss:0.86309                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.05964\tvalidate-mlogloss:1.05877                               \n",
      "[200]\ttrain-mlogloss:0.79938\tvalidate-mlogloss:0.87109                             \n",
      "[400]\ttrain-mlogloss:0.75199\tvalidate-mlogloss:0.86584                             \n",
      "[600]\ttrain-mlogloss:0.72374\tvalidate-mlogloss:0.86409                             \n",
      "[800]\ttrain-mlogloss:0.70237\tvalidate-mlogloss:0.86348                             \n",
      "[996]\ttrain-mlogloss:0.68782\tvalidate-mlogloss:0.86146                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8603236752640672                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 10, 'learning_rate': 0.0029729193284216693, 'max_delta_step': 6, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 1181, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09799\tvalidate-mlogloss:1.09796                               \n",
      "[200]\ttrain-mlogloss:1.01211\tvalidate-mlogloss:1.00606                             \n",
      "[400]\ttrain-mlogloss:0.96619\tvalidate-mlogloss:0.95919                             \n",
      "[600]\ttrain-mlogloss:0.93865\tvalidate-mlogloss:0.93268                             \n",
      "[800]\ttrain-mlogloss:0.92052\tvalidate-mlogloss:0.91639                             \n",
      "[1000]\ttrain-mlogloss:0.90737\tvalidate-mlogloss:0.90520                            \n",
      "[1180]\ttrain-mlogloss:0.89849\tvalidate-mlogloss:0.89824                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09795\tvalidate-mlogloss:1.09797                               \n",
      "[200]\ttrain-mlogloss:1.00971\tvalidate-mlogloss:1.00999                             \n",
      "[400]\ttrain-mlogloss:0.96283\tvalidate-mlogloss:0.96461                             \n",
      "[600]\ttrain-mlogloss:0.93524\tvalidate-mlogloss:0.93892                             \n",
      "[800]\ttrain-mlogloss:0.91669\tvalidate-mlogloss:0.92282                             \n",
      "[1000]\ttrain-mlogloss:0.90349\tvalidate-mlogloss:0.91200                            \n",
      "[1180]\ttrain-mlogloss:0.89445\tvalidate-mlogloss:0.90513                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09796\tvalidate-mlogloss:1.09799                               \n",
      "[200]\ttrain-mlogloss:1.01064\tvalidate-mlogloss:1.01283                             \n",
      "[400]\ttrain-mlogloss:0.96394\tvalidate-mlogloss:0.96850                             \n",
      "[600]\ttrain-mlogloss:0.93633\tvalidate-mlogloss:0.94301                             \n",
      "[800]\ttrain-mlogloss:0.91801\tvalidate-mlogloss:0.92708                             \n",
      "[1000]\ttrain-mlogloss:0.90517\tvalidate-mlogloss:0.91666                            \n",
      "[1180]\ttrain-mlogloss:0.89597\tvalidate-mlogloss:0.90976                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.9043736899332094                                               \n",
      "{'booster_params': {'alpha': 10, 'booster': 'gbtree', 'colsample_bylevel': 0.6, 'colsample_bynode': 0.9, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 10, 'learning_rate': 0.09001343669173092, 'max_delta_step': 3, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.6, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 929, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08289\tvalidate-mlogloss:1.08157                               \n",
      "[200]\ttrain-mlogloss:0.90572\tvalidate-mlogloss:0.89180                             \n",
      "[400]\ttrain-mlogloss:0.90006\tvalidate-mlogloss:0.88841                             \n",
      "[600]\ttrain-mlogloss:0.89821\tvalidate-mlogloss:0.88724                             \n",
      "[800]\ttrain-mlogloss:0.89651\tvalidate-mlogloss:0.88702                             \n",
      "[928]\ttrain-mlogloss:0.89582\tvalidate-mlogloss:0.88645                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08441\tvalidate-mlogloss:1.08277                               \n",
      "[200]\ttrain-mlogloss:0.90148\tvalidate-mlogloss:0.89576                             \n",
      "[400]\ttrain-mlogloss:0.89652\tvalidate-mlogloss:0.89345                             \n",
      "[600]\ttrain-mlogloss:0.89474\tvalidate-mlogloss:0.89340                             \n",
      "[800]\ttrain-mlogloss:0.89308\tvalidate-mlogloss:0.89356                             \n",
      "[928]\ttrain-mlogloss:0.89233\tvalidate-mlogloss:0.89295                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08180\tvalidate-mlogloss:1.08177                               \n",
      "[200]\ttrain-mlogloss:0.89961\tvalidate-mlogloss:0.89930                             \n",
      "[400]\ttrain-mlogloss:0.89406\tvalidate-mlogloss:0.89761                             \n",
      "[600]\ttrain-mlogloss:0.89245\tvalidate-mlogloss:0.89783                             \n",
      "[785]\ttrain-mlogloss:0.89053\tvalidate-mlogloss:0.89795                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8924280830898083                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.06315114097249189, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 509, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08088\tvalidate-mlogloss:1.08189                               \n",
      "[200]\ttrain-mlogloss:0.60062\tvalidate-mlogloss:0.83669                             \n",
      "[400]\ttrain-mlogloss:0.46518\tvalidate-mlogloss:0.82743                             \n",
      "[508]\ttrain-mlogloss:0.42222\tvalidate-mlogloss:0.82607                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08179\tvalidate-mlogloss:1.08333                               \n",
      "[200]\ttrain-mlogloss:0.59875\tvalidate-mlogloss:0.84806                             \n",
      "[400]\ttrain-mlogloss:0.46139\tvalidate-mlogloss:0.83445                             \n",
      "[508]\ttrain-mlogloss:0.41803\tvalidate-mlogloss:0.83437                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08072\tvalidate-mlogloss:1.08197                               \n",
      "[200]\ttrain-mlogloss:0.59715\tvalidate-mlogloss:0.84114                             \n",
      "[400]\ttrain-mlogloss:0.46081\tvalidate-mlogloss:0.83237                             \n",
      "[508]\ttrain-mlogloss:0.41956\tvalidate-mlogloss:0.83090                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8304423752363624                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 1, 'learning_rate': 0.01915433398903857, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1683, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09378\tvalidate-mlogloss:1.09367                               \n",
      "[200]\ttrain-mlogloss:0.87763\tvalidate-mlogloss:0.88875                             \n",
      "[400]\ttrain-mlogloss:0.86163\tvalidate-mlogloss:0.88097                             \n",
      "[600]\ttrain-mlogloss:0.85639\tvalidate-mlogloss:0.87953                             \n",
      "[800]\ttrain-mlogloss:0.85319\tvalidate-mlogloss:0.87816                             \n",
      "[1000]\ttrain-mlogloss:0.85072\tvalidate-mlogloss:0.87707                            \n",
      "[1200]\ttrain-mlogloss:0.84874\tvalidate-mlogloss:0.87644                            \n",
      "[1400]\ttrain-mlogloss:0.84724\tvalidate-mlogloss:0.87586                            \n",
      "[1600]\ttrain-mlogloss:0.84552\tvalidate-mlogloss:0.87565                            \n",
      "[1682]\ttrain-mlogloss:0.84499\tvalidate-mlogloss:0.87557                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09383\tvalidate-mlogloss:1.09406                               \n",
      "[200]\ttrain-mlogloss:0.87155\tvalidate-mlogloss:0.89683                             \n",
      "[400]\ttrain-mlogloss:0.85456\tvalidate-mlogloss:0.88946                             \n",
      "[600]\ttrain-mlogloss:0.85003\tvalidate-mlogloss:0.88760                             \n",
      "[800]\ttrain-mlogloss:0.84657\tvalidate-mlogloss:0.88725                             \n",
      "[1000]\ttrain-mlogloss:0.84423\tvalidate-mlogloss:0.88691                            \n",
      "[1200]\ttrain-mlogloss:0.84271\tvalidate-mlogloss:0.88643                            \n",
      "[1400]\ttrain-mlogloss:0.84109\tvalidate-mlogloss:0.88570                            \n",
      "[1600]\ttrain-mlogloss:0.83983\tvalidate-mlogloss:0.88488                            \n",
      "[1682]\ttrain-mlogloss:0.83954\tvalidate-mlogloss:0.88485                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09384\tvalidate-mlogloss:1.09378                               \n",
      "[200]\ttrain-mlogloss:0.87078\tvalidate-mlogloss:0.88787                             \n",
      "[400]\ttrain-mlogloss:0.85404\tvalidate-mlogloss:0.87855                             \n",
      "[600]\ttrain-mlogloss:0.84898\tvalidate-mlogloss:0.87740                             \n",
      "[800]\ttrain-mlogloss:0.84603\tvalidate-mlogloss:0.87636                             \n",
      "[1000]\ttrain-mlogloss:0.84363\tvalidate-mlogloss:0.87564                            \n",
      "[1200]\ttrain-mlogloss:0.84199\tvalidate-mlogloss:0.87545                            \n",
      "[1400]\ttrain-mlogloss:0.84025\tvalidate-mlogloss:0.87488                            \n",
      "[1600]\ttrain-mlogloss:0.83871\tvalidate-mlogloss:0.87545                            \n",
      "[1682]\ttrain-mlogloss:0.83812\tvalidate-mlogloss:0.87542                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8786155531553418                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 1, 'learning_rate': 0.04451981745359676, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1457, 'num_feat': 70, 'step': 0.3}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08751\tvalidate-mlogloss:1.08764                               \n",
      "[200]\ttrain-mlogloss:0.83074\tvalidate-mlogloss:0.86958                             \n",
      "[400]\ttrain-mlogloss:0.81668\tvalidate-mlogloss:0.86595                             \n",
      "[600]\ttrain-mlogloss:0.80836\tvalidate-mlogloss:0.86324                             \n",
      "[800]\ttrain-mlogloss:0.80386\tvalidate-mlogloss:0.86226                             \n",
      "[1000]\ttrain-mlogloss:0.79977\tvalidate-mlogloss:0.86059                            \n",
      "[1200]\ttrain-mlogloss:0.79652\tvalidate-mlogloss:0.85984                            \n",
      "[1400]\ttrain-mlogloss:0.79362\tvalidate-mlogloss:0.85868                            \n",
      "[1456]\ttrain-mlogloss:0.79289\tvalidate-mlogloss:0.85837                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08700\tvalidate-mlogloss:1.08758                               \n",
      "[200]\ttrain-mlogloss:0.82513\tvalidate-mlogloss:0.87798                             \n",
      "[400]\ttrain-mlogloss:0.81291\tvalidate-mlogloss:0.87551                             \n",
      "[600]\ttrain-mlogloss:0.80626\tvalidate-mlogloss:0.87257                             \n",
      "[800]\ttrain-mlogloss:0.80138\tvalidate-mlogloss:0.87140                             \n",
      "[1000]\ttrain-mlogloss:0.79828\tvalidate-mlogloss:0.87013                            \n",
      "[1200]\ttrain-mlogloss:0.79567\tvalidate-mlogloss:0.86932                            \n",
      "[1400]\ttrain-mlogloss:0.79273\tvalidate-mlogloss:0.86795                            \n",
      "[1456]\ttrain-mlogloss:0.79157\tvalidate-mlogloss:0.86688                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08743\tvalidate-mlogloss:1.08840                               \n",
      "[200]\ttrain-mlogloss:0.82824\tvalidate-mlogloss:0.88024                             \n",
      "[400]\ttrain-mlogloss:0.81387\tvalidate-mlogloss:0.87571                             \n",
      "[600]\ttrain-mlogloss:0.80737\tvalidate-mlogloss:0.87390                             \n",
      "[800]\ttrain-mlogloss:0.80250\tvalidate-mlogloss:0.87238                             \n",
      "[1000]\ttrain-mlogloss:0.79826\tvalidate-mlogloss:0.87093                            \n",
      "[1200]\ttrain-mlogloss:0.79589\tvalidate-mlogloss:0.87110                            \n",
      "[1400]\ttrain-mlogloss:0.79313\tvalidate-mlogloss:0.86953                            \n",
      "[1456]\ttrain-mlogloss:0.79275\tvalidate-mlogloss:0.87000                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8650800924128331                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.14040216668277422, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1557, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.06036\tvalidate-mlogloss:1.06254                               \n",
      "[200]\ttrain-mlogloss:0.43802\tvalidate-mlogloss:0.83948                             \n",
      "[400]\ttrain-mlogloss:0.35180\tvalidate-mlogloss:0.84580                             \n",
      "[586]\ttrain-mlogloss:0.32859\tvalidate-mlogloss:0.84894                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.06229\tvalidate-mlogloss:1.06565                               \n",
      "[200]\ttrain-mlogloss:0.44074\tvalidate-mlogloss:0.84630                             \n",
      "[400]\ttrain-mlogloss:0.35064\tvalidate-mlogloss:0.85397                             \n",
      "[580]\ttrain-mlogloss:0.32768\tvalidate-mlogloss:0.85841                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.06000\tvalidate-mlogloss:1.06274                               \n",
      "[200]\ttrain-mlogloss:0.44088\tvalidate-mlogloss:0.84097                             \n",
      "[400]\ttrain-mlogloss:0.34993\tvalidate-mlogloss:0.84476                             \n",
      "[588]\ttrain-mlogloss:0.32754\tvalidate-mlogloss:0.84808                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8517890598304368                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.07375756683710943, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1956, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.07799\tvalidate-mlogloss:1.07916                               \n",
      "[200]\ttrain-mlogloss:0.57623\tvalidate-mlogloss:0.83547                             \n",
      "[400]\ttrain-mlogloss:0.43584\tvalidate-mlogloss:0.82875                             \n",
      "[600]\ttrain-mlogloss:0.37869\tvalidate-mlogloss:0.82902                             \n",
      "[800]\ttrain-mlogloss:0.35420\tvalidate-mlogloss:0.83095                             \n",
      "[819]\ttrain-mlogloss:0.35272\tvalidate-mlogloss:0.83109                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.07904\tvalidate-mlogloss:1.08084                               \n",
      "[200]\ttrain-mlogloss:0.56660\tvalidate-mlogloss:0.84128                             \n",
      "[400]\ttrain-mlogloss:0.43179\tvalidate-mlogloss:0.83382                             \n",
      "[600]\ttrain-mlogloss:0.37638\tvalidate-mlogloss:0.83520                             \n",
      "[800]\ttrain-mlogloss:0.35280\tvalidate-mlogloss:0.83726                             \n",
      "[806]\ttrain-mlogloss:0.35240\tvalidate-mlogloss:0.83717                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.07780\tvalidate-mlogloss:1.07926                               \n",
      "[200]\ttrain-mlogloss:0.56598\tvalidate-mlogloss:0.83950                             \n",
      "[400]\ttrain-mlogloss:0.42884\tvalidate-mlogloss:0.83494                             \n",
      "[600]\ttrain-mlogloss:0.37464\tvalidate-mlogloss:0.83576                             \n",
      "[757]\ttrain-mlogloss:0.35424\tvalidate-mlogloss:0.83707                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8351224230952147                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.058811738084435725, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 509, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08207\tvalidate-mlogloss:1.08301                               \n",
      "[200]\ttrain-mlogloss:0.61367\tvalidate-mlogloss:0.83930                             \n",
      "[400]\ttrain-mlogloss:0.47706\tvalidate-mlogloss:0.82907                             \n",
      "[508]\ttrain-mlogloss:0.43171\tvalidate-mlogloss:0.82714                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08292\tvalidate-mlogloss:1.08436                               \n",
      "[200]\ttrain-mlogloss:0.61260\tvalidate-mlogloss:0.84573                             \n",
      "[400]\ttrain-mlogloss:0.47505\tvalidate-mlogloss:0.83397                             \n",
      "[508]\ttrain-mlogloss:0.43012\tvalidate-mlogloss:0.83317                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08192\tvalidate-mlogloss:1.08309                               \n",
      "[200]\ttrain-mlogloss:0.60781\tvalidate-mlogloss:0.83998                             \n",
      "[400]\ttrain-mlogloss:0.47238\tvalidate-mlogloss:0.82965                             \n",
      "[508]\ttrain-mlogloss:0.42934\tvalidate-mlogloss:0.82862                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8296406027201885                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.06314121514100657, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 684, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.08089\tvalidate-mlogloss:1.08189                               \n",
      "[200]\ttrain-mlogloss:0.60166\tvalidate-mlogloss:0.83750                             \n",
      "[400]\ttrain-mlogloss:0.46335\tvalidate-mlogloss:0.82845                             \n",
      "[600]\ttrain-mlogloss:0.39804\tvalidate-mlogloss:0.82655                             \n",
      "[683]\ttrain-mlogloss:0.38191\tvalidate-mlogloss:0.82702                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.08179\tvalidate-mlogloss:1.08333                               \n",
      "[200]\ttrain-mlogloss:0.60102\tvalidate-mlogloss:0.85031                             \n",
      "[400]\ttrain-mlogloss:0.46176\tvalidate-mlogloss:0.83693                             \n",
      "[600]\ttrain-mlogloss:0.39542\tvalidate-mlogloss:0.83471                             \n",
      "[683]\ttrain-mlogloss:0.38029\tvalidate-mlogloss:0.83501                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.08072\tvalidate-mlogloss:1.08197                               \n",
      "[200]\ttrain-mlogloss:0.59330\tvalidate-mlogloss:0.84009                             \n",
      "[400]\ttrain-mlogloss:0.45858\tvalidate-mlogloss:0.83048                             \n",
      "[600]\ttrain-mlogloss:0.39421\tvalidate-mlogloss:0.82995                             \n",
      "[683]\ttrain-mlogloss:0.38003\tvalidate-mlogloss:0.83016                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8307288280268392                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.013959493730327316, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1316, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09462\tvalidate-mlogloss:1.09485                               \n",
      "[200]\ttrain-mlogloss:0.80664\tvalidate-mlogloss:0.87516                             \n",
      "[400]\ttrain-mlogloss:0.72594\tvalidate-mlogloss:0.85208                             \n",
      "[600]\ttrain-mlogloss:0.66962\tvalidate-mlogloss:0.84179                             \n",
      "[800]\ttrain-mlogloss:0.62163\tvalidate-mlogloss:0.83479                             \n",
      "[1000]\ttrain-mlogloss:0.58088\tvalidate-mlogloss:0.83079                            \n",
      "[1200]\ttrain-mlogloss:0.54490\tvalidate-mlogloss:0.82734                            \n",
      "[1315]\ttrain-mlogloss:0.52585\tvalidate-mlogloss:0.82570                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09482\tvalidate-mlogloss:1.09517                               \n",
      "[200]\ttrain-mlogloss:0.80264\tvalidate-mlogloss:0.88307                             \n",
      "[400]\ttrain-mlogloss:0.72125\tvalidate-mlogloss:0.85900                             \n",
      "[600]\ttrain-mlogloss:0.66627\tvalidate-mlogloss:0.84908                             \n",
      "[800]\ttrain-mlogloss:0.61961\tvalidate-mlogloss:0.84268                             \n",
      "[1000]\ttrain-mlogloss:0.57867\tvalidate-mlogloss:0.83771                            \n",
      "[1200]\ttrain-mlogloss:0.54220\tvalidate-mlogloss:0.83367                            \n",
      "[1315]\ttrain-mlogloss:0.52327\tvalidate-mlogloss:0.83158                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09458\tvalidate-mlogloss:1.09486                               \n",
      "[200]\ttrain-mlogloss:0.80100\tvalidate-mlogloss:0.87749                             \n",
      "[400]\ttrain-mlogloss:0.71905\tvalidate-mlogloss:0.85417                             \n",
      "[600]\ttrain-mlogloss:0.66407\tvalidate-mlogloss:0.84506                             \n",
      "[800]\ttrain-mlogloss:0.61587\tvalidate-mlogloss:0.83866                             \n",
      "[1000]\ttrain-mlogloss:0.57536\tvalidate-mlogloss:0.83377                            \n",
      "[1200]\ttrain-mlogloss:0.53990\tvalidate-mlogloss:0.83018                            \n",
      "[1315]\ttrain-mlogloss:0.52122\tvalidate-mlogloss:0.82849                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.8285900189633862                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.02213046288151048, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 1043, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09230\tvalidate-mlogloss:1.09266                               \n",
      "[200]\ttrain-mlogloss:0.75492\tvalidate-mlogloss:0.85870                             \n",
      "[400]\ttrain-mlogloss:0.66318\tvalidate-mlogloss:0.84222                             \n",
      "[600]\ttrain-mlogloss:0.59073\tvalidate-mlogloss:0.83213                             \n",
      "[800]\ttrain-mlogloss:0.53276\tvalidate-mlogloss:0.82726                             \n",
      "[1000]\ttrain-mlogloss:0.48822\tvalidate-mlogloss:0.82440                            \n",
      "[1042]\ttrain-mlogloss:0.48014\tvalidate-mlogloss:0.82387                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09262\tvalidate-mlogloss:1.09317                               \n",
      "[200]\ttrain-mlogloss:0.74806\tvalidate-mlogloss:0.86486                             \n",
      "[400]\ttrain-mlogloss:0.65846\tvalidate-mlogloss:0.84889                             \n",
      "[600]\ttrain-mlogloss:0.58882\tvalidate-mlogloss:0.83933                             \n",
      "[800]\ttrain-mlogloss:0.53247\tvalidate-mlogloss:0.83375                             \n",
      "[1000]\ttrain-mlogloss:0.48710\tvalidate-mlogloss:0.82994                            \n",
      "[1042]\ttrain-mlogloss:0.47920\tvalidate-mlogloss:0.82910                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09224\tvalidate-mlogloss:1.09269                               \n",
      "[200]\ttrain-mlogloss:0.74604\tvalidate-mlogloss:0.86018                             \n",
      "[400]\ttrain-mlogloss:0.65534\tvalidate-mlogloss:0.84479                             \n",
      "[600]\ttrain-mlogloss:0.58474\tvalidate-mlogloss:0.83611                             \n",
      "[800]\ttrain-mlogloss:0.52790\tvalidate-mlogloss:0.82999                             \n",
      "[1000]\ttrain-mlogloss:0.48368\tvalidate-mlogloss:0.82696                            \n",
      "[1042]\ttrain-mlogloss:0.47633\tvalidate-mlogloss:0.82648                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.826485621314395                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 1, 'learning_rate': 0.003137599900522949, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 30, 'num_boost_round': 934, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09787\tvalidate-mlogloss:1.09782                               \n",
      "[200]\ttrain-mlogloss:1.00053\tvalidate-mlogloss:0.99642                             \n",
      "[400]\ttrain-mlogloss:0.95387\tvalidate-mlogloss:0.94853                             \n",
      "[600]\ttrain-mlogloss:0.92897\tvalidate-mlogloss:0.92341                             \n",
      "[800]\ttrain-mlogloss:0.91469\tvalidate-mlogloss:0.90997                             \n",
      "[933]\ttrain-mlogloss:0.90841\tvalidate-mlogloss:0.90438                             \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09786\tvalidate-mlogloss:1.09792                               \n",
      "[200]\ttrain-mlogloss:0.99858\tvalidate-mlogloss:1.00098                             \n",
      "[400]\ttrain-mlogloss:0.95088\tvalidate-mlogloss:0.95455                             \n",
      "[600]\ttrain-mlogloss:0.92563\tvalidate-mlogloss:0.93035                             \n",
      "[800]\ttrain-mlogloss:0.91079\tvalidate-mlogloss:0.91654                             \n",
      "[933]\ttrain-mlogloss:0.90417\tvalidate-mlogloss:0.91081                             \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09787\tvalidate-mlogloss:1.09785                               \n",
      "[200]\ttrain-mlogloss:0.99794\tvalidate-mlogloss:0.99545                             \n",
      "[400]\ttrain-mlogloss:0.95032\tvalidate-mlogloss:0.94759                             \n",
      "[600]\ttrain-mlogloss:0.92478\tvalidate-mlogloss:0.92286                             \n",
      "[800]\ttrain-mlogloss:0.91008\tvalidate-mlogloss:0.90904                             \n",
      "[933]\ttrain-mlogloss:0.90321\tvalidate-mlogloss:0.90320                             \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.9061305843014956                                               \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.014666052411703897, 'max_delta_step': 8, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1586, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))        \n",
      "Start training model for fold 1...                                                 \n",
      "[0]\ttrain-mlogloss:1.09442\tvalidate-mlogloss:1.09466                               \n",
      "[200]\ttrain-mlogloss:0.80201\tvalidate-mlogloss:0.87381                             \n",
      "[400]\ttrain-mlogloss:0.71971\tvalidate-mlogloss:0.85076                             \n",
      "[600]\ttrain-mlogloss:0.66156\tvalidate-mlogloss:0.84071                             \n",
      "[800]\ttrain-mlogloss:0.61263\tvalidate-mlogloss:0.83407                             \n",
      "[1000]\ttrain-mlogloss:0.57084\tvalidate-mlogloss:0.82986                            \n",
      "[1200]\ttrain-mlogloss:0.53512\tvalidate-mlogloss:0.82648                            \n",
      "[1400]\ttrain-mlogloss:0.50317\tvalidate-mlogloss:0.82385                            \n",
      "[1585]\ttrain-mlogloss:0.47850\tvalidate-mlogloss:0.82201                            \n",
      "Predicting for fold 1...                                                           \n",
      "Start processing fold 2...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))        \n",
      "Start training model for fold 2...                                                 \n",
      "[0]\ttrain-mlogloss:1.09463\tvalidate-mlogloss:1.09500                               \n",
      "[200]\ttrain-mlogloss:0.79589\tvalidate-mlogloss:0.88108                             \n",
      "[400]\ttrain-mlogloss:0.71412\tvalidate-mlogloss:0.85998                             \n",
      "[600]\ttrain-mlogloss:0.65804\tvalidate-mlogloss:0.85067                             \n",
      "[800]\ttrain-mlogloss:0.61039\tvalidate-mlogloss:0.84401                             \n",
      "[1000]\ttrain-mlogloss:0.56845\tvalidate-mlogloss:0.83868                            \n",
      "[1200]\ttrain-mlogloss:0.53273\tvalidate-mlogloss:0.83462                            \n",
      "[1400]\ttrain-mlogloss:0.50141\tvalidate-mlogloss:0.83133                            \n",
      "[1585]\ttrain-mlogloss:0.47702\tvalidate-mlogloss:0.82909                            \n",
      "Predicting for fold 2...                                                           \n",
      "Start processing fold 3...                                                         \n",
      "Class distribution:                                                                \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                   \n",
      "Class instance weights:                                                            \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))        \n",
      "Start training model for fold 3...                                                 \n",
      "[0]\ttrain-mlogloss:1.09438\tvalidate-mlogloss:1.09467                               \n",
      "[200]\ttrain-mlogloss:0.79526\tvalidate-mlogloss:0.87460                             \n",
      "[400]\ttrain-mlogloss:0.71270\tvalidate-mlogloss:0.85309                             \n",
      "[600]\ttrain-mlogloss:0.65667\tvalidate-mlogloss:0.84355                             \n",
      "[800]\ttrain-mlogloss:0.60798\tvalidate-mlogloss:0.83745                             \n",
      "[1000]\ttrain-mlogloss:0.56494\tvalidate-mlogloss:0.83246                            \n",
      "[1200]\ttrain-mlogloss:0.52888\tvalidate-mlogloss:0.82876                            \n",
      "[1400]\ttrain-mlogloss:0.49803\tvalidate-mlogloss:0.82636                            \n",
      "[1585]\ttrain-mlogloss:0.47372\tvalidate-mlogloss:0.82477                            \n",
      "Predicting for fold 3...                                                           \n",
      "Average log loss: 0.82529292075083                                                 \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 1, 'learning_rate': 0.037200358921863685, 'max_delta_step': 5, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1488, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.08783\tvalidate-mlogloss:1.08892                              \n",
      "[200]\ttrain-mlogloss:0.77624\tvalidate-mlogloss:0.86225                            \n",
      "[400]\ttrain-mlogloss:0.75778\tvalidate-mlogloss:0.85852                            \n",
      "[600]\ttrain-mlogloss:0.74731\tvalidate-mlogloss:0.85620                            \n",
      "[800]\ttrain-mlogloss:0.74106\tvalidate-mlogloss:0.85489                            \n",
      "[1000]\ttrain-mlogloss:0.73660\tvalidate-mlogloss:0.85424                           \n",
      "[1200]\ttrain-mlogloss:0.73186\tvalidate-mlogloss:0.85279                           \n",
      "[1400]\ttrain-mlogloss:0.72766\tvalidate-mlogloss:0.85198                           \n",
      "[1487]\ttrain-mlogloss:0.72643\tvalidate-mlogloss:0.85196                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.08762\tvalidate-mlogloss:1.08952                              \n",
      "[200]\ttrain-mlogloss:0.77312\tvalidate-mlogloss:0.87228                            \n",
      "[400]\ttrain-mlogloss:0.75421\tvalidate-mlogloss:0.86786                            \n",
      "[600]\ttrain-mlogloss:0.74410\tvalidate-mlogloss:0.86401                            \n",
      "[800]\ttrain-mlogloss:0.73800\tvalidate-mlogloss:0.86370                            \n",
      "[1000]\ttrain-mlogloss:0.73283\tvalidate-mlogloss:0.86242                           \n",
      "[1200]\ttrain-mlogloss:0.72914\tvalidate-mlogloss:0.86171                           \n",
      "[1400]\ttrain-mlogloss:0.72595\tvalidate-mlogloss:0.86031                           \n",
      "[1487]\ttrain-mlogloss:0.72431\tvalidate-mlogloss:0.85926                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.08798\tvalidate-mlogloss:1.08879                              \n",
      "[200]\ttrain-mlogloss:0.77075\tvalidate-mlogloss:0.86414                            \n",
      "[400]\ttrain-mlogloss:0.74945\tvalidate-mlogloss:0.85989                            \n",
      "[600]\ttrain-mlogloss:0.74082\tvalidate-mlogloss:0.85845                            \n",
      "[800]\ttrain-mlogloss:0.73506\tvalidate-mlogloss:0.85725                            \n",
      "[1000]\ttrain-mlogloss:0.73065\tvalidate-mlogloss:0.85641                           \n",
      "[1200]\ttrain-mlogloss:0.72668\tvalidate-mlogloss:0.85600                           \n",
      "[1400]\ttrain-mlogloss:0.72347\tvalidate-mlogloss:0.85504                           \n",
      "[1487]\ttrain-mlogloss:0.72182\tvalidate-mlogloss:0.85486                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8553574764460535                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 1, 'learning_rate': 0.021599909650409227, 'max_delta_step': 4, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 796, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.09285\tvalidate-mlogloss:1.09329                              \n",
      "[200]\ttrain-mlogloss:0.79489\tvalidate-mlogloss:0.86625                            \n",
      "[400]\ttrain-mlogloss:0.71812\tvalidate-mlogloss:0.85023                            \n",
      "[600]\ttrain-mlogloss:0.65591\tvalidate-mlogloss:0.84114                            \n",
      "[795]\ttrain-mlogloss:0.60244\tvalidate-mlogloss:0.83531                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.09274\tvalidate-mlogloss:1.09338                              \n",
      "[200]\ttrain-mlogloss:0.78996\tvalidate-mlogloss:0.87477                            \n",
      "[400]\ttrain-mlogloss:0.71326\tvalidate-mlogloss:0.85982                            \n",
      "[600]\ttrain-mlogloss:0.65301\tvalidate-mlogloss:0.85098                            \n",
      "[795]\ttrain-mlogloss:0.60028\tvalidate-mlogloss:0.84486                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.09316\tvalidate-mlogloss:1.09331                              \n",
      "[200]\ttrain-mlogloss:0.78791\tvalidate-mlogloss:0.86670                            \n",
      "[400]\ttrain-mlogloss:0.71047\tvalidate-mlogloss:0.85158                            \n",
      "[600]\ttrain-mlogloss:0.64862\tvalidate-mlogloss:0.84336                            \n",
      "[795]\ttrain-mlogloss:0.59587\tvalidate-mlogloss:0.83766                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8392737968900396                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.047623391477938384, 'max_delta_step': 9, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 978, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.08665\tvalidate-mlogloss:1.08708                              \n",
      "[200]\ttrain-mlogloss:0.75452\tvalidate-mlogloss:0.85618                            \n",
      "[400]\ttrain-mlogloss:0.66077\tvalidate-mlogloss:0.84438                            \n",
      "[600]\ttrain-mlogloss:0.58980\tvalidate-mlogloss:0.83701                            \n",
      "[800]\ttrain-mlogloss:0.53898\tvalidate-mlogloss:0.83248                            \n",
      "[977]\ttrain-mlogloss:0.50701\tvalidate-mlogloss:0.83052                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.08670\tvalidate-mlogloss:1.08770                              \n",
      "[200]\ttrain-mlogloss:0.74997\tvalidate-mlogloss:0.86784                            \n",
      "[400]\ttrain-mlogloss:0.65684\tvalidate-mlogloss:0.85399                            \n",
      "[600]\ttrain-mlogloss:0.58684\tvalidate-mlogloss:0.84561                            \n",
      "[800]\ttrain-mlogloss:0.53508\tvalidate-mlogloss:0.84042                            \n",
      "[977]\ttrain-mlogloss:0.50449\tvalidate-mlogloss:0.83729                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.08683\tvalidate-mlogloss:1.08693                              \n",
      "[200]\ttrain-mlogloss:0.74846\tvalidate-mlogloss:0.86035                            \n",
      "[400]\ttrain-mlogloss:0.65338\tvalidate-mlogloss:0.84796                            \n",
      "[600]\ttrain-mlogloss:0.58454\tvalidate-mlogloss:0.84069                            \n",
      "[800]\ttrain-mlogloss:0.53527\tvalidate-mlogloss:0.83612                            \n",
      "[977]\ttrain-mlogloss:0.50286\tvalidate-mlogloss:0.83349                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8337665144691878                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 1.0, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 1, 'learning_rate': 0.011077200849783008, 'max_delta_step': 1, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 626, 'num_feat': 80, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.09547\tvalidate-mlogloss:1.09562                              \n",
      "[200]\ttrain-mlogloss:0.83615\tvalidate-mlogloss:0.88781                            \n",
      "[400]\ttrain-mlogloss:0.76205\tvalidate-mlogloss:0.85656                            \n",
      "[600]\ttrain-mlogloss:0.71865\tvalidate-mlogloss:0.84579                            \n",
      "[625]\ttrain-mlogloss:0.71379\tvalidate-mlogloss:0.84466                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.09556\tvalidate-mlogloss:1.09583                              \n",
      "[200]\ttrain-mlogloss:0.83238\tvalidate-mlogloss:0.89355                            \n",
      "[400]\ttrain-mlogloss:0.75646\tvalidate-mlogloss:0.86500                            \n",
      "[600]\ttrain-mlogloss:0.71421\tvalidate-mlogloss:0.85554                            \n",
      "[625]\ttrain-mlogloss:0.70996\tvalidate-mlogloss:0.85468                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.09544\tvalidate-mlogloss:1.09594                              \n",
      "[200]\ttrain-mlogloss:0.83009\tvalidate-mlogloss:0.89581                            \n",
      "[400]\ttrain-mlogloss:0.75537\tvalidate-mlogloss:0.86640                            \n",
      "[600]\ttrain-mlogloss:0.71280\tvalidate-mlogloss:0.85705                            \n",
      "[625]\ttrain-mlogloss:0.70832\tvalidate-mlogloss:0.85616                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8518340830561617                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.9, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 1, 'learning_rate': 0.025106515341400314, 'max_delta_step': 7, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 578, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.09299\tvalidate-mlogloss:1.09309                              \n",
      "[200]\ttrain-mlogloss:0.87842\tvalidate-mlogloss:0.88298                            \n",
      "[400]\ttrain-mlogloss:0.84828\tvalidate-mlogloss:0.86884                            \n",
      "[577]\ttrain-mlogloss:0.83027\tvalidate-mlogloss:0.86294                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.09277\tvalidate-mlogloss:1.09285                              \n",
      "[200]\ttrain-mlogloss:0.87384\tvalidate-mlogloss:0.89090                            \n",
      "[400]\ttrain-mlogloss:0.84293\tvalidate-mlogloss:0.88495                            \n",
      "[577]\ttrain-mlogloss:0.82626\tvalidate-mlogloss:0.88244                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.09319\tvalidate-mlogloss:1.09332                              \n",
      "[200]\ttrain-mlogloss:0.87366\tvalidate-mlogloss:0.89148                            \n",
      "[400]\ttrain-mlogloss:0.84294\tvalidate-mlogloss:0.87975                            \n",
      "[577]\ttrain-mlogloss:0.82642\tvalidate-mlogloss:0.87736                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8742445489227126                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.28008143059585844, 'max_delta_step': 8, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 791, 'num_feat': 50, 'step': 0.3}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.01127\tvalidate-mlogloss:1.03072                              \n",
      "[200]\ttrain-mlogloss:0.45920\tvalidate-mlogloss:0.83669                            \n",
      "[400]\ttrain-mlogloss:0.44948\tvalidate-mlogloss:0.83722                            \n",
      "[600]\ttrain-mlogloss:0.44781\tvalidate-mlogloss:0.83718                            \n",
      "[602]\ttrain-mlogloss:0.44781\tvalidate-mlogloss:0.83719                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.00523\tvalidate-mlogloss:1.03310                              \n",
      "[200]\ttrain-mlogloss:0.47030\tvalidate-mlogloss:0.84551                            \n",
      "[400]\ttrain-mlogloss:0.45324\tvalidate-mlogloss:0.84459                            \n",
      "[600]\ttrain-mlogloss:0.43979\tvalidate-mlogloss:0.84419                            \n",
      "[790]\ttrain-mlogloss:0.43720\tvalidate-mlogloss:0.84458                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.00588\tvalidate-mlogloss:1.03177                              \n",
      "[200]\ttrain-mlogloss:0.46529\tvalidate-mlogloss:0.84361                            \n",
      "[400]\ttrain-mlogloss:0.45504\tvalidate-mlogloss:0.84252                            \n",
      "[600]\ttrain-mlogloss:0.45138\tvalidate-mlogloss:0.84271                            \n",
      "[651]\ttrain-mlogloss:0.44653\tvalidate-mlogloss:0.84256                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8414432290297014                                              \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.6, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 1, 'learning_rate': 0.03847915895057259, 'max_delta_step': 1, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 761, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.09236\tvalidate-mlogloss:1.09188                              \n",
      "[200]\ttrain-mlogloss:0.93717\tvalidate-mlogloss:0.91494                            \n",
      "[400]\ttrain-mlogloss:0.92620\tvalidate-mlogloss:0.90516                            \n",
      "[600]\ttrain-mlogloss:0.92172\tvalidate-mlogloss:0.90126                            \n",
      "[760]\ttrain-mlogloss:0.91982\tvalidate-mlogloss:0.89958                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.09360\tvalidate-mlogloss:1.09308                              \n",
      "[200]\ttrain-mlogloss:0.93672\tvalidate-mlogloss:0.92072                            \n",
      "[400]\ttrain-mlogloss:0.92449\tvalidate-mlogloss:0.91048                            \n",
      "[600]\ttrain-mlogloss:0.92053\tvalidate-mlogloss:0.90669                            \n",
      "[760]\ttrain-mlogloss:0.91927\tvalidate-mlogloss:0.90585                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.09304\tvalidate-mlogloss:1.09240                              \n",
      "[200]\ttrain-mlogloss:0.93538\tvalidate-mlogloss:0.92470                            \n",
      "[400]\ttrain-mlogloss:0.92378\tvalidate-mlogloss:0.91472                            \n",
      "[600]\ttrain-mlogloss:0.91950\tvalidate-mlogloss:0.91127                            \n",
      "[760]\ttrain-mlogloss:0.91815\tvalidate-mlogloss:0.91023                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.9052202634639722                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 100, 'learning_rate': 0.0975879892276344, 'max_delta_step': 2, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.7, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1786, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.07871\tvalidate-mlogloss:1.08024                              \n",
      "[200]\ttrain-mlogloss:0.87515\tvalidate-mlogloss:0.87822                            \n",
      "[400]\ttrain-mlogloss:0.87040\tvalidate-mlogloss:0.87534                            \n",
      "[600]\ttrain-mlogloss:0.86744\tvalidate-mlogloss:0.87414                            \n",
      "[800]\ttrain-mlogloss:0.86625\tvalidate-mlogloss:0.87399                            \n",
      "[1000]\ttrain-mlogloss:0.86501\tvalidate-mlogloss:0.87340                           \n",
      "[1200]\ttrain-mlogloss:0.86386\tvalidate-mlogloss:0.87268                           \n",
      "[1400]\ttrain-mlogloss:0.86280\tvalidate-mlogloss:0.87290                           \n",
      "[1600]\ttrain-mlogloss:0.86192\tvalidate-mlogloss:0.87257                           \n",
      "[1785]\ttrain-mlogloss:0.86114\tvalidate-mlogloss:0.87250                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.07849\tvalidate-mlogloss:1.07832                              \n",
      "[200]\ttrain-mlogloss:0.87155\tvalidate-mlogloss:0.89605                            \n",
      "[400]\ttrain-mlogloss:0.86829\tvalidate-mlogloss:0.89487                            \n",
      "[600]\ttrain-mlogloss:0.86605\tvalidate-mlogloss:0.89412                            \n",
      "[800]\ttrain-mlogloss:0.86433\tvalidate-mlogloss:0.89595                            \n",
      "[1000]\ttrain-mlogloss:0.86358\tvalidate-mlogloss:0.89580                           \n",
      "[1002]\ttrain-mlogloss:0.86358\tvalidate-mlogloss:0.89596                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.07969\tvalidate-mlogloss:1.07937                              \n",
      "[200]\ttrain-mlogloss:0.86994\tvalidate-mlogloss:0.88973                            \n",
      "[400]\ttrain-mlogloss:0.86589\tvalidate-mlogloss:0.88817                            \n",
      "[600]\ttrain-mlogloss:0.86397\tvalidate-mlogloss:0.88850                            \n",
      "[800]\ttrain-mlogloss:0.86231\tvalidate-mlogloss:0.88776                            \n",
      "[1000]\ttrain-mlogloss:0.86125\tvalidate-mlogloss:0.88699                           \n",
      "[1200]\ttrain-mlogloss:0.86016\tvalidate-mlogloss:0.88760                           \n",
      "[1400]\ttrain-mlogloss:0.85961\tvalidate-mlogloss:0.88700                           \n",
      "[1600]\ttrain-mlogloss:0.85861\tvalidate-mlogloss:0.88681                           \n",
      "[1785]\ttrain-mlogloss:0.85819\tvalidate-mlogloss:0.88697                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8851416994967081                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.9, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.07943204886035085, 'max_delta_step': 3, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 1402, 'num_feat': 60, 'step': 0.3}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.07531\tvalidate-mlogloss:1.07780                              \n",
      "[200]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                            \n",
      "[400]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                            \n",
      "[600]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                            \n",
      "[800]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                            \n",
      "[1000]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                           \n",
      "[1200]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                           \n",
      "[1400]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                           \n",
      "[1401]\ttrain-mlogloss:0.65541\tvalidate-mlogloss:0.83946                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.07621\tvalidate-mlogloss:1.08013                              \n",
      "[200]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                            \n",
      "[400]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                            \n",
      "[600]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                            \n",
      "[800]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                            \n",
      "[1000]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                           \n",
      "[1200]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                           \n",
      "[1400]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                           \n",
      "[1401]\ttrain-mlogloss:0.65787\tvalidate-mlogloss:0.85744                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.07774\tvalidate-mlogloss:1.08079                              \n",
      "[200]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85597                            \n",
      "[400]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                            \n",
      "[600]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                            \n",
      "[800]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                            \n",
      "[1000]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                           \n",
      "[1200]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                           \n",
      "[1400]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                           \n",
      "[1401]\ttrain-mlogloss:0.65563\tvalidate-mlogloss:0.85596                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8509531054839213                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 1, 'learning_rate': 0.1157618000773758, 'max_delta_step': 8, 'max_depth': 11, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1694, 'num_feat': 60, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.07392\tvalidate-mlogloss:1.07340                              \n",
      "[200]\ttrain-mlogloss:0.88234\tvalidate-mlogloss:0.88550                            \n",
      "[400]\ttrain-mlogloss:0.87835\tvalidate-mlogloss:0.88425                            \n",
      "[600]\ttrain-mlogloss:0.87612\tvalidate-mlogloss:0.88499                            \n",
      "[800]\ttrain-mlogloss:0.87419\tvalidate-mlogloss:0.88433                            \n",
      "[812]\ttrain-mlogloss:0.87394\tvalidate-mlogloss:0.88456                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.07210\tvalidate-mlogloss:1.07266                              \n",
      "[200]\ttrain-mlogloss:0.87767\tvalidate-mlogloss:0.89308                            \n",
      "[400]\ttrain-mlogloss:0.87369\tvalidate-mlogloss:0.89088                            \n",
      "[600]\ttrain-mlogloss:0.87140\tvalidate-mlogloss:0.88969                            \n",
      "[800]\ttrain-mlogloss:0.87006\tvalidate-mlogloss:0.89106                            \n",
      "[1000]\ttrain-mlogloss:0.86871\tvalidate-mlogloss:0.89125                           \n",
      "[1075]\ttrain-mlogloss:0.86852\tvalidate-mlogloss:0.89089                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.07332\tvalidate-mlogloss:1.07145                              \n",
      "[200]\ttrain-mlogloss:0.87663\tvalidate-mlogloss:0.88274                            \n",
      "[400]\ttrain-mlogloss:0.87269\tvalidate-mlogloss:0.88141                            \n",
      "[600]\ttrain-mlogloss:0.87080\tvalidate-mlogloss:0.88009                            \n",
      "[800]\ttrain-mlogloss:0.86926\tvalidate-mlogloss:0.88005                            \n",
      "[1000]\ttrain-mlogloss:0.86810\tvalidate-mlogloss:0.87872                           \n",
      "[1200]\ttrain-mlogloss:0.86733\tvalidate-mlogloss:0.87975                           \n",
      "[1400]\ttrain-mlogloss:0.86645\tvalidate-mlogloss:0.87918                           \n",
      "[1577]\ttrain-mlogloss:0.86577\tvalidate-mlogloss:0.87941                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8848053083177959                                              \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 0.5, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 100, 'learning_rate': 0.008982932827056552, 'max_delta_step': 4, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.5, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1586, 'num_feat': 80, 'step': 0.3}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.09737\tvalidate-mlogloss:1.09722                              \n",
      "[200]\ttrain-mlogloss:0.98096\tvalidate-mlogloss:0.96262                            \n",
      "[400]\ttrain-mlogloss:0.95539\tvalidate-mlogloss:0.93330                            \n",
      "[600]\ttrain-mlogloss:0.94442\tvalidate-mlogloss:0.92184                            \n",
      "[800]\ttrain-mlogloss:0.93842\tvalidate-mlogloss:0.91610                            \n",
      "[1000]\ttrain-mlogloss:0.93487\tvalidate-mlogloss:0.91313                           \n",
      "[1200]\ttrain-mlogloss:0.93222\tvalidate-mlogloss:0.91076                           \n",
      "[1400]\ttrain-mlogloss:0.93055\tvalidate-mlogloss:0.90909                           \n",
      "[1585]\ttrain-mlogloss:0.92934\tvalidate-mlogloss:0.90807                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.09724\tvalidate-mlogloss:1.09715                              \n",
      "[200]\ttrain-mlogloss:0.97832\tvalidate-mlogloss:0.96809                            \n",
      "[400]\ttrain-mlogloss:0.95242\tvalidate-mlogloss:0.93953                            \n",
      "[600]\ttrain-mlogloss:0.94212\tvalidate-mlogloss:0.92905                            \n",
      "[800]\ttrain-mlogloss:0.93598\tvalidate-mlogloss:0.92338                            \n",
      "[1000]\ttrain-mlogloss:0.93225\tvalidate-mlogloss:0.92007                           \n",
      "[1200]\ttrain-mlogloss:0.92980\tvalidate-mlogloss:0.91813                           \n",
      "[1400]\ttrain-mlogloss:0.92790\tvalidate-mlogloss:0.91661                           \n",
      "[1585]\ttrain-mlogloss:0.92673\tvalidate-mlogloss:0.91549                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.09725\tvalidate-mlogloss:1.09715                              \n",
      "[200]\ttrain-mlogloss:0.97692\tvalidate-mlogloss:0.96875                            \n",
      "[400]\ttrain-mlogloss:0.95006\tvalidate-mlogloss:0.94020                            \n",
      "[600]\ttrain-mlogloss:0.93954\tvalidate-mlogloss:0.92962                            \n",
      "[800]\ttrain-mlogloss:0.93362\tvalidate-mlogloss:0.92404                            \n",
      "[1000]\ttrain-mlogloss:0.93003\tvalidate-mlogloss:0.92094                           \n",
      "[1200]\ttrain-mlogloss:0.92755\tvalidate-mlogloss:0.91892                           \n",
      "[1400]\ttrain-mlogloss:0.92581\tvalidate-mlogloss:0.91734                           \n",
      "[1585]\ttrain-mlogloss:0.92477\tvalidate-mlogloss:0.91652                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.9133597960950622                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.8, 'colsample_bynode': 1.0, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 1, 'learning_rate': 0.08763902804051552, 'max_delta_step': 9, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.9, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 1361, 'num_feat': 70, 'step': 0.2}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.07532\tvalidate-mlogloss:1.07776                              \n",
      "[200]\ttrain-mlogloss:0.79543\tvalidate-mlogloss:0.86404                            \n",
      "[400]\ttrain-mlogloss:0.79151\tvalidate-mlogloss:0.86276                            \n",
      "[600]\ttrain-mlogloss:0.79128\tvalidate-mlogloss:0.86270                            \n",
      "[800]\ttrain-mlogloss:0.79035\tvalidate-mlogloss:0.86245                            \n",
      "[1000]\ttrain-mlogloss:0.78867\tvalidate-mlogloss:0.86158                           \n",
      "[1200]\ttrain-mlogloss:0.78763\tvalidate-mlogloss:0.86104                           \n",
      "[1360]\ttrain-mlogloss:0.78702\tvalidate-mlogloss:0.86093                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.07506\tvalidate-mlogloss:1.07717                              \n",
      "[200]\ttrain-mlogloss:0.79240\tvalidate-mlogloss:0.87487                            \n",
      "[400]\ttrain-mlogloss:0.78720\tvalidate-mlogloss:0.87376                            \n",
      "[600]\ttrain-mlogloss:0.78575\tvalidate-mlogloss:0.87323                            \n",
      "[800]\ttrain-mlogloss:0.78564\tvalidate-mlogloss:0.87349                            \n",
      "[1000]\ttrain-mlogloss:0.78435\tvalidate-mlogloss:0.87278                           \n",
      "[1200]\ttrain-mlogloss:0.78285\tvalidate-mlogloss:0.87261                           \n",
      "[1360]\ttrain-mlogloss:0.78216\tvalidate-mlogloss:0.87273                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.07580\tvalidate-mlogloss:1.07783                              \n",
      "[200]\ttrain-mlogloss:0.78894\tvalidate-mlogloss:0.87243                            \n",
      "[400]\ttrain-mlogloss:0.78556\tvalidate-mlogloss:0.87176                            \n",
      "[600]\ttrain-mlogloss:0.78448\tvalidate-mlogloss:0.87148                            \n",
      "[800]\ttrain-mlogloss:0.78328\tvalidate-mlogloss:0.87141                            \n",
      "[1000]\ttrain-mlogloss:0.78260\tvalidate-mlogloss:0.87114                           \n",
      "[1200]\ttrain-mlogloss:0.78126\tvalidate-mlogloss:0.87063                           \n",
      "[1360]\ttrain-mlogloss:0.78114\tvalidate-mlogloss:0.87076                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8681412900802045                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.04312878947991126, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 542, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.08625\tvalidate-mlogloss:1.08792                              \n",
      "[200]\ttrain-mlogloss:0.63058\tvalidate-mlogloss:0.83492                            \n",
      "[400]\ttrain-mlogloss:0.52450\tvalidate-mlogloss:0.82097                            \n",
      "[541]\ttrain-mlogloss:0.48673\tvalidate-mlogloss:0.81663                            \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.08493\tvalidate-mlogloss:1.08823                              \n",
      "[200]\ttrain-mlogloss:0.63007\tvalidate-mlogloss:0.84652                            \n",
      "[400]\ttrain-mlogloss:0.52569\tvalidate-mlogloss:0.83266                            \n",
      "[541]\ttrain-mlogloss:0.49248\tvalidate-mlogloss:0.82795                            \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.08511\tvalidate-mlogloss:1.08757                              \n",
      "[200]\ttrain-mlogloss:0.62852\tvalidate-mlogloss:0.85213                            \n",
      "[400]\ttrain-mlogloss:0.52195\tvalidate-mlogloss:0.83755                            \n",
      "[541]\ttrain-mlogloss:0.49091\tvalidate-mlogloss:0.83405                            \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8262102155891419                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.6, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 1, 'learning_rate': 0.041333340355679565, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 1508, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.08743\tvalidate-mlogloss:1.08850                              \n",
      "[200]\ttrain-mlogloss:0.66088\tvalidate-mlogloss:0.84063                            \n",
      "[400]\ttrain-mlogloss:0.53288\tvalidate-mlogloss:0.82364                            \n",
      "[600]\ttrain-mlogloss:0.43548\tvalidate-mlogloss:0.81760                            \n",
      "[800]\ttrain-mlogloss:0.36101\tvalidate-mlogloss:0.81705                            \n",
      "[1000]\ttrain-mlogloss:0.30116\tvalidate-mlogloss:0.82088                           \n",
      "[1120]\ttrain-mlogloss:0.27164\tvalidate-mlogloss:0.82450                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.08702\tvalidate-mlogloss:1.08876                              \n",
      "[200]\ttrain-mlogloss:0.65742\tvalidate-mlogloss:0.85093                            \n",
      "[400]\ttrain-mlogloss:0.53209\tvalidate-mlogloss:0.83407                            \n",
      "[600]\ttrain-mlogloss:0.43477\tvalidate-mlogloss:0.82793                            \n",
      "[800]\ttrain-mlogloss:0.35740\tvalidate-mlogloss:0.82684                            \n",
      "[1000]\ttrain-mlogloss:0.29676\tvalidate-mlogloss:0.83115                           \n",
      "[1102]\ttrain-mlogloss:0.27070\tvalidate-mlogloss:0.83426                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.08711\tvalidate-mlogloss:1.08913                              \n",
      "[200]\ttrain-mlogloss:0.66055\tvalidate-mlogloss:0.85571                            \n",
      "[400]\ttrain-mlogloss:0.53333\tvalidate-mlogloss:0.83890                            \n",
      "[600]\ttrain-mlogloss:0.43545\tvalidate-mlogloss:0.83172                            \n",
      "[800]\ttrain-mlogloss:0.35718\tvalidate-mlogloss:0.82862                            \n",
      "[1000]\ttrain-mlogloss:0.29774\tvalidate-mlogloss:0.83214                           \n",
      "[1198]\ttrain-mlogloss:0.25076\tvalidate-mlogloss:0.83841                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8323877999914653                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.029621786689346695, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1043, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))       \n",
      "Start training model for fold 1...                                                \n",
      "[0]\ttrain-mlogloss:1.08978\tvalidate-mlogloss:1.09051                              \n",
      "[200]\ttrain-mlogloss:0.68937\tvalidate-mlogloss:0.84448                            \n",
      "[400]\ttrain-mlogloss:0.58829\tvalidate-mlogloss:0.82898                            \n",
      "[600]\ttrain-mlogloss:0.52973\tvalidate-mlogloss:0.82097                            \n",
      "[800]\ttrain-mlogloss:0.49745\tvalidate-mlogloss:0.81718                            \n",
      "[1000]\ttrain-mlogloss:0.47688\tvalidate-mlogloss:0.81493                           \n",
      "[1042]\ttrain-mlogloss:0.47437\tvalidate-mlogloss:0.81448                           \n",
      "Predicting for fold 1...                                                          \n",
      "Start processing fold 2...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))       \n",
      "Start training model for fold 2...                                                \n",
      "[0]\ttrain-mlogloss:1.08959\tvalidate-mlogloss:1.09119                              \n",
      "[200]\ttrain-mlogloss:0.68878\tvalidate-mlogloss:0.85551                            \n",
      "[400]\ttrain-mlogloss:0.59008\tvalidate-mlogloss:0.84115                            \n",
      "[600]\ttrain-mlogloss:0.53551\tvalidate-mlogloss:0.83258                            \n",
      "[800]\ttrain-mlogloss:0.50404\tvalidate-mlogloss:0.82818                            \n",
      "[1000]\ttrain-mlogloss:0.48629\tvalidate-mlogloss:0.82612                           \n",
      "[1042]\ttrain-mlogloss:0.48236\tvalidate-mlogloss:0.82545                           \n",
      "Predicting for fold 2...                                                          \n",
      "Start processing fold 3...                                                        \n",
      "Class distribution:                                                               \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                  \n",
      "Class instance weights:                                                           \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))       \n",
      "Start training model for fold 3...                                                \n",
      "[0]\ttrain-mlogloss:1.08935\tvalidate-mlogloss:1.09126                              \n",
      "[200]\ttrain-mlogloss:0.68327\tvalidate-mlogloss:0.86069                            \n",
      "[400]\ttrain-mlogloss:0.58751\tvalidate-mlogloss:0.84501                            \n",
      "[600]\ttrain-mlogloss:0.53202\tvalidate-mlogloss:0.83730                            \n",
      "[800]\ttrain-mlogloss:0.50090\tvalidate-mlogloss:0.83286                            \n",
      "[1000]\ttrain-mlogloss:0.48319\tvalidate-mlogloss:0.83043                           \n",
      "[1042]\ttrain-mlogloss:0.48015\tvalidate-mlogloss:0.83001                           \n",
      "Predicting for fold 3...                                                          \n",
      "Average log loss: 0.8233149153538175                                              \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 2, 'lambda': 1, 'learning_rate': 0.0750551499629755, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1997, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07597\tvalidate-mlogloss:1.07842                                \n",
      "[200]\ttrain-mlogloss:0.64847\tvalidate-mlogloss:0.83658                              \n",
      "[400]\ttrain-mlogloss:0.62374\tvalidate-mlogloss:0.83263                              \n",
      "[600]\ttrain-mlogloss:0.61132\tvalidate-mlogloss:0.83061                              \n",
      "[800]\ttrain-mlogloss:0.60547\tvalidate-mlogloss:0.82977                              \n",
      "[1000]\ttrain-mlogloss:0.59934\tvalidate-mlogloss:0.82846                             \n",
      "[1200]\ttrain-mlogloss:0.59400\tvalidate-mlogloss:0.82743                             \n",
      "[1400]\ttrain-mlogloss:0.59056\tvalidate-mlogloss:0.82711                             \n",
      "[1600]\ttrain-mlogloss:0.58627\tvalidate-mlogloss:0.82675                             \n",
      "[1800]\ttrain-mlogloss:0.58335\tvalidate-mlogloss:0.82611                             \n",
      "[1996]\ttrain-mlogloss:0.58161\tvalidate-mlogloss:0.82608                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07580\tvalidate-mlogloss:1.08012                                \n",
      "[200]\ttrain-mlogloss:0.65268\tvalidate-mlogloss:0.84772                              \n",
      "[400]\ttrain-mlogloss:0.62806\tvalidate-mlogloss:0.84286                              \n",
      "[600]\ttrain-mlogloss:0.61640\tvalidate-mlogloss:0.84080                              \n",
      "[800]\ttrain-mlogloss:0.61161\tvalidate-mlogloss:0.84023                              \n",
      "[1000]\ttrain-mlogloss:0.60723\tvalidate-mlogloss:0.83933                             \n",
      "[1200]\ttrain-mlogloss:0.60428\tvalidate-mlogloss:0.83881                             \n",
      "[1400]\ttrain-mlogloss:0.59965\tvalidate-mlogloss:0.83793                             \n",
      "[1600]\ttrain-mlogloss:0.59716\tvalidate-mlogloss:0.83769                             \n",
      "[1800]\ttrain-mlogloss:0.59532\tvalidate-mlogloss:0.83728                             \n",
      "[1996]\ttrain-mlogloss:0.59276\tvalidate-mlogloss:0.83703                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07714\tvalidate-mlogloss:1.08150                                \n",
      "[200]\ttrain-mlogloss:0.64796\tvalidate-mlogloss:0.85128                              \n",
      "[400]\ttrain-mlogloss:0.62318\tvalidate-mlogloss:0.84685                              \n",
      "[600]\ttrain-mlogloss:0.61105\tvalidate-mlogloss:0.84497                              \n",
      "[800]\ttrain-mlogloss:0.60369\tvalidate-mlogloss:0.84390                              \n",
      "[1000]\ttrain-mlogloss:0.59908\tvalidate-mlogloss:0.84317                             \n",
      "[1200]\ttrain-mlogloss:0.59627\tvalidate-mlogloss:0.84261                             \n",
      "[1400]\ttrain-mlogloss:0.59172\tvalidate-mlogloss:0.84223                             \n",
      "[1600]\ttrain-mlogloss:0.58817\tvalidate-mlogloss:0.84169                             \n",
      "[1800]\ttrain-mlogloss:0.58704\tvalidate-mlogloss:0.84171                             \n",
      "[1996]\ttrain-mlogloss:0.58493\tvalidate-mlogloss:0.84139                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8348302558373025                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 3, 'lambda': 1, 'learning_rate': 0.04955673370412476, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 919, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))          \n",
      "Start training model for fold 1...                                                   \n",
      "[0]\ttrain-mlogloss:1.08417\tvalidate-mlogloss:1.08510                                 \n",
      "[200]\ttrain-mlogloss:0.73567\tvalidate-mlogloss:0.84804                               \n",
      "[400]\ttrain-mlogloss:0.72285\tvalidate-mlogloss:0.84521                               \n",
      "[600]\ttrain-mlogloss:0.71627\tvalidate-mlogloss:0.84389                               \n",
      "[800]\ttrain-mlogloss:0.71225\tvalidate-mlogloss:0.84315                               \n",
      "[918]\ttrain-mlogloss:0.71104\tvalidate-mlogloss:0.84259                               \n",
      "Predicting for fold 1...                                                             \n",
      "Start processing fold 2...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))          \n",
      "Start training model for fold 2...                                                   \n",
      "[0]\ttrain-mlogloss:1.08397\tvalidate-mlogloss:1.08641                                 \n",
      "[200]\ttrain-mlogloss:0.73506\tvalidate-mlogloss:0.85860                               \n",
      "[400]\ttrain-mlogloss:0.72385\tvalidate-mlogloss:0.85598                               \n",
      "[600]\ttrain-mlogloss:0.71830\tvalidate-mlogloss:0.85469                               \n",
      "[800]\ttrain-mlogloss:0.71573\tvalidate-mlogloss:0.85438                               \n",
      "[918]\ttrain-mlogloss:0.71453\tvalidate-mlogloss:0.85410                               \n",
      "Predicting for fold 2...                                                             \n",
      "Start processing fold 3...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))          \n",
      "Start training model for fold 3...                                                   \n",
      "[0]\ttrain-mlogloss:1.08362\tvalidate-mlogloss:1.08634                                 \n",
      "[200]\ttrain-mlogloss:0.73137\tvalidate-mlogloss:0.86528                               \n",
      "[400]\ttrain-mlogloss:0.71863\tvalidate-mlogloss:0.86353                               \n",
      "[600]\ttrain-mlogloss:0.71139\tvalidate-mlogloss:0.86242                               \n",
      "[800]\ttrain-mlogloss:0.70662\tvalidate-mlogloss:0.86188                               \n",
      "[918]\ttrain-mlogloss:0.70422\tvalidate-mlogloss:0.86144                               \n",
      "Predicting for fold 3...                                                             \n",
      "Average log loss: 0.8527105603797303                                                 \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.030214489162899733, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 756, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09017\tvalidate-mlogloss:1.09069                                \n",
      "[200]\ttrain-mlogloss:0.69849\tvalidate-mlogloss:0.84640                              \n",
      "[400]\ttrain-mlogloss:0.60172\tvalidate-mlogloss:0.83070                              \n",
      "[600]\ttrain-mlogloss:0.54964\tvalidate-mlogloss:0.82308                              \n",
      "[755]\ttrain-mlogloss:0.52549\tvalidate-mlogloss:0.81985                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08972\tvalidate-mlogloss:1.09114                                \n",
      "[200]\ttrain-mlogloss:0.69643\tvalidate-mlogloss:0.85483                              \n",
      "[400]\ttrain-mlogloss:0.60380\tvalidate-mlogloss:0.84037                              \n",
      "[600]\ttrain-mlogloss:0.55478\tvalidate-mlogloss:0.83239                              \n",
      "[755]\ttrain-mlogloss:0.53144\tvalidate-mlogloss:0.82959                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.08975\tvalidate-mlogloss:1.09143                                \n",
      "[200]\ttrain-mlogloss:0.69680\tvalidate-mlogloss:0.86197                              \n",
      "[400]\ttrain-mlogloss:0.60629\tvalidate-mlogloss:0.84673                              \n",
      "[600]\ttrain-mlogloss:0.55239\tvalidate-mlogloss:0.83876                              \n",
      "[755]\ttrain-mlogloss:0.53021\tvalidate-mlogloss:0.83569                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8283768475959614                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 7, 'lambda': 1, 'learning_rate': 0.0017267315292870018, 'max_delta_step': 5, 'max_depth': 7, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 873, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09818\tvalidate-mlogloss:1.09816                                \n",
      "[200]\ttrain-mlogloss:1.03035\tvalidate-mlogloss:1.02884                              \n",
      "[400]\ttrain-mlogloss:0.98608\tvalidate-mlogloss:0.98403                              \n",
      "[600]\ttrain-mlogloss:0.95578\tvalidate-mlogloss:0.95399                              \n",
      "[800]\ttrain-mlogloss:0.93441\tvalidate-mlogloss:0.93306                              \n",
      "[872]\ttrain-mlogloss:0.92826\tvalidate-mlogloss:0.92728                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09817\tvalidate-mlogloss:1.09819                                \n",
      "[200]\ttrain-mlogloss:1.02869\tvalidate-mlogloss:1.03207                              \n",
      "[400]\ttrain-mlogloss:0.98349\tvalidate-mlogloss:0.98917                              \n",
      "[600]\ttrain-mlogloss:0.95298\tvalidate-mlogloss:0.96031                              \n",
      "[800]\ttrain-mlogloss:0.93170\tvalidate-mlogloss:0.94033                              \n",
      "[872]\ttrain-mlogloss:0.92556\tvalidate-mlogloss:0.93465                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09818\tvalidate-mlogloss:1.09821                                \n",
      "[200]\ttrain-mlogloss:1.02822\tvalidate-mlogloss:1.03284                              \n",
      "[400]\ttrain-mlogloss:0.98290\tvalidate-mlogloss:0.99069                              \n",
      "[600]\ttrain-mlogloss:0.95203\tvalidate-mlogloss:0.96240                              \n",
      "[800]\ttrain-mlogloss:0.93051\tvalidate-mlogloss:0.94306                              \n",
      "[872]\ttrain-mlogloss:0.92439\tvalidate-mlogloss:0.93768                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.9332009945876938                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 1.0, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 5, 'lambda': 1, 'learning_rate': 0.05608929876808203, 'max_delta_step': 5, 'max_depth': 5, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 542, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08610\tvalidate-mlogloss:1.08589                                \n",
      "[200]\ttrain-mlogloss:0.86096\tvalidate-mlogloss:0.87109                              \n",
      "[400]\ttrain-mlogloss:0.85441\tvalidate-mlogloss:0.86844                              \n",
      "[541]\ttrain-mlogloss:0.85190\tvalidate-mlogloss:0.86808                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08574\tvalidate-mlogloss:1.08591                                \n",
      "[200]\ttrain-mlogloss:0.85694\tvalidate-mlogloss:0.88272                              \n",
      "[400]\ttrain-mlogloss:0.85219\tvalidate-mlogloss:0.88231                              \n",
      "[541]\ttrain-mlogloss:0.84930\tvalidate-mlogloss:0.88162                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.08572\tvalidate-mlogloss:1.08603                                \n",
      "[200]\ttrain-mlogloss:0.85553\tvalidate-mlogloss:0.88778                              \n",
      "[400]\ttrain-mlogloss:0.84962\tvalidate-mlogloss:0.88757                              \n",
      "[541]\ttrain-mlogloss:0.84788\tvalidate-mlogloss:0.88733                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8790102239765414                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.6, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 1, 'learning_rate': 0.10374343149814072, 'max_delta_step': 5, 'max_depth': 4, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 1713, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07788\tvalidate-mlogloss:1.07688                                \n",
      "[200]\ttrain-mlogloss:0.84170\tvalidate-mlogloss:0.86611                              \n",
      "[400]\ttrain-mlogloss:0.79627\tvalidate-mlogloss:0.85965                              \n",
      "[600]\ttrain-mlogloss:0.76210\tvalidate-mlogloss:0.85682                              \n",
      "[800]\ttrain-mlogloss:0.73438\tvalidate-mlogloss:0.85561                              \n",
      "[1000]\ttrain-mlogloss:0.71193\tvalidate-mlogloss:0.85383                             \n",
      "[1200]\ttrain-mlogloss:0.69282\tvalidate-mlogloss:0.85331                             \n",
      "[1400]\ttrain-mlogloss:0.67577\tvalidate-mlogloss:0.85274                             \n",
      "[1600]\ttrain-mlogloss:0.66114\tvalidate-mlogloss:0.85259                             \n",
      "[1712]\ttrain-mlogloss:0.65403\tvalidate-mlogloss:0.85257                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08024\tvalidate-mlogloss:1.07863                                \n",
      "[200]\ttrain-mlogloss:0.83909\tvalidate-mlogloss:0.87989                              \n",
      "[400]\ttrain-mlogloss:0.79342\tvalidate-mlogloss:0.87848                              \n",
      "[600]\ttrain-mlogloss:0.76012\tvalidate-mlogloss:0.87533                              \n",
      "[800]\ttrain-mlogloss:0.73298\tvalidate-mlogloss:0.87361                              \n",
      "[1000]\ttrain-mlogloss:0.71054\tvalidate-mlogloss:0.87299                             \n",
      "[1200]\ttrain-mlogloss:0.69213\tvalidate-mlogloss:0.87149                             \n",
      "[1400]\ttrain-mlogloss:0.67508\tvalidate-mlogloss:0.87244                             \n",
      "[1600]\ttrain-mlogloss:0.66047\tvalidate-mlogloss:0.87108                             \n",
      "[1712]\ttrain-mlogloss:0.65349\tvalidate-mlogloss:0.87005                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07830\tvalidate-mlogloss:1.07818                                \n",
      "[200]\ttrain-mlogloss:0.83650\tvalidate-mlogloss:0.88619                              \n",
      "[400]\ttrain-mlogloss:0.79077\tvalidate-mlogloss:0.88227                              \n",
      "[600]\ttrain-mlogloss:0.75710\tvalidate-mlogloss:0.87825                              \n",
      "[800]\ttrain-mlogloss:0.73014\tvalidate-mlogloss:0.87691                              \n",
      "[1000]\ttrain-mlogloss:0.70786\tvalidate-mlogloss:0.87517                             \n",
      "[1200]\ttrain-mlogloss:0.68903\tvalidate-mlogloss:0.87735                             \n",
      "[1400]\ttrain-mlogloss:0.67215\tvalidate-mlogloss:0.87605                             \n",
      "[1455]\ttrain-mlogloss:0.66788\tvalidate-mlogloss:0.87519                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8659384748477464                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.01777191323779318, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1662, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09537\tvalidate-mlogloss:1.09527                                \n",
      "[200]\ttrain-mlogloss:0.91862\tvalidate-mlogloss:0.90947                              \n",
      "[400]\ttrain-mlogloss:0.89829\tvalidate-mlogloss:0.89428                              \n",
      "[600]\ttrain-mlogloss:0.88831\tvalidate-mlogloss:0.88782                              \n",
      "[800]\ttrain-mlogloss:0.88205\tvalidate-mlogloss:0.88432                              \n",
      "[1000]\ttrain-mlogloss:0.87844\tvalidate-mlogloss:0.88215                             \n",
      "[1200]\ttrain-mlogloss:0.87610\tvalidate-mlogloss:0.88103                             \n",
      "[1400]\ttrain-mlogloss:0.87436\tvalidate-mlogloss:0.87996                             \n",
      "[1600]\ttrain-mlogloss:0.87280\tvalidate-mlogloss:0.87935                             \n",
      "[1661]\ttrain-mlogloss:0.87241\tvalidate-mlogloss:0.87913                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09537\tvalidate-mlogloss:1.09535                                \n",
      "[200]\ttrain-mlogloss:0.91732\tvalidate-mlogloss:0.92263                              \n",
      "[400]\ttrain-mlogloss:0.89686\tvalidate-mlogloss:0.90574                              \n",
      "[600]\ttrain-mlogloss:0.88711\tvalidate-mlogloss:0.89965                              \n",
      "[800]\ttrain-mlogloss:0.88127\tvalidate-mlogloss:0.89629                              \n",
      "[1000]\ttrain-mlogloss:0.87799\tvalidate-mlogloss:0.89475                             \n",
      "[1200]\ttrain-mlogloss:0.87599\tvalidate-mlogloss:0.89366                             \n",
      "[1400]\ttrain-mlogloss:0.87433\tvalidate-mlogloss:0.89252                             \n",
      "[1600]\ttrain-mlogloss:0.87299\tvalidate-mlogloss:0.89203                             \n",
      "[1661]\ttrain-mlogloss:0.87267\tvalidate-mlogloss:0.89179                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09512\tvalidate-mlogloss:1.09523                                \n",
      "[200]\ttrain-mlogloss:0.91496\tvalidate-mlogloss:0.92234                              \n",
      "[400]\ttrain-mlogloss:0.89383\tvalidate-mlogloss:0.90757                              \n",
      "[600]\ttrain-mlogloss:0.88400\tvalidate-mlogloss:0.90199                              \n",
      "[800]\ttrain-mlogloss:0.87843\tvalidate-mlogloss:0.89972                              \n",
      "[1000]\ttrain-mlogloss:0.87509\tvalidate-mlogloss:0.89816                             \n",
      "[1200]\ttrain-mlogloss:0.87299\tvalidate-mlogloss:0.89793                             \n",
      "[1400]\ttrain-mlogloss:0.87126\tvalidate-mlogloss:0.89762                             \n",
      "[1600]\ttrain-mlogloss:0.87004\tvalidate-mlogloss:0.89718                             \n",
      "[1661]\ttrain-mlogloss:0.86971\tvalidate-mlogloss:0.89717                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8893649995633198                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 8, 'lambda': 1, 'learning_rate': 0.027299566076176063, 'max_delta_step': 5, 'max_depth': 6, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 20, 'num_boost_round': 897, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))          \n",
      "Start training model for fold 1...                                                   \n",
      "[0]\ttrain-mlogloss:1.09210\tvalidate-mlogloss:1.09210                                 \n",
      "[200]\ttrain-mlogloss:0.88142\tvalidate-mlogloss:0.88048                               \n",
      "[400]\ttrain-mlogloss:0.87730\tvalidate-mlogloss:0.87786                               \n",
      "[600]\ttrain-mlogloss:0.87629\tvalidate-mlogloss:0.87701                               \n",
      "[800]\ttrain-mlogloss:0.87574\tvalidate-mlogloss:0.87665                               \n",
      "[896]\ttrain-mlogloss:0.87540\tvalidate-mlogloss:0.87624                               \n",
      "Predicting for fold 1...                                                             \n",
      "Start processing fold 2...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))          \n",
      "Start training model for fold 2...                                                   \n",
      "[0]\ttrain-mlogloss:1.09188\tvalidate-mlogloss:1.09213                                 \n",
      "[200]\ttrain-mlogloss:0.87854\tvalidate-mlogloss:0.89070                               \n",
      "[400]\ttrain-mlogloss:0.87437\tvalidate-mlogloss:0.88837                               \n",
      "[600]\ttrain-mlogloss:0.87332\tvalidate-mlogloss:0.88757                               \n",
      "[800]\ttrain-mlogloss:0.87285\tvalidate-mlogloss:0.88764                               \n",
      "[896]\ttrain-mlogloss:0.87267\tvalidate-mlogloss:0.88760                               \n",
      "Predicting for fold 2...                                                             \n",
      "Start processing fold 3...                                                           \n",
      "Class distribution:                                                                  \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                     \n",
      "Class instance weights:                                                              \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))          \n",
      "Start training model for fold 3...                                                   \n",
      "[0]\ttrain-mlogloss:1.09188\tvalidate-mlogloss:1.09226                                 \n",
      "[200]\ttrain-mlogloss:0.87732\tvalidate-mlogloss:0.89418                               \n",
      "[400]\ttrain-mlogloss:0.87253\tvalidate-mlogloss:0.89154                               \n",
      "[600]\ttrain-mlogloss:0.87177\tvalidate-mlogloss:0.89091                               \n",
      "[800]\ttrain-mlogloss:0.87123\tvalidate-mlogloss:0.89083                               \n",
      "[896]\ttrain-mlogloss:0.87095\tvalidate-mlogloss:0.89097                               \n",
      "Predicting for fold 3...                                                             \n",
      "Average log loss: 0.884940464599229                                                  \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 6, 'lambda': 1, 'learning_rate': 0.034841986592786894, 'max_delta_step': 7, 'max_depth': 3, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 25, 'num_boost_round': 548, 'num_feat': 80, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09180\tvalidate-mlogloss:1.09163                                \n",
      "[200]\ttrain-mlogloss:0.90751\tvalidate-mlogloss:0.89346                              \n",
      "[400]\ttrain-mlogloss:0.89367\tvalidate-mlogloss:0.88433                              \n",
      "[547]\ttrain-mlogloss:0.89062\tvalidate-mlogloss:0.88300                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09201\tvalidate-mlogloss:1.09192                                \n",
      "[200]\ttrain-mlogloss:0.90344\tvalidate-mlogloss:0.90526                              \n",
      "[400]\ttrain-mlogloss:0.88757\tvalidate-mlogloss:0.89384                              \n",
      "[547]\ttrain-mlogloss:0.88455\tvalidate-mlogloss:0.89265                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09160\tvalidate-mlogloss:1.09146                                \n",
      "[200]\ttrain-mlogloss:0.90174\tvalidate-mlogloss:0.90130                              \n",
      "[400]\ttrain-mlogloss:0.88698\tvalidate-mlogloss:0.88772                              \n",
      "[547]\ttrain-mlogloss:0.88437\tvalidate-mlogloss:0.88533                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8869929042561194                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 4, 'lambda': 1, 'learning_rate': 0.06703889796469538, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 15, 'num_boost_round': 1324, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.08217\tvalidate-mlogloss:1.08217                                \n",
      "[200]\ttrain-mlogloss:0.79506\tvalidate-mlogloss:0.85931                              \n",
      "[400]\ttrain-mlogloss:0.78914\tvalidate-mlogloss:0.85775                              \n",
      "[600]\ttrain-mlogloss:0.78685\tvalidate-mlogloss:0.85719                              \n",
      "[800]\ttrain-mlogloss:0.78517\tvalidate-mlogloss:0.85696                              \n",
      "[1000]\ttrain-mlogloss:0.78264\tvalidate-mlogloss:0.85577                             \n",
      "[1200]\ttrain-mlogloss:0.78183\tvalidate-mlogloss:0.85541                             \n",
      "[1323]\ttrain-mlogloss:0.78104\tvalidate-mlogloss:0.85511                             \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.08046\tvalidate-mlogloss:1.08228                                \n",
      "[200]\ttrain-mlogloss:0.79296\tvalidate-mlogloss:0.87174                              \n",
      "[400]\ttrain-mlogloss:0.78842\tvalidate-mlogloss:0.87064                              \n",
      "[600]\ttrain-mlogloss:0.78384\tvalidate-mlogloss:0.86951                              \n",
      "[800]\ttrain-mlogloss:0.78250\tvalidate-mlogloss:0.86942                              \n",
      "[1000]\ttrain-mlogloss:0.78078\tvalidate-mlogloss:0.86907                             \n",
      "[1145]\ttrain-mlogloss:0.78034\tvalidate-mlogloss:0.86934                             \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.08010\tvalidate-mlogloss:1.08232                                \n",
      "[200]\ttrain-mlogloss:0.79332\tvalidate-mlogloss:0.87791                              \n",
      "[400]\ttrain-mlogloss:0.78754\tvalidate-mlogloss:0.87638                              \n",
      "[600]\ttrain-mlogloss:0.78428\tvalidate-mlogloss:0.87521                              \n",
      "[800]\ttrain-mlogloss:0.78133\tvalidate-mlogloss:0.87509                              \n",
      "[1000]\ttrain-mlogloss:0.78067\tvalidate-mlogloss:0.87472                             \n",
      "[1200]\ttrain-mlogloss:0.77884\tvalidate-mlogloss:0.87432                             \n",
      "[1323]\ttrain-mlogloss:0.77793\tvalidate-mlogloss:0.87437                             \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8662710401906075                                                \n",
      "{'booster_params': {'alpha': 100, 'booster': 'gbtree', 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss', 'gamma': 0, 'lambda': 1, 'learning_rate': 0.0075490002502211105, 'max_delta_step': 5, 'max_depth': 9, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 0.8, 'tree_method': 'hist'}, 'k_neighbors': 5, 'num_boost_round': 740, 'num_feat': 50, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.09712\tvalidate-mlogloss:1.09703                                \n",
      "[200]\ttrain-mlogloss:0.95782\tvalidate-mlogloss:0.94908                              \n",
      "[400]\ttrain-mlogloss:0.92286\tvalidate-mlogloss:0.91471                              \n",
      "[600]\ttrain-mlogloss:0.90820\tvalidate-mlogloss:0.90270                              \n",
      "[739]\ttrain-mlogloss:0.90218\tvalidate-mlogloss:0.89861                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.09723\tvalidate-mlogloss:1.09724                                \n",
      "[200]\ttrain-mlogloss:0.95373\tvalidate-mlogloss:0.95721                              \n",
      "[400]\ttrain-mlogloss:0.91804\tvalidate-mlogloss:0.92266                              \n",
      "[600]\ttrain-mlogloss:0.90349\tvalidate-mlogloss:0.91009                              \n",
      "[739]\ttrain-mlogloss:0.89759\tvalidate-mlogloss:0.90563                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.09709\tvalidate-mlogloss:1.09715                                \n",
      "[200]\ttrain-mlogloss:0.95215\tvalidate-mlogloss:0.95854                              \n",
      "[400]\ttrain-mlogloss:0.91560\tvalidate-mlogloss:0.92575                              \n",
      "[600]\ttrain-mlogloss:0.90027\tvalidate-mlogloss:0.91314                              \n",
      "[739]\ttrain-mlogloss:0.89410\tvalidate-mlogloss:0.90897                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.9044006791095351                                                \n",
      "{'booster_params': {'alpha': 1, 'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 0.8, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 1, 'lambda': 100, 'learning_rate': 0.12425992738897947, 'max_delta_step': 2, 'max_depth': 8, 'num_class': 3, 'objective': 'multi:softprob', 'predictor': 'cpu_predictor', 'subsample': 1.0, 'tree_method': 'hist'}, 'k_neighbors': 10, 'num_boost_round': 702, 'num_feat': 60, 'step': 0.1}\n",
      "Start processing fold 1...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6056, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61827461, 0.95433525, 2.98734038]), array([29261, 18957,  6056]))         \n",
      "Start training model for fold 1...                                                  \n",
      "[0]\ttrain-mlogloss:1.07369\tvalidate-mlogloss:1.07349                                \n",
      "[200]\ttrain-mlogloss:0.78720\tvalidate-mlogloss:0.85583                              \n",
      "[400]\ttrain-mlogloss:0.78604\tvalidate-mlogloss:0.85518                              \n",
      "[600]\ttrain-mlogloss:0.78604\tvalidate-mlogloss:0.85518                              \n",
      "[701]\ttrain-mlogloss:0.78604\tvalidate-mlogloss:0.85518                              \n",
      "Predicting for fold 1...                                                            \n",
      "Start processing fold 2...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18957, 29261]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.618286  , 0.95435283, 2.98690221]), array([29261, 18957,  6057]))         \n",
      "Start training model for fold 2...                                                  \n",
      "[0]\ttrain-mlogloss:1.07540\tvalidate-mlogloss:1.07654                                \n",
      "[200]\ttrain-mlogloss:0.79112\tvalidate-mlogloss:0.86929                              \n",
      "[400]\ttrain-mlogloss:0.78950\tvalidate-mlogloss:0.86848                              \n",
      "[600]\ttrain-mlogloss:0.78950\tvalidate-mlogloss:0.86848                              \n",
      "[701]\ttrain-mlogloss:0.78950\tvalidate-mlogloss:0.86848                              \n",
      "Predicting for fold 2...                                                            \n",
      "Start processing fold 3...                                                          \n",
      "Class distribution:                                                                 \n",
      "(array([0, 1, 2]), array([ 6057, 18958, 29260]))                                    \n",
      "Class instance weights:                                                             \n",
      "(array([0.61830713, 0.95430249, 2.98690221]), array([29260, 18958,  6057]))         \n",
      "Start training model for fold 3...                                                  \n",
      "[0]\ttrain-mlogloss:1.07325\tvalidate-mlogloss:1.07359                                \n",
      "[200]\ttrain-mlogloss:0.78600\tvalidate-mlogloss:0.87577                              \n",
      "[400]\ttrain-mlogloss:0.78270\tvalidate-mlogloss:0.87454                              \n",
      "[600]\ttrain-mlogloss:0.78270\tvalidate-mlogloss:0.87454                              \n",
      "[701]\ttrain-mlogloss:0.78270\tvalidate-mlogloss:0.87454                              \n",
      "Predicting for fold 3...                                                            \n",
      "Average log loss: 0.8660678866773187                                                \n",
      "100%|██████████| 100/100 [2:03:44<00:00, 74.24s/trial, best loss: 0.8233149153538175]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=objective, space=search_space, algo=tpe.suggest, max_evals=100, trials=trials\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the search, the best set of parameters are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'colsample_bylevel': 4,\n",
       " 'colsample_bynode': 3,\n",
       " 'colsample_bytree': 4,\n",
       " 'gamma': 1,\n",
       " 'k_neighbors': 4,\n",
       " 'lambda': 0,\n",
       " 'learning_rate': 0.029621786689346695,\n",
       " 'max_delta_step': 5,\n",
       " 'max_depth': 6,\n",
       " 'num_boost_round': 1043,\n",
       " 'num_feat': 1,\n",
       " 'step': 0,\n",
       " 'subsample': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for `hp.choice`, the returned values is not the actual values of the hyperparamter but simply the indices to the choice lists. \n",
    "\n",
    "* The `colsample_bynode` returns $3$, which corresponds to the fourth element of the choice list--- `[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]`--- 1.0. \n",
    "\n",
    "* The `colsample_bytree` returns $4$, which correponds to  the fifth element of the choice list--- `[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]`--- 0.8.\n",
    "\n",
    "We can simply use the dictionary from the standard output and modify as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster_params': {'alpha': 1,\n",
       "  'booster': 'gbtree',\n",
       "  'colsample_bylevel': 0.9,\n",
       "  'colsample_bynode': 0.8,\n",
       "  'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'mlogloss',\n",
       "  'gamma': 1,\n",
       "  'lambda': 1,\n",
       "  'learning_rate': 0.021239520998594802,\n",
       "  'max_delta_step': 5,\n",
       "  'max_depth': 9,\n",
       "  'num_class': 3,\n",
       "  'objective': 'multi:softprob',\n",
       "  'predictor': 'cpu_predictor',\n",
       "  'subsample': 0.8,\n",
       "  'tree_method': 'hist'},\n",
       " 'k_neighbors': 25,\n",
       " 'num_boost_round': 10000,\n",
       " 'num_feat': 60,\n",
       " 'step': 0.1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params = {\n",
    "    \"booster_params\": {\n",
    "        \"alpha\": 1,\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"colsample_bylevel\": 0.9,\n",
    "        \"colsample_bynode\": 0.8,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"gamma\": 1,\n",
    "        \"lambda\": 1,\n",
    "        \"learning_rate\": 0.021239520998594802,\n",
    "        \"max_delta_step\": 5,\n",
    "        \"max_depth\": 9,\n",
    "        \"num_class\": 3,\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"predictor\": \"cpu_predictor\",\n",
    "        \"subsample\": 0.8,\n",
    "        \"tree_method\": \"hist\",\n",
    "    },\n",
    "    \"k_neighbors\": 25,\n",
    "    \"num_boost_round\": 10000,\n",
    "    \"num_feat\": 60,\n",
    "    \"step\": 0.1,\n",
    "}\n",
    "optimal_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this optimized set of parameters as a starting point for cross validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "# Fold 1\n",
      "# Training set size 65129 Validation set size 16283\n",
      "################################################################################\n",
      "The training and validation sets are disjoint: True\n",
      "The preprocessor is not fitted yet. Fitting now...\n",
      "The label encoder is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor_fold_1.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder_fold_1.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenwu/opt/anaconda3/envs/python_for_machine_learning/lib/python3.9/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but RFE was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature selector is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/feature_selector_fold_1.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.11159289 0.34928512 0.539122  ]\n",
      "Class instance weights: (array([0.61828925, 0.95433019, 2.98704825]), array([43891, 28436,  9085]))\n",
      "[0]\ttrain-mlogloss:1.09060\tvalidate-mlogloss:1.09210\n",
      "[1000]\ttrain-mlogloss:0.49258\tvalidate-mlogloss:0.75476\n",
      "[2000]\ttrain-mlogloss:0.43132\tvalidate-mlogloss:0.73051\n",
      "[3000]\ttrain-mlogloss:0.41110\tvalidate-mlogloss:0.72302\n",
      "[4000]\ttrain-mlogloss:0.40035\tvalidate-mlogloss:0.71932\n",
      "[5000]\ttrain-mlogloss:0.39369\tvalidate-mlogloss:0.71711\n",
      "[6000]\ttrain-mlogloss:0.38842\tvalidate-mlogloss:0.71540\n",
      "[7000]\ttrain-mlogloss:0.38503\tvalidate-mlogloss:0.71419\n",
      "[8000]\ttrain-mlogloss:0.38165\tvalidate-mlogloss:0.71293\n",
      "[9000]\ttrain-mlogloss:0.37858\tvalidate-mlogloss:0.71155\n",
      "[9999]\ttrain-mlogloss:0.37589\tvalidate-mlogloss:0.71055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/models/eval_fold_1.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class logloss: 0.7105462577036723\n",
      "Balanced accuracy (Average recall): 0.5702642929962398\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.69      0.41      0.98      0.52      0.64      0.38      1817\n",
      "          1       0.78      0.35      0.95      0.48      0.57      0.31      5688\n",
      "          2       0.66      0.95      0.43      0.78      0.64      0.43      8778\n",
      "\n",
      "avg / total       0.70      0.68      0.67      0.64      0.61      0.38     16283\n",
      "\n",
      "################################################################################\n",
      "# Fold 2\n",
      "# Training set size 65129 Validation set size 16283\n",
      "################################################################################\n",
      "The training and validation sets are disjoint: True\n",
      "The preprocessor is not fitted yet. Fitting now...\n",
      "The label encoder is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor_fold_2.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder_fold_2.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenwu/opt/anaconda3/envs/python_for_machine_learning/lib/python3.9/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but RFE was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature selector is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/feature_selector_fold_2.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.11159289 0.34928512 0.539122  ]\n",
      "Class instance weights: (array([0.61828925, 0.95433019, 2.98704825]), array([43891, 28436,  9085]))\n",
      "[0]\ttrain-mlogloss:1.09060\tvalidate-mlogloss:1.09211\n",
      "[1000]\ttrain-mlogloss:0.49258\tvalidate-mlogloss:0.75747\n",
      "[2000]\ttrain-mlogloss:0.43132\tvalidate-mlogloss:0.73276\n",
      "[3000]\ttrain-mlogloss:0.41110\tvalidate-mlogloss:0.72444\n",
      "[4000]\ttrain-mlogloss:0.40035\tvalidate-mlogloss:0.72014\n",
      "[5000]\ttrain-mlogloss:0.39369\tvalidate-mlogloss:0.71772\n",
      "[6000]\ttrain-mlogloss:0.38842\tvalidate-mlogloss:0.71600\n",
      "[7000]\ttrain-mlogloss:0.38503\tvalidate-mlogloss:0.71493\n",
      "[8000]\ttrain-mlogloss:0.38165\tvalidate-mlogloss:0.71361\n",
      "[9000]\ttrain-mlogloss:0.37858\tvalidate-mlogloss:0.71225\n",
      "[9999]\ttrain-mlogloss:0.37589\tvalidate-mlogloss:0.71123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/models/eval_fold_2.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class logloss: 0.7112275309821218\n",
      "Balanced accuracy (Average recall): 0.5718789061490636\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.70      0.42      0.98      0.53      0.64      0.39      1817\n",
      "          1       0.77      0.34      0.95      0.47      0.57      0.30      5687\n",
      "          2       0.66      0.95      0.42      0.78      0.64      0.43      8779\n",
      "\n",
      "avg / total       0.70      0.68      0.67      0.64      0.61      0.38     16283\n",
      "\n",
      "################################################################################\n",
      "# Fold 3\n",
      "# Training set size 65130 Validation set size 16282\n",
      "################################################################################\n",
      "The training and validation sets are disjoint: True\n",
      "The preprocessor is not fitted yet. Fitting now...\n",
      "The label encoder is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor_fold_3.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder_fold_3.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenwu/opt/anaconda3/envs/python_for_machine_learning/lib/python3.9/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but RFE was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature selector is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/feature_selector_fold_3.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.11159289 0.34928512 0.539122  ]\n",
      "Class instance weights: (array([0.61828925, 0.95433019, 2.98704825]), array([43891, 28436,  9085]))\n",
      "[0]\ttrain-mlogloss:1.09060\tvalidate-mlogloss:1.09226\n",
      "[1000]\ttrain-mlogloss:0.49258\tvalidate-mlogloss:0.75823\n",
      "[2000]\ttrain-mlogloss:0.43132\tvalidate-mlogloss:0.73462\n",
      "[3000]\ttrain-mlogloss:0.41110\tvalidate-mlogloss:0.72702\n",
      "[4000]\ttrain-mlogloss:0.40035\tvalidate-mlogloss:0.72303\n",
      "[5000]\ttrain-mlogloss:0.39369\tvalidate-mlogloss:0.72089\n",
      "[6000]\ttrain-mlogloss:0.38842\tvalidate-mlogloss:0.71919\n",
      "[7000]\ttrain-mlogloss:0.38503\tvalidate-mlogloss:0.71804\n",
      "[8000]\ttrain-mlogloss:0.38165\tvalidate-mlogloss:0.71692\n",
      "[9000]\ttrain-mlogloss:0.37858\tvalidate-mlogloss:0.71567\n",
      "[9999]\ttrain-mlogloss:0.37589\tvalidate-mlogloss:0.71472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/models/eval_fold_3.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class logloss: 0.7147174204066138\n",
      "Balanced accuracy (Average recall): 0.5688914316025578\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.70      0.42      0.98      0.52      0.64      0.39      1817\n",
      "          1       0.79      0.33      0.95      0.47      0.56      0.30      5687\n",
      "          2       0.66      0.96      0.41      0.78      0.63      0.42      8778\n",
      "\n",
      "avg / total       0.71      0.68      0.66      0.64      0.61      0.37     16282\n",
      "\n",
      "################################################################################\n",
      "# Fold 4\n",
      "# Training set size 65130 Validation set size 16282\n",
      "################################################################################\n",
      "The training and validation sets are disjoint: True\n",
      "The preprocessor is not fitted yet. Fitting now...\n",
      "The label encoder is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor_fold_4.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder_fold_4.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenwu/opt/anaconda3/envs/python_for_machine_learning/lib/python3.9/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but RFE was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature selector is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/feature_selector_fold_4.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.11159289 0.34928512 0.539122  ]\n",
      "Class instance weights: (array([0.61828925, 0.95433019, 2.98704825]), array([43891, 28436,  9085]))\n",
      "[0]\ttrain-mlogloss:1.09060\tvalidate-mlogloss:1.09226\n",
      "[1000]\ttrain-mlogloss:0.49258\tvalidate-mlogloss:0.74686\n",
      "[2000]\ttrain-mlogloss:0.43132\tvalidate-mlogloss:0.72069\n",
      "[3000]\ttrain-mlogloss:0.41110\tvalidate-mlogloss:0.71184\n",
      "[4000]\ttrain-mlogloss:0.40035\tvalidate-mlogloss:0.70734\n",
      "[5000]\ttrain-mlogloss:0.39369\tvalidate-mlogloss:0.70489\n",
      "[6000]\ttrain-mlogloss:0.38842\tvalidate-mlogloss:0.70292\n",
      "[7000]\ttrain-mlogloss:0.38503\tvalidate-mlogloss:0.70160\n",
      "[8000]\ttrain-mlogloss:0.38165\tvalidate-mlogloss:0.70017\n",
      "[9000]\ttrain-mlogloss:0.37858\tvalidate-mlogloss:0.69880\n",
      "[9999]\ttrain-mlogloss:0.37589\tvalidate-mlogloss:0.69776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/models/eval_fold_4.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class logloss: 0.6977592059906331\n",
      "Balanced accuracy (Average recall): 0.5911424555446585\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.72      0.46      0.98      0.56      0.67      0.43      1817\n",
      "          1       0.79      0.36      0.95      0.50      0.59      0.32      5687\n",
      "          2       0.67      0.95      0.44      0.78      0.65      0.44      8778\n",
      "\n",
      "avg / total       0.72      0.69      0.68      0.66      0.63      0.40     16282\n",
      "\n",
      "################################################################################\n",
      "# Fold 5\n",
      "# Training set size 65130 Validation set size 16282\n",
      "################################################################################\n",
      "The training and validation sets are disjoint: True\n",
      "The preprocessor is not fitted yet. Fitting now...\n",
      "The label encoder is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/preprocessor_fold_5.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/label_encoder_fold_5.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenwu/opt/anaconda3/envs/python_for_machine_learning/lib/python3.9/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but RFE was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature selector is not fitted yet. Fitting now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/pipeline/feature_selector_fold_5.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.11159289 0.34928512 0.539122  ]\n",
      "Class instance weights: (array([0.61828925, 0.95433019, 2.98704825]), array([43891, 28436,  9085]))\n",
      "[0]\ttrain-mlogloss:1.09060\tvalidate-mlogloss:1.09248\n",
      "[1000]\ttrain-mlogloss:0.49258\tvalidate-mlogloss:0.75846\n",
      "[2000]\ttrain-mlogloss:0.43132\tvalidate-mlogloss:0.73214\n",
      "[3000]\ttrain-mlogloss:0.41110\tvalidate-mlogloss:0.72355\n",
      "[4000]\ttrain-mlogloss:0.40035\tvalidate-mlogloss:0.71893\n",
      "[5000]\ttrain-mlogloss:0.39369\tvalidate-mlogloss:0.71626\n",
      "[6000]\ttrain-mlogloss:0.38842\tvalidate-mlogloss:0.71433\n",
      "[7000]\ttrain-mlogloss:0.38503\tvalidate-mlogloss:0.71294\n",
      "[8000]\ttrain-mlogloss:0.38165\tvalidate-mlogloss:0.71159\n",
      "[9000]\ttrain-mlogloss:0.37858\tvalidate-mlogloss:0.71011\n",
      "[9999]\ttrain-mlogloss:0.37589\tvalidate-mlogloss:0.70896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/models/eval_fold_5.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class logloss: 0.7089625423678502\n",
      "Balanced accuracy (Average recall): 0.582086402146765\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.66      0.45      0.97      0.53      0.66      0.41      1817\n",
      "          1       0.78      0.35      0.95      0.48      0.57      0.31      5687\n",
      "          2       0.67      0.95      0.44      0.78      0.65      0.44      8778\n",
      "\n",
      "avg / total       0.71      0.68      0.68      0.65      0.62      0.39     16282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Out-of-fold prediction dictionary\n",
    "oof = {}\n",
    "# Feature importance container\n",
    "feat_imp_list = []\n",
    "# Classification report container\n",
    "clf_report_list = []\n",
    "# CV splitter\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_X, train_y)):\n",
    "    # Print messages to console\n",
    "    print(\"#\" * 80)\n",
    "    print(\"# Fold\", fold + 1)\n",
    "    print(\"# Training set size\", len(train_idx), \"Validation set size\", len(val_idx))\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    # Check that the indices are indeed disjoint for training and validation set\n",
    "    print(\n",
    "        \"The training and validation sets are disjoint:\",\n",
    "        set(train_idx).isdisjoint(set(val_idx)),\n",
    "    )\n",
    "\n",
    "    # Train and validation sets\n",
    "    fold_train_X, fold_train_y = train_X.iloc[train_idx], train_y[train_idx]\n",
    "    fold_val_X, fold_val_y = train_X.iloc[val_idx], train_y[val_idx]\n",
    "\n",
    "    # Preprocessing\n",
    "    preprocessor = joblib.load(\"../outputs/pipeline/preprocessor.joblib\")\n",
    "    label_encoder = joblib.load(\"../outputs/pipeline/label_encoder.joblib\")\n",
    "    try:\n",
    "        preprocessor.transform(train_X)\n",
    "    except NotFittedError:\n",
    "        print(\"The preprocessor is not fitted yet. Fitting now...\")\n",
    "    try:\n",
    "        label_encoder.transform(train_y)\n",
    "    except NotFittedError:\n",
    "        print(\"The label encoder is not fitted yet. Fitting now...\")\n",
    "    # Fit and transform on training data\n",
    "    fold_train_X = preprocessor.fit_transform(train_X)\n",
    "    fold_train_y = label_encoder.fit_transform(train_y)\n",
    "    # Transform validation data\n",
    "    fold_val_X = preprocessor.transform(fold_val_X)\n",
    "    fold_val_y = label_encoder.transform(fold_val_y)\n",
    "    # Store fitted preprocessor and label encoder\n",
    "    joblib.dump(\n",
    "        preprocessor, f\"../outputs/pipeline/preprocessor_fold_{fold + 1}.joblib\"\n",
    "    )\n",
    "    joblib.dump(\n",
    "        label_encoder, f\"../outputs/pipeline/label_encoder_fold_{fold + 1}.joblib\"\n",
    "    )\n",
    "\n",
    "    # Feature selection\n",
    "    selector = RFE(\n",
    "        estimator=DecisionTreeClassifier(random_state=rs),\n",
    "        n_features_to_select=optimal_params[\"num_feat\"],\n",
    "        step=optimal_params[\"step\"],\n",
    "    )\n",
    "    try:\n",
    "        selector.transform(fold_train_X)\n",
    "    except NotFittedError:\n",
    "        print(\"The feature selector is not fitted yet. Fitting now...\")\n",
    "    fold_train_X = selector.fit_transform(fold_train_X, fold_train_y)\n",
    "    fold_val_X = selector.transform(fold_val_X)\n",
    "    # Store fitted feature selector\n",
    "    joblib.dump(\n",
    "        selector, f\"../outputs/pipeline/feature_selector_fold_{fold + 1}.joblib\"\n",
    "    )\n",
    "\n",
    "    # Obtaining training data class weight after resampling\n",
    "    print(\n",
    "        \"Class distribution:\",\n",
    "        np.unique(fold_train_y, return_counts=True)[1] / len(fold_train_y),\n",
    "    )\n",
    "    instance_weights = compute_sample_weight(\"balanced\", fold_train_y)\n",
    "    print(\"Class instance weights:\", np.unique(instance_weights, return_counts=True))\n",
    "\n",
    "    # Container for evaluation results\n",
    "    evals_result = {}\n",
    "    # Model, applying weights to the training data and not the validation data\n",
    "    dtrain = xgb.DMatrix(\n",
    "        data=fold_train_X,\n",
    "        label=fold_train_y,\n",
    "        feature_names=selector.get_feature_names_out().tolist(),\n",
    "        weight=instance_weights,\n",
    "    )\n",
    "    dvalid = xgb.DMatrix(\n",
    "        data=fold_val_X,\n",
    "        label=fold_val_y,\n",
    "        feature_names=selector.get_feature_names_out().tolist(),\n",
    "    )\n",
    "    model = xgb.train(\n",
    "        params=optimal_params[\"booster_params\"],\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=optimal_params[\"num_boost_round\"],\n",
    "        early_stopping_rounds=400,\n",
    "        evals=[(dtrain, \"train\"), (dvalid, \"validate\")],\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "    )\n",
    "    model.save_model(model_path + f\"model_fold_{fold + 1}.xgb\")\n",
    "    joblib.dump(evals_result, model_path + f\"eval_fold_{fold + 1}.joblib\")\n",
    "\n",
    "    # Feature importance for the current fold\n",
    "    # The booster object has a get_score method that returns a dictionary of feature names and their importance scores\n",
    "    feat_imp = model.get_score(importance_type=\"weight\")\n",
    "    df = pd.DataFrame(\n",
    "        {\"feature\": feat_imp.keys(), f\"importance_{fold + 1}\": feat_imp.values()}\n",
    "    )\n",
    "    # Add the current fold's feature importance to the container\n",
    "    feat_imp_list.append(df)\n",
    "\n",
    "    # Out-of-fold prediction, matrix of probabilities with shape (n_samples, n_classes)\n",
    "    oof_pred = model.predict(dvalid)\n",
    "    pred_classes = np.argmax(oof_pred, axis=1)\n",
    "    # Add the current fold's out-of-fold prediction to the dictionary with target values\n",
    "    oof[f\"fold_{fold + 1}\"] = {\"target\": fold_val_y, \"prediction\": oof_pred}\n",
    "    # Add report to container\n",
    "    clf_report_list.append(\n",
    "        classification_report_imbalanced(y_true=fold_val_y, y_pred=pred_classes)\n",
    "    )\n",
    "    # Print multi-class logloss and balanced accuracy (average recall (i.e., the ability of the classifier to find all the positive samples) for each class)\n",
    "    print(\n",
    "        \"Multi-class logloss:\",\n",
    "        log_loss(y_true=fold_val_y, y_pred=oof_pred, labels=[0, 1, 2]),\n",
    "    )\n",
    "    print(\n",
    "        \"Balanced accuracy (Average recall):\",\n",
    "        balanced_accuracy_score(y_true=fold_val_y, y_pred=pred_classes),\n",
    "    )\n",
    "    print(classification_report_imbalanced(y_true=fold_val_y, y_pred=pred_classes))\n",
    "\n",
    "    del (\n",
    "        fold_train_X,\n",
    "        fold_train_y,\n",
    "        fold_val_X,\n",
    "        fold_val_y,\n",
    "        dtrain,\n",
    "        dvalid,\n",
    "        model,\n",
    "        feat_imp,\n",
    "        oof_pred,\n",
    "        pred_classes,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Validation Set\n",
    "\n",
    "One quick way to benchmark the model performance is using the multi-class log-loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average multi-class logloss: 0.7086425914901782\n"
     ]
    }
   ],
   "source": [
    "avg_log_loss = 0\n",
    "for fold in range(5):\n",
    "    avg_log_loss += log_loss(\n",
    "        y_true=oof[f\"fold_{fold + 1}\"][\"target\"],\n",
    "        y_pred=oof[f\"fold_{fold + 1}\"][\"prediction\"],\n",
    "        labels=[0, 1, 2],\n",
    "    )\n",
    "avg_log_loss /= 5\n",
    "print(\"Average multi-class logloss:\", avg_log_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random guess model, when the dataset is imbalanced, simply uses the overall proportions of the traning examples belonging to each class as the predicted probabilities for each class. We can implement a function below that computes the multi-class log loss values given any array of class proportions and sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_guess_log_loss(class_ratio, sample_size):\n",
    "    if sum(class_ratio) != 1.0:\n",
    "        class_ratio[-1] += 1 - sum(\n",
    "            class_ratio\n",
    "        )  # Add the difference to the last class ratio\n",
    "\n",
    "    true_y = []\n",
    "    for ith_class_label, ith_class_ratio in enumerate(class_ratio):\n",
    "        true_y = true_y + [\n",
    "            ith_class_label for val in range(ceil(ith_class_ratio * sample_size))\n",
    "        ]\n",
    "\n",
    "    # The 'random guess' predictions simply predict the class ratios\n",
    "    preds = []\n",
    "    for i in range(len(true_y)):\n",
    "        preds += [class_ratio]\n",
    "\n",
    "    return log_loss(true_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11159289, 0.34928512, 0.539122  ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the average class ratios across five folds\n",
    "avg_class_ratios = 0\n",
    "for fold in range(5):\n",
    "    avg_class_ratios += np.unique(\n",
    "        oof[f\"fold_{fold + 1}\"][\"target\"], return_counts=True\n",
    "    )[1] / len(oof[f\"fold_{fold + 1}\"][\"target\"])\n",
    "avg_class_ratios /= 5\n",
    "avg_class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16282"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample sizes across five folds\n",
    "sample_size = (\n",
    "    reduce(\n",
    "        lambda x, y: x + y,\n",
    "        [len(oof[f\"fold_{fold + 1}\"][\"target\"]) for fold in range(5)],\n",
    "    )\n",
    "    // 5\n",
    ")\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451992625850723"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_guess_log_loss(avg_class_ratios, sample_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, our log loss values are all lower than this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average multi-class logloss: 0.7087826433332591\n"
     ]
    }
   ],
   "source": [
    "print(\"Average multi-class logloss:\", avg_log_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb7d42b50>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb7d42f70>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fb7d42dc0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fold 1 Learning Curve')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb79d6400>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb79d6820>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fb7bd72e0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fold 2 Learning Curve')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb795f5b0>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb795f9d0>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fb795f820>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fold 3 Learning Curve')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABb70lEQVR4nO3deXwTZf4H8M/kTnqXXhRayn1bLsGCrqiVCiyiroqKIqh4ryI/dMUDUFdxPVhZF0VRxHNBXEBdWFyoIIcIchQ5y00RelLa9EyazPP7Y5K0gRYaaDtp83m/XvNqMnlm8s2g9MNzTCQhhAARERGRSjRqF0BERESBjWGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhKiJLFiwAJIk4dixYxdsm5SUhPHjxzd6Tc3V+PHjkZSUpHYZRNRAGEaIzsMdIGrbnn32WbXLw1NPPYV+/fohMjISFosF3bt3x4wZM1BaWnrBY48dOwZJkvDWW281QaUtz9KlSzF8+HBERUXBYDAgPj4et99+O3788Ue1SyNqdnRqF0DUHLz88sto3769175evXqpVE21X3/9FVdddRUmTJgAk8mEHTt24PXXX8fq1auxbt06aDQt898b8+bNgyzLqry3EAL33XcfFixYgL59+2Ly5MmIi4tDdnY2li5diuuuuw4bN27E4MGDVamPqDliGCGqh+HDh2PAgAFql3GODRs2nLOvY8eOmDJlCrZs2YIrrrhChap8I4RAZWUlzGZzvY/R6/WNWNH5vf3221iwYAEmTZqEWbNmQZIkz2vPP/88Pv/8c+h0l/5X68VcF6LmqmX+s4moif3444+46qqrEBQUhPDwcIwePRr79u274HFCCPz1r39F27ZtYbFYcM0112DPnj2XVIt7LkVRUdElncfNZrNh+vTp6NSpE4xGIxISEvDMM8/AZrN5tfvkk09w7bXXIiYmBkajET169MD7779fa31//OMf8cMPP2DAgAEwm8344IMPsHbtWkiShK+//hqvvvoq2rZtC5PJhOuuuw6HDh3yOsfZc0ZqDjl9+OGH6NixI4xGIy6//HL8+uuv59SwePFi9OjRAyaTCb169cLSpUvrNQ+loqICM2fORLdu3fDWW295BRG3e+65BwMHDgQAzJgxo9Y2tc0fquu69OrVC9dcc80555BlGW3atMGtt97qte+dd95Bz549YTKZEBsbi4ceeghnzpw57+ciUht7Rojqobi4GAUFBV77oqKiAACrV6/G8OHD0aFDB8yYMQMVFRV49913MWTIEGzfvv28v+CmTZuGv/71rxgxYgRGjBiB7du3Y9iwYbDb7fWuzeFwoKioCHa7Hbt378YLL7yAkJAQzy/ESyHLMm688UZs2LABDz74ILp3745du3bh73//Ow4cOIBly5Z52r7//vvo2bMnbrzxRuh0Onz//fd49NFHIcsyHnvsMa/zZmZm4s4778RDDz2EiRMnomvXrp7XXn/9dWg0GkyZMgXFxcV44403MHbsWGzevPmC9X711VcoKSnBQw89BEmS8MYbb+CWW27BkSNHPL0py5cvx5gxY9C7d2/MnDkTZ86cwf333482bdpc8PwbNmxAYWEhJk2aBK1WW8+rWH+1XZcxY8ZgxowZyMnJQVxcnFctp06dwh133OHZ99BDD2HBggWYMGECnnjiCRw9ehT//Oc/sWPHDmzcuFHVHiWi8xJEVKdPPvlEAKh1c+vTp4+IiYkRp0+f9uzbuXOn0Gg0Yty4ceec6+jRo0IIIfLy8oTBYBAjR44Usix72j333HMCgLj33nvrVeOmTZu86uratatYs2bNBY87evSoACDefPPNOtt8/vnnQqPRiPXr13vtnzt3rgAgNm7c6NlXXl5+zvFpaWmiQ4cOXvvatWsnAIiVK1d67V+zZo0AILp37y5sNptn/+zZswUAsWvXLs++e++9V7Rr1+6cz9KqVStRWFjo2f/tt98KAOL777/37Ovdu7do27atKCkp8exbu3atAOB1ztq4a1m6dOl527lNnz5d1PbX7Nn/LQhR93XJzMwUAMS7777rtf/RRx8VwcHBnuu+fv16AUB8+eWXXu1WrlxZ634if8JhGqJ6mDNnDlatWuW1AUB2djYyMjIwfvx4REZGetpfdtlluP7667FixYo6z7l69WrY7Xb8+c9/9urKnzRpkk+19ejRA6tWrcKyZcvwzDPPICgoqF6raepj8eLF6N69O7p164aCggLPdu211wIA1qxZ42lbc26Duyfp6quvxpEjR1BcXOx13vbt2yMtLa3W95wwYQIMBoPn+VVXXQUAOHLkyAXrHTNmDCIiIuo89tSpU9i1axfGjRuH4OBgT7urr74avXv3vuD5rVYrACAkJOSCbS9GbdelS5cu6NOnDxYtWuTZ53Q68c0332DUqFGe67548WKEhYXh+uuv9/qz6t+/P4KDg73+rIj8DYdpiOph4MCBtU5gPX78OAB4DTO4de/eHT/88APKysoQFBRU57GdO3f22h8dHe31C/VCQkNDkZqaCgAYPXo0vvrqK4wePRrbt29HcnJyvc9Tm4MHD2Lfvn2Ijo6u9fW8vDzP440bN2L69OnYtGkTysvLvdoVFxcjLCzM8/zslUk1JSYmej13X4v6zHu40LHua96pU6dzju3UqRO2b99+3vOHhoYCAEpKSi5Yy8Wo67qMGTMGzz33HE6ePIk2bdpg7dq1yMvLw5gxYzxtDh48iOLiYsTExNR6jpp/VkT+hmGEqIW55ZZbcM8992DhwoWXHEZkWUbv3r0xa9asWl9PSEgAABw+fBjXXXcdunXrhlmzZiEhIQEGgwErVqzA3//+93OW4Z5vhUhdczGEEBes91KOrY9u3boBAHbt2oWbbrrpgu1rm7wKKD0btanruowZMwZTp07F4sWLMWnSJHz99dcICwvDDTfc4GkjyzJiYmLw5Zdf1nqOugIlkT9gGCG6BO3atQOgTDw82/79+xEVFVVrr0jNYw8ePIgOHTp49ufn51/S6gebzQZZls8ZGrkYHTt2xM6dO3HdddfV+YsVAL7//nvYbDZ89913Xr0T/jY04L7mZ6/OqWvf2a688kpERETgX//6F5577rkLTmJ198wUFRUhPDzcs9/dQ1Nf7du3x8CBA7Fo0SI8/vjjWLJkCW666SYYjUZPm44dO2L16tUYMmQIlwNTs8M5I0SXoHXr1ujTpw8+/fRTr6W0u3fvxv/+9z+MGDGizmNTU1Oh1+vx7rvvev3L/Z133qnXexcVFaGqquqc/R999BEANMh9UW6//XacPHkS8+bNO+e1iooKlJWVAajukaj5OYqLi/HJJ59ccg0NKT4+Hr169cJnn33mNa/mp59+wq5duy54vMViwV/+8hfs27cPf/nLX2rtcfniiy+wZcsWAEpAAIB169Z5Xi8rK8Onn37qc+1jxozBL7/8gvnz56OgoMBriAZQ/qycTideeeWVc451r7gi8lfsGSG6RG+++SaGDx+OlJQU3H///Z6lvWFhYZgxY0adx0VHR2PKlCmYOXMm/vjHP2LEiBHYsWMH/vvf/3qWDZ/P2rVr8cQTT+DWW29F586dYbfbsX79eixZsgQDBgzA3XffXa/609PTUVlZec7+m266Cffccw++/vprPPzww1izZg2GDBkCp9OJ/fv34+uvv/bcE2PYsGEwGAwYNWoUHnroIZSWlmLevHmIiYlBdnZ2vepoKq+99hpGjx6NIUOGYMKECThz5gz++c9/olevXvWa+Pv0009jz549ePvtt7FmzRrceuutiIuLQ05ODpYtW4YtW7bg559/BgAMGzYMiYmJuP/++/H0009Dq9Vi/vz5iI6ORlZWlk9133777ZgyZQqmTJmCyMhIzzwht6uvvhoPPfQQZs6ciYyMDAwbNgx6vR4HDx7E4sWLMXv2bK97khD5FVXX8hD5OfcSzF9//fW87VavXi2GDBkizGazCA0NFaNGjRJ79+6t9Vw1l3M6nU7x0ksvidatWwuz2SyGDh0qdu/eLdq1a3fBpb2HDh0S48aNEx06dBBms1mYTCbRs2dPMX36dFFaWnrBz+ZeDlvX9vnnnwshhLDb7eJvf/ub6NmzpzAajSIiIkL0799fvPTSS6K4uNhzvu+++05cdtllwmQyiaSkJPG3v/1NzJ8/v9YlrCNHjjynHvfS3sWLF9da5yeffOLZV9fS3tqWKQMQ06dP99q3cOFC0a1bN2E0GkWvXr3Ed999J/70pz+Jbt26XfC6uX3zzTdi2LBhIjIyUuh0OtG6dWsxZswYsXbtWq9227ZtE4MGDRIGg0EkJiaKWbNm1bm0t7brUtOQIUMEAPHAAw/U2ebDDz8U/fv3F2azWYSEhIjevXuLZ555Rpw6daren42oqUlCNNDMLiKiZqxPnz6Ijo72LNsmoqbDOSNEFFCqqqrgcDi89q1duxY7d+7E0KFD1SmKKMCxZ4SIAsqxY8eQmpqKu+++G/Hx8di/fz/mzp2LsLAw7N69G61atVK7RKKAwwmsRBRQIiIi0L9/f3z00UfIz89HUFAQRo4ciddff51BhEgl7BkhIiIiVXHOCBEREamKYYSIiIhU1SzmjMiyjFOnTiEkJOS8t6QmIiIi/yGEQElJCeLj46HR1N3/0SzCyKlTpzxfyEVERETNy4kTJ9C2bds6X28WYSQkJASA8mHcX+FNRERE/s1qtSIhIcHze7wuzSKMuIdmQkNDGUaIiIiamQtNseAEViIiIlIVwwgRERGpimGEiIiIVNUs5owQEVHgEkLA4XDA6XSqXQqdRavVQqfTXfJtNxhGiIjIb9ntdmRnZ6O8vFztUqgOFosFrVu3hsFguOhzMIwQEZFfkmUZR48ehVarRXx8PAwGA2986UeEELDb7cjPz8fRo0fRuXPn897Y7Hx8DiPr1q3Dm2++iW3btiE7OxtLly7FTTfdVGf77Oxs/N///R+2bt2KQ4cO4YknnsA777xzUcUSEVHgsNvtkGUZCQkJsFgsapdDtTCbzdDr9Th+/DjsdjtMJtNFncfnCFNWVobk5GTMmTOnXu1tNhuio6PxwgsvIDk52ecCiYgosF3sv7apaTTEn4/PPSPDhw/H8OHD690+KSkJs2fPBgDMnz/f17cjIiKiFs4v54zYbDbYbDbPc6vVqmI1RERE1Jj8su9r5syZCAsL82z8kjwiIgpUSUlJLX6upV+GkalTp6K4uNiznThxQu2SiIiI6m3o0KGYNGlSg5zr119/xYMPPtgg5/JXfjlMYzQaYTQaG/+NMv4FnNoB9LgRSLqy8d+PiIgIyrJYp9MJne7Cv4ajo6OboCJ1+WXPSFPZve7fwJYPsPPX9WqXQkREFyCEQLndocomhKh3nePHj8dPP/2E2bNnQ5IkSJKEBQsWQJIk/Pe//0X//v1hNBqxYcMGHD58GKNHj0ZsbCyCg4Nx+eWXY/Xq1V7nO3uYRpIkfPTRR7j55pthsVjQuXNnfPfddw11mVXhc89IaWkpDh065Hl+9OhRZGRkIDIyEomJiZg6dSpOnjyJzz77zNMmIyPDc2x+fj4yMjJgMBjQo0ePS/8El6Dcodw8p9Juu0BLIiJSW0WVEz2m/aDKe+99OQ0WQ/1+Zc6ePRsHDhxAr1698PLLLwMA9uzZAwB49tln8dZbb6FDhw6IiIjAiRMnMGLECLz66qswGo347LPPMGrUKGRmZiIxMbHO93jppZfwxhtv4M0338S7776LsWPH4vjx44iMjLz0D6sCn8PI1q1bcc0113ieT548GQBw7733YsGCBcjOzkZWVpbXMX379vU83rZtG7766iu0a9cOx44du8iyG4aQlI8vOatUrYOIiFqOsLAwGAwGWCwWxMXFAQD2798PAHj55Zdx/fXXe9pGRkZ63YPrlVdewdKlS/Hdd9/h8ccfr/M9xo8fjzvvvBMA8Nprr+Ef//gHtmzZghtuuKExPlKj8zmMDB069LzdVQsWLDhnny/dW01J1rg+vuxQtxAiIrogs16LvS+nqfbeDWHAgAFez0tLSzFjxgwsX74c2dnZcDgcqKioOOcf9We77LLLPI+DgoIQGhqKvLy8BqlRDX45gbXJuMKIJLNnhIjI30mSVO+hEn8VFBTk9XzKlClYtWoV3nrrLXTq1Almsxm33nor7Hb7ec+j1+u9nkuSBFmWG7zeptK8/1QvkSyxZ4SIiBqewWCA0+m8YLuNGzdi/PjxuPnmmwEoPSVqT2FQQ0CvphGenhGGESIiajhJSUnYvHkzjh07hoKCgjp7LTp37owlS5YgIyMDO3fuxF133dWsezguVoCHEVc3F4dpiIioAU2ZMgVarRY9evRAdHR0nXNAZs2ahYiICAwePBijRo1CWloa+vXr18TVqi+gh2ncc0Y07BkhIqIG1KVLF2zatMlr3/jx489pl5SUhB9//NFr32OPPeb1/Oxhm9oWhRQVFV1Unf4ioHtGZE/PCMMIERGRWgI6jEgaZakWe0aIiIjUE9BhxD1nRBIMI0RERGoJ6DACrqYhIiJSXWCHEa27Z4SraYiIiNQS0GHEPUzDOSNERETqCegwAq1raS/njBAREakmoMOIxPuMEBERqS6gwwh0BgCAJC78/QFERETUOAI6jHh6RjhMQ0REfiQpKQnvvPOO57kkSVi2bFmd7Y8dOwZJkpCRkdHotTWGgL4dvOSawKplGCEiIj+WnZ2NiIiIBj3n+PHjUVRUdN6Q01QCOoy4l/ayZ4SIiPxZXFyc2iU0qoAeptHo3D0jnDNCROT3hADsZepstXw5XV0+/PBDxMfHQ5Zlr/2jR4/Gfffdh8OHD2P06NGIjY1FcHAwLr/8cqxevfq85zx7mGbLli3o27cvTCYTBgwYgB07dni1dzqduP/++9G+fXuYzWZ07doVs2fP9rw+Y8YMfPrpp/j2228hSRIkScLatWsBACdOnMDtt9+O8PBwREZGYvTo0ed8WV9DC+yeEQ7TEBE1H1XlwGvx6rz3c6cAQ1C9mt52223485//jDVr1uC6664DABQWFmLlypVYsWIFSktLMWLECLz66qswGo347LPPMGrUKGRmZiIxMfGC5y8tLcUf//hHXH/99fjiiy9w9OhRPPnkk15tZFlG27ZtsXjxYrRq1Qo///wzHnzwQbRu3Rq33347pkyZgn379sFqteKTTz4BAERGRqKqqgppaWlISUnB+vXrodPp8Ne//hU33HADfvvtNxgMBh8vXP0EdBjRuO8zAvaMEBFRw4iIiMDw4cPx1VdfecLIN998g6ioKFxzzTXQaDRITk72tH/llVewdOlSfPfdd3j88ccveP6vvvoKsizj448/hslkQs+ePfH777/jkUce8bTR6/V46aWXPM/bt2+PTZs24euvv8btt9+O4OBgmM1m2Gw2ryGgL774ArIs46OPPoIkSQCATz75BOHh4Vi7di2GDRt2ydenNgEdRqBjzwgRUbOhtyg9FGq9tw/Gjh2LiRMn4r333oPRaMSXX36JO+64AxqNBqWlpZgxYwaWL1+O7OxsOBwOVFRUICsrq17n3rdvHy677DKYTCbPvpSUlHPazZkzB/Pnz0dWVhYqKipgt9vRp0+f8557586dOHToEEJCQrz2V1ZW4vDhw/Wq72IEdBjRMIwQETUfklTvoRK1jRo1CkIILF++HJdffjnWr1+Pv//97wCAKVOmYNWqVXjrrbfQqVMnmM1m3HrrrbDb7Q32/gsXLsSUKVPw9ttvIyUlBSEhIXjzzTexefPm8x5XWlqK/v3748svvzzntejo6Aar72wBHUY8S3s5TENERA3IZDLhlltuwZdffolDhw6ha9eu6NevHwBg48aNGD9+PG6++WYASgDwZYJo9+7d8fnnn6OystLTO/LLL794tdm4cSMGDx6MRx991LPv7J4Ng8EAp9P791+/fv2waNEixMTEIDQ0tN41XaoAX02jTMRhzwgRETW0sWPHYvny5Zg/fz7Gjh3r2d+5c2csWbIEGRkZ2LlzJ+66665zVt6cz1133QVJkjBx4kTs3bsXK1aswFtvveXVpnPnzti6dSt++OEHHDhwAC+++CJ+/fVXrzZJSUn47bffkJmZiYKCAlRVVWHs2LGIiorC6NGjsX79ehw9ehRr167FE088gd9///3SLsh5BHQYkbRKGNGxZ4SIiBrYtddei8jISGRmZuKuu+7y7J81axYiIiIwePBgjBo1CmlpaZ5ek/oIDg7G999/j127dqFv3754/vnn8be//c2rzUMPPYRbbrkFY8aMwaBBg3D69GmvXhIAmDhxIrp27YoBAwYgOjoaGzduhMViwbp165CYmIhbbrkF3bt3x/3334/KyspG7SmRhPBh8bRKrFYrwsLCUFxc3KAXI2PPXvRZnAIHtNDNKGyw8xIR0aWrrKzE0aNH0b59e6/JmuRfzvfnVN/f3wHeM6LMGdHB6dMNbYiIiKjhBHQY0epq3LxF5rwRIiIiNQR0GHEv7QUAOKvUK4SIiCiABXQY0eprhBGZYYSIiEgNgR1Gag7TsGeEiMgvNYN1FgGtIf58AjqMaDRa2IVWeeKwqVsMERF50bt6r8vLy1WuhM7H/eejrzna4KOAvgOrTqOBHXoY4AScDCNERP5Eq9UiPDwceXl5AACLxeL58jZSnxAC5eXlyMvLQ3h4OLRa7UWfK6DDiFYrwQY9glHJnhEiIj/k/kZZdyAh/xMeHu71zb8XI6DDiE4jwQ5XtxLDCBGR35EkCa1bt0ZMTAyqqji3z9/o9fpL6hFxC+gwopEkVAodIAFwNty3JRIRUcPSarUN8kuP/JPPE1jXrVuHUaNGIT4+HpIkYdmyZRc8Zu3atejXrx+MRiM6deqEBQsWXESpDa9mz4hcValyNURERIHJ5zBSVlaG5ORkzJkzp17tjx49ipEjR+Kaa65BRkYGJk2ahAceeAA//PCDz8U2NK1Wgt3VOeRkGCEiIlKFz8M0w4cPx/Dhw+vdfu7cuWjfvj3efvttAED37t2xYcMG/P3vf0daWpqvb9+gdBplAisAyFWcM0JERKSGRr/PyKZNm5Camuq1Ly0tDZs2barzGJvNBqvV6rU1Bo3EYRoiIiK1NXoYycnJQWxsrNe+2NhYWK1WVFRU1HrMzJkzERYW5tkSEhIapTadRoJdKJ1DMlfTEBERqcIv78A6depUFBcXe7YTJ040yvtoa05gtbNnhIiISA2NvrQ3Li4Oubm5Xvtyc3MRGhoKs9lc6zFGoxFGo7GxS4MkSbBLyvfTcAIrERGROhq9ZyQlJQXp6ele+1atWoWUlJTGfut6cUhKz4io4n1GiIiI1OBzGCktLUVGRgYyMjIAKEt3MzIykJWVBUAZYhk3bpyn/cMPP4wjR47gmWeewf79+/Hee+/h66+/xlNPPdUwn+ASucOI7GDPCBERkRp8DiNbt25F37590bdvXwDA5MmT0bdvX0ybNg0AkJ2d7QkmANC+fXssX74cq1atQnJyMt5++2189NFHqi/rdfP0jDCMEBERqcLnOSNDhw6FEKLO12u7u+rQoUOxY8cOX9+qSTg0BsAJCN5nhIiISBV+uZqmKTldE1gFl/YSERGpgmFE4w4jnMBKRESkBoYR15wRcM4IERGRKhhGtK77mTg5TENERKSGgA8jsmuYBhymISIiUkXAhxH3nBGJwzRERESqCPgw4tAqt6TXOGr/0j4iIiJqXAEfRpw6dxgpV7kSIiKiwMQw4uoZ0To5TENERKQGhhF3GOEwDRERkSoCPow4XMM0OifDCBERkRoCPoxAZ1F+MIwQERGpIuDDiFPv6hmRKwFZVrkaIiKiwBPwYUS4ekYAAJw3QkRE1OQCPoxIrp4RAICdy3uJiIiaWsCHEa1WiwrhuiV8FcMIERFRUwv4MKLXaVAO15flMYwQERE1OYYRjYQKdxjhMA0REVGTYxjRalAh2DNCRESkloAPIzoth2mIiIjUFPBhRK+tOUxTpm4xREREAYhhRKupsZqG9xkhIiJqagEfRnRaicM0REREKgr4MGLQalABk/LEXqpuMURERAEo4MOIUa9FiXDdhdVWom4xREREASjgw4hBq0ExgpQnFUWq1kJERBSIAj6MGPUaWIUrjFQWq1sMERFRAGIY0WlgheubexlGiIiImhzDiE4Dq2AYISIiUgvDiE4LKzhMQ0REpBaGEfaMEBERqSrgw4hBp2HPCBERkYoCPowYddrqnhFHBeCwqVsQERFRgGEY0WlQAjNkISk72DtCRETUpAI+jBh0GggogQQAUHFG3YKIiIgCTMCHEaNOuQQFIkzZUVagYjVERESB56LCyJw5c5CUlASTyYRBgwZhy5YtdbatqqrCyy+/jI4dO8JkMiE5ORkrV6686IIbmk6rgVYj4TRClR1l+eoWREREFGB8DiOLFi3C5MmTMX36dGzfvh3JyclIS0tDXl5ere1feOEFfPDBB3j33Xexd+9ePPzww7j55puxY8eOSy6+oRi0GpwWDCNERERq8DmMzJo1CxMnTsSECRPQo0cPzJ07FxaLBfPnz6+1/eeff47nnnsOI0aMQIcOHfDII49gxIgRePvtty+5+IZi1NcMIxymISIiako+hRG73Y5t27YhNTW1+gQaDVJTU7Fp06Zaj7HZbDCZTF77zGYzNmzYUOf72Gw2WK1Wr60xGXUanIZ7zgh7RoiIiJqST2GkoKAATqcTsbGxXvtjY2ORk5NT6zFpaWmYNWsWDh48CFmWsWrVKixZsgTZ2dl1vs/MmTMRFhbm2RISEnwp02dGnRYFHKYhIiJSRaOvppk9ezY6d+6Mbt26wWAw4PHHH8eECROg0dT91lOnTkVxcbFnO3HiRKPWaNBxmIaIiEgtPoWRqKgoaLVa5Obmeu3Pzc1FXFxcrcdER0dj2bJlKCsrw/Hjx7F//34EBwejQ4cOdb6P0WhEaGio19aYjDpN9dLekrp7bIiIiKjh+RRGDAYD+vfvj/T0dM8+WZaRnp6OlJSU8x5rMpnQpk0bOBwO/Pvf/8bo0aMvruJGYNRpcApRyhPrKUCW1S2IiIgogOh8PWDy5Mm49957MWDAAAwcOBDvvPMOysrKMGHCBADAuHHj0KZNG8ycORMAsHnzZpw8eRJ9+vTByZMnMWPGDMiyjGeeeaZhP8klMOg0yBEREJAgOW1AeQEQHKN2WURERAHB5zAyZswY5OfnY9q0acjJyUGfPn2wcuVKz6TWrKwsr/kglZWVeOGFF3DkyBEEBwdjxIgR+PzzzxEeHt5gH+JSGXVaOKBDhSkGlspcoPgEwwgREVETkYQQQu0iLsRqtSIsLAzFxcWNMn/kwc+24n97c/Fr3N8QXbQTuP0zoIf/DCMRERE1R/X9/R3w300DKMM0AFBqdC1ZLmrc1TtERERUjWEEyjANAJwxtlF2nDmqYjVERESBhWEEyu3gAaDA2E7ZkZ+pYjVERESBhWEEyhflAUCe0XWn14KDKlZDREQUWBhGUN0zckqXqOwozQEqi1WsiIiIKHAwjAAw65U5I0XCDAS77iTLoRoiIqImwTACwGJQwkil3Qm0TlZ2ntyuYkVERESBg2EE1T0j5XYn0Ka/svPkVhUrIiIiChwMIwDMBuVGtOVVTqCtK4z8zjBCRETUFBhGcNYwjbtn5MxRoOy0ilUREREFBoYR1BimqXIA5gigVSflhVOcN0JERNTYGEYAmA015owA1b0jJ7aoVBEREVHgYBjBWcM0AJCYovw8tl6lioiIiAIHwwhqDtO4wkiHq5Wfv/8K2EpVqoqIiCgwMIyglmGaiPZAWCIgO4CsX1SsjIiIqOVjGAFgcS3ttTtkOGUBSBLQcajy4oH/qlcYERFRAGAYQfUwDQBUuIdqeoxWfu5ZBjgdTV8UERFRgGAYAWDSayBJyuNyuyt4tL8asLQCyguAI2tVq42IiKilYxgBIEmSp3ek0i4rO7V6oNeflMe/vKdSZURERC0fw4iL143P3K54RPl5+Eeg8IgKVREREbV8DCMu56yoAYDIDkCn6wEIYONsdQojIiJq4RhGXNw9IxU1wwgAXPmU8jPjK6D4ZBNXRURE1PIxjLgEGZXlvWW2s1bOtBsMJA4GnHYg/SUVKiMiImrZGEZcQkxKGCmpPCuMSBKQ9qry+Levgdw9TVwZERFRy8Yw4hJq0gMASiqrzn2xTT/XfUcEkP5y0xZGRETUwjGMuAS7hmlKzx6mcbt2GiBpgQMrgcyVTVgZERFRy8Yw4lLnMI1bVCcg5VHl8X8mARVnmqYwIiKiFo5hxCXYHUbq6hkBgGueB1p1Akqygf88BQjRRNURERG1XAwjLiGeOSPnCSN6M3DLh4BGB+xZChz4oYmqIyIiarkYRlxC3HNGapvAWlOb/sCgh5XH3z0OlOQ2cmVEREQtG8OIywXnjNR07QtATE+gLB9YMhGQnRc+hoiIiGrFMOJSr2EaN70ZuG0BoLcAR38Cfv5H4xZHRETUgjGMuLgnsNa5tPds0V2A4W8oj9fMBPIPNFJlRERELRvDiIt7mMZ6oTkjNfW9G+h4HeC0AUsfBJw+HEtEREQAGEY8Qmrc9EzUd8muJAGj/wmYwoBTO4B1bzZihURERC0Tw4iLe86IEEDZ2d/cez6h8cCIt5THP/0N+G1xI1RHRETUcl1UGJkzZw6SkpJgMpkwaNAgbNmy5bzt33nnHXTt2hVmsxkJCQl46qmnUFlZeVEFNxaTXgOdRgIAlNZnEmtNl90OpDyuPF72CHD4xwaujoiIqOXyOYwsWrQIkydPxvTp07F9+3YkJycjLS0NeXl5tbb/6quv8Oyzz2L69OnYt28fPv74YyxatAjPPffcJRffkCRJqr4Lqy/zRtyuf0X5Mj25CvjXncCxDQ1cIRERUcvkcxiZNWsWJk6ciAkTJqBHjx6YO3cuLBYL5s+fX2v7n3/+GUOGDMFdd92FpKQkDBs2DHfeeed5e1NsNhusVqvX1hSqJ7H62DMCABoNcMs8oMtwwFEJLLobOH24gSskIiJqeXwKI3a7Hdu2bUNqamr1CTQapKamYtOmTbUeM3jwYGzbts0TPo4cOYIVK1ZgxIgRdb7PzJkzERYW5tkSEhJ8KfOiBRuVeSP1Xt57Np0RuO0T5S6tFWeAhWMBW2kDVkhERNTy+BRGCgoK4HQ6ERsb67U/NjYWOTk5tR5z11134eWXX8aVV14JvV6Pjh07YujQoecdppk6dSqKi4s924kTJ3wp86KFXMowjZveDNzxFRAcC+TvA75/gl+oR0REdB6Nvppm7dq1eO211/Dee+9h+/btWLJkCZYvX45XXnmlzmOMRiNCQ0O9tqYQ6r7x2cUM09QUEgfc9qnyhXq7/w1s+HsDVEdERNQy6XxpHBUVBa1Wi9xc7y+Hy83NRVxcXK3HvPjii7jnnnvwwAMPAAB69+6NsrIyPPjgg3j++eeh0fjP6uJgow/fT3Mh7VKAG14HVkwB0l8CorsC3UZe+nmJiIhaGJ+SgMFgQP/+/ZGenu7ZJ8sy0tPTkZKSUusx5eXl5wQOrVYLAPW/uVgT8Xw/zcXOGTnbwInAwIeUx0sfBnJ2N8x5iYiIWhCfuyUmT56MefPm4dNPP8W+ffvwyCOPoKysDBMmTAAAjBs3DlOnTvW0HzVqFN5//30sXLgQR48exapVq/Diiy9i1KhRnlDiL8LMShgpLrc33EmH/RVIHAzYrMCXtwFFWQ13biIiohbAp2EaABgzZgzy8/Mxbdo05OTkoE+fPli5cqVnUmtWVpZXT8gLL7wASZLwwgsv4OTJk4iOjsaoUaPw6quvNtynaCARQQYAQGF5A37HjM4A3PkVMP8GIH8/MH84cNciIK5Xw70HERFRMyYJfxsrqYXVakVYWBiKi4sbdTLr0h2/46lFO3Flpyh88cCghj259RTw2Wig4ABgCAHu/gZIvKJh34OIiMiP1Pf3t//MHvUDERZXz0hZAw7TuIXGA/f9ALS7ErCXAF/8CThe+71ZiIiIAgnDSA2RrmGaMw05Z6QmSyQwdjHQ/mrAXgp8cQtwdH3jvBcREVEzwTBSQ82ekUYbvTJYlDkjHa8DqsqBL28FDqVf+DgiIqIWimGkBnfPiM0ho6LK2Xhv5L5La5cblO+x+ep2YMcXjfd+REREfoxhpAaLQQuDTrkkjTJvpCa9Cbj9c6DXnwDZAXz7GLDsUaCqsnHfl4iIyM8wjNQgSRIiXUM1Z8oacHlvXXQG4E8fA394GpA0QMaXwPuDgeM/N/57ExER+QmGkbNU32ukkXtG3CQJuPYF4O5/A8FxQOFh4JMRwIZ3+AV7REQUEBhGztLKHUbKbE37xh2vBR77BUi+C4AAVk8HFt4FlBU0bR1ERERNjGHkLK2ClTBSUNJEPSM1mSOAm94DRrwFaA1A5grgvRTlm39luenrISIiagIMI2eJDTUBAHKtKk0klSTlC/YeSAeiugBlecA39wEf/gE48AOHboiIqMVhGDlLTIgRAJBX0sTDNGdrfRnw0Hpg6HPK7eNzdilLgOen8UZpRETUojCMnCVG7Z6RmvQmYOhfgEm/AUOeBHRm4MRm4NM/Ap/dBJzcpnaFREREl4xh5Cyx/tIzUpMlErj+ZeDJDODyiYBGDxxZA8y7Flg4Fsjdq3aFREREF41h5Cx+1TNytpA4YORbwJ+3AX3GKvcm2f8f5d4k/7oL+G0xYCtVu0oiIiKfMIycxT1npNzuRKnNoXI1dYhop6y6efQXoNsfAQggczmw5AHgzY5KMNnxJVBpVbtSIiKiC2IYOUuQUYcQow6An/aO1BTdFbjjS+DhjcBVU4CI9sp33WQuB759FHi7K/DN/cDuJQwmRETkt3RqF+CPYkKNKMl3INdaiY7RwWqXc2FxvZTt2heA3D3Avu+Ve5OcPgjs/kbZNHog6Uqgw9VA3GVAwkDAGKJ25URERAwjtYkJMeFwfhny/WkSa31IUnUwGfqsstpm77dA5n+VYHJkjbIBgEYHdBgK9LwZ6DwMCI5RtXQiIgpcDCO1iA1V5o34/TDN+UgS0HaAsg17BSg4CBxYCZzcDpzcChRlAYdWKxsAxPcDEgYp9zdp01+54ZokqfsZiIgoIDCM1KL6LqzNrGfkfKI6K5tbwUFlLknmciB7J3Bqu7K5WVoBbS8H4noDMT2AVh2Vn1p909dOREQtGsNILaJDWkDPyIVEdVZuqDb0L4A1Gzi6ThnWyc4ATmUA5aeVnpQDK6uP0QcB7VKAdkOA2J5AdDcgPJE9KEREdEkYRmrh7hnxqxufNabQ1kDyGGUDAIdNuf3871uB3F1A/gGg4ABQWeQ9tAMApjAgurvSc9Kqk/IzsgMQlgCYw9X4NERE1MwwjNTCE0Zacs/I+eiM1fNN3GQZyNujfC/O71uAnN3AmWNAZTFw4hdlO5shBAhrq4STiHZASGsgNF7ZwhOBoGjlvYiIKKAxjNQixjNMY4MQAhKHIQCNRpk/EtcbwKPKPocdyN+v9JoUHlHmoZw+pISUikLAXgLk71O2Os+rV5YYG4OVeSqmMOU7eAwW5bk7wARFK70txhBlMwRxeIiIqIVgGKlFjGs1TUWVEyU2B0JNnLRZK51BWX3T+rJzX7OXAcW/A8UngNOHlccl2cr8FOvvQPFJQK5StopCZSvK8uHNJcAQrIQY909zBBAcpyxTDo5Vwow5AgiKUkKOKRwwhXISLhGRn2EYqYXFoEOISYeSSgdyiysZRi6GIUi5Q2x0V6BT6rmvyzJgLwVsVuXusPZSoKwAsJUod5G1lwJl+UBJDmA9BZTmKT/tJYCQAQjlsb3E99r0Flc4CVN6XNzBxRKp7DMEuQJOSPVjQ5DreTCgN7NXhoioATGM1CEhwoK92VZkFZajcyzvVNrgNBqll8IUCoT5cJwQQFWFElrspTV+liorgEpzgNJ8oDRX6W0pPw2Un1HmtriDS1W5spVkK8NMvpI0roDiDinBZ4WXIO/XawYaT6g5a7/WwIBDRAGLYaQOiZHVYYT8iCQp80kMFgCxvh3rdLh6YoqVnxVFSmgpy3eFlkJlv61UGWayl9R4XKpsgNIzY7MqW0PR6LzDic6kDCfpTEpQ0RldP02A3qTMq9EZlV4anbH6uTlc6fnRGQGt0fWa6xwarWvTAZLrp1anvCeHrohIRQwjdWjXygIAOH6aYaTF0OqUoRhL5MUdL8tKj4q7J8YdUGo+tpcpW2Wxq21ZjTBTy2OHa8WW7FCOqSxuuM/rC0mrBBKtocbmCkPuQOMJRMYabWs81hnOOt5w7n6NTulZkjRKkDIEu85vrBGYdMrEZknjHaA0euW92INE1OIwjNQhIVIJIyfYM0JuGo0yJGMMBhpq5M7pAKrcIaW8OqhUVSiTex2Vyqolp025/4ujUtmqKqsf13xeXujaZ3MdYwccFYCzCpCdgHAqwcf92E04AYezOhz5M3dw8vT6uAOR3hVY3D0/WleIcvcmmapDlbudO+BodDWOP/u5K0A5HUoQcockrcE1f8gdlrQ1jtNV92R5hTdX4CIiLwwjdfD0jDCMUGPS6gCtazJtUxNCCSb2UiXMyFVKaHHaXWHGXh2G3KHH/XrNzWE/d5/TrrR12GocY1N+oUMoYcjdy+So8ZrsqK4Doo66awYnlXqSLoXkCknuMKTR1R5mavYIeT2v8VPSKuEIcD139TpJ2trba43VYcjTrkZ7z0/NWc/d56tlX53nqLlf50NbrXf97AkLCAwjdUis0TMiywIaDf+HoBZGkpRffOYIwKx2MbUQoroHx1nlCioO1+Oq6l4fd+DxhClXkJEdtfcgOV1By1kj+MhVZz13eO8XsmtejVCG64SzugdKdlaHKFn2rsPhCnlen8up9IZV1fah6VzSuUFJiBohq+ZWS1Bz92bV3M4OQOeEL8mH0FXjWKD295M0ZwWyGsdpdLW8R40NZ/3u8Qpnrsden1OqPs79XHZUD5F6jpGqz+H+vK06Xvww9iViGKlDfLgZWo0Em0NGfqnNc1dWImoikqT0HkDXvO/U6wko9uqA4qisDjGeoOV0BRpHjec1QpHsrN4nnNXPhay8j5CrN3cbp6PG0JxDCXDupfFCrjF0J1efU9Q4r9fzmu9Zn7Y1zumpubb3cZ738nmCJRzAhZrSpbnlI+Cy21R5a4aROui1GsSHm3CisALHT5czjBDRxdFoAI2xeQeqxlZXSJFl7/Al3OFLqg5dXpurF61mSBKiOqRB1BGi5LOOOU9wqjO4OeDpdXCfo+b5zzmPo+7Ahpo11yBqDl0K1/OaP92BFN6fV6OrUZOo/XghK7daUAnDyHkkRlpworACWYXlGNhena4rIqIWT6MBoOES8wCmuZiD5syZg6SkJJhMJgwaNAhbtmyps+3QoUMhSdI528iRIy+66KaSGBkEAMg6XaZyJURERC2Xz2Fk0aJFmDx5MqZPn47t27cjOTkZaWlpyMvLq7X9kiVLkJ2d7dl2794NrVaL225TZ1zKF+4VNUcKGEaIiIgai89hZNasWZg4cSImTJiAHj16YO7cubBYLJg/f36t7SMjIxEXF+fZVq1aBYvF0izCSOeYYADAobxSlSshIiJquXwKI3a7Hdu2bUNqavUXn2k0GqSmpmLTpk31OsfHH3+MO+64A0FBQXW2sdlssFqtXpsauri+k+ZIfhkcTvkCrYmIiOhi+BRGCgoK4HQ6ERvr/Z0gsbGxyMnJueDxW7Zswe7du/HAAw+ct93MmTMRFhbm2RISEnwps8G0CTfDpNfA7pT5HTVERESN5KImsF6sjz/+GL1798bAgQPP227q1KkoLi72bCdOnGiiCr1pNBI6uYZqDuRyqIaIiKgx+BRGoqKioNVqkZub67U/NzcXcXFx5z22rKwMCxcuxP3333/B9zEajQgNDfXa1NIlRhmqOZRXoloNRERELZlPYcRgMKB///5IT0/37JNlGenp6UhJSTnvsYsXL4bNZsPdd999cZWqpFOs0jNykJNYiYiIGoXPNz2bPHky7r33XgwYMAADBw7EO++8g7KyMkyYMAEAMG7cOLRp0wYzZ870Ou7jjz/GTTfdhFatWjVM5U2ks6tn5CCHaYiIiBqFz2FkzJgxyM/Px7Rp05CTk4M+ffpg5cqVnkmtWVlZ0Gi8O1wyMzOxYcMG/O9//2uYqptQF1fPyOH8UjhlAS2/MI+IiKhBSUKIOr6n239YrVaEhYWhuLi4yeePOGWBHtNWwuaQsWbKULSPqntJMhEREVWr7+/vJl1N0xxpNRK6xilDNXtPqXO/EyIiopaMYaQeesYraW7PqWKVKyEiImp5GEbqoUd8GABgD3tGiIiIGhzDSD308vSMMIwQERE1NIaReugWFwqNBBSU2pBrrVS7HCIiohaFYaQezAYtOkYrS3w5b4SIiKhhMYzUU682yryR3Sc5VENERNSQGEbq6bK2ShjZdvyMypUQERG1LAwj9XRFB+U29r8eK0SVU1a5GiIiopaDYaSeusaGIMKiR7ndiV0nOW+EiIiooTCM1JNGI2FQe6V3ZNPh0ypXQ0RE1HIwjPjgig6RAIBfjjCMEBERNRSGER9c0VHpGdl67AzsDs4bISIiaggMIz7oEhOCyCADKqqc2HWySO1yiIiIWgSGER8o80aUoRrOGyEiImoYDCM+ci/x/eVIocqVEBERtQwMIz5Kcc8bOV7IeSNEREQNgGHER51jghEZZEBllYydvxepXQ4REVGzxzDiI0mSkOIaqll/IF/laoiIiJo/hpGLcE23GABA+v48lSshIiJq/hhGLsI1XaMhScCeU1ZkF1eoXQ4REVGzxjByEVoFG9EvMQIAsHpvrsrVEBERNW8MIxfpuu7KUM2PHKohIiK6JAwjF+m6brEAgI2HT6Pc7lC5GiIiouaLYeQidYkNRptwM+wOGT8f4t1YiYiILhbDyEWSJAnXulbV/JjJoRoiIqKLxTByCa51zRtZsz8PQgiVqyEiImqeGEYuQUqHVjDrtcgursS+7BK1yyEiImqWGEYugUmvxZBOyt1Yf9zPJb5EREQXg2HkEl3rWlXDu7ESERFdHIaRS+SexJpxoginS20qV0NERNT8MIxcorgwE3q0DoUQwNpMfnEeERGRrxhGGoDnbqxc4ktEROQzhpEG4B6qWZeZjyqnrHI1REREzQvDSANIbhuOVkEGlNgc+PVYodrlEBERNSsMIw1Ao5EwtGv1DdCIiIio/i4qjMyZMwdJSUkwmUwYNGgQtmzZct72RUVFeOyxx9C6dWsYjUZ06dIFK1asuKiC/ZV73giX+BIREfnG5zCyaNEiTJ48GdOnT8f27duRnJyMtLQ05OXV/kvYbrfj+uuvx7Fjx/DNN98gMzMT8+bNQ5s2bS65eH9yZeco6DQSjuSX4VhBmdrlEBERNRs+h5FZs2Zh4sSJmDBhAnr06IG5c+fCYrFg/vz5tbafP38+CgsLsWzZMgwZMgRJSUm4+uqrkZycfMnF+5NQkx4D20cCAJbvyla5GiIioubDpzBit9uxbds2pKamVp9Ao0Fqaio2bdpU6zHfffcdUlJS8NhjjyE2Nha9evXCa6+9BqfTWef72Gw2WK1Wr605uLmv0tuzeOsJfnEeERFRPfkURgoKCuB0OhEbG+u1PzY2Fjk5ObUec+TIEXzzzTdwOp1YsWIFXnzxRbz99tv461//Wuf7zJw5E2FhYZ4tISHBlzJVM6J3a5j1Whw7XY6ME0Vql0NERNQsNPpqGlmWERMTgw8//BD9+/fHmDFj8Pzzz2Pu3Ll1HjN16lQUFxd7thMnTjR2mQ0iyKjD9T2UoLaCQzVERET14lMYiYqKglarRW6u9zfU5ubmIi4urtZjWrdujS5dukCr1Xr2de/eHTk5ObDb7bUeYzQaERoa6rU1FyN6K9dhxa4cDtUQERHVg09hxGAwoH///khPT/fsk2UZ6enpSElJqfWYIUOG4NChQ5Dl6juTHjhwAK1bt4bBYLjIsv3X0K4xCDJocbKoAtuOn1G7HCIiIr/n8zDN5MmTMW/ePHz66afYt28fHnnkEZSVlWHChAkAgHHjxmHq1Kme9o888ggKCwvx5JNP4sCBA1i+fDlee+01PPbYYw33KfyISa9FWk+ld+S7nadUroaIiMj/6Xw9YMyYMcjPz8e0adOQk5ODPn36YOXKlZ5JrVlZWdBoqjNOQkICfvjhBzz11FO47LLL0KZNGzz55JP4y1/+0nCfws/c2CceS3acxIpd2Zj2xx7QaXmjWyIiorpIohlMbLBarQgLC0NxcXGzmD9S5ZQx6LV0FJbZ8dl9A/GHLtFql0RERNTk6vv7m/9kbwR6rcYzkZVDNUREROfHMNJIbkxWboD2w+4cVFbVfYM3IiKiQMcw0kgGtItA6zATSmwOrM3MV7scIiIiv8Uw0kg0GgmjkuMBAN9zqIaIiKhODCON6EZXGFm9LxelNofK1RAREfknhpFG1DM+FB2igmBzyFi1t/bv7iEiIgp0DCONSJKqh2q+y+BQDRERUW0YRhrZjX2UMLL+YAEKy2r/Lh4iIqJAxjDSyDpGB6NXm1A4ZMFv8iUiIqoFw0gTcE9kXbL9d5UrISIi8j8MI03gpr5toNNI2J5VhD2nitUuh4iIyK8wjDSBmBATbuil3B7+i1+yVK6GiIjIvzCMNJG7r2gHAPg24ySslVUqV0NEROQ/GEaayKD2kegcE4xyuxNLt59UuxwiIiK/wTDSRCRJwj0pSu/I578chxBC5YqIiIj8A8NIE7q5bxtYDFocyivFxkOn1S6HiIjILzCMNKEQkx639W8LAJi/8ajK1RAREfkHhpEmNn5Ie0gS8OP+PBzJL1W7HCIiItUxjDSx9lFBuK5bDADg05+PqVsMERGRH2AYUcG4lCQAwNIdJ1Fhd6pbDBERkcoYRlQwpFMU2kaYYa10YOkOLvMlIqLAxjCiAq1GwvjBSQCUiaxc5ktERIGMYUQlYy5PQJBrme/mo4Vql0NERKQahhGVhJj0uLGP8m2+H60/onI1RERE6mEYUdEDV3WAViNh9b48bDvO3hEiIgpMDCMq6hgdjFv7KTdBe/t/Bzh3hIiIAhLDiMoev7YTdBoJPx8+jdX78tQuh4iIqMkxjKgsIdKCB67qAAD428r9cDhllSsiIiJqWgwjfuDRazoiwqLHobxSLN72u9rlEBERNSmGET8QatLjz9d2BgDMWnUApTaHyhURERE1HYYRPzH2ikQkRlqQX2LD31cdULscIiKiJsMw4ieMOi1eHt0TAPDZpmP4/Uy5yhURERE1DYYRPzK0awwGd2yFKqfA7NUH1S6HiIioSTCM+JkpaV0BAP/e/jsO5JaoXA0REVHjYxjxM/0SIzCsRyxkAbz0/R7eCI2IiFo8hhE/9PzI7jDqNNh46DQWb+VSXyIiatkuKozMmTMHSUlJMJlMGDRoELZs2VJn2wULFkCSJK/NZDJddMGBoF2rIEy+vgsA4NUV+5BfYlO5IiIiosbjcxhZtGgRJk+ejOnTp2P79u1ITk5GWloa8vLqvpV5aGgosrOzPdvx48cvqehAcP+V7dEzPhTFFVWY8f0etcshIiJqND6HkVmzZmHixImYMGECevTogblz58JisWD+/Pl1HiNJEuLi4jxbbGzsJRUdCHRaDf72p8ug1UhY/ls2Pt5wVO2SiIiIGoVPYcRut2Pbtm1ITU2tPoFGg9TUVGzatKnO40pLS9GuXTskJCRg9OjR2LPn/P/St9lssFqtXlsg6tUmDM+4Vte8unwvfj5UoHJFREREDc+nMFJQUACn03lOz0ZsbCxycnJqPaZr166YP38+vv32W3zxxReQZRmDBw/G77/XPTFz5syZCAsL82wJCQm+lNmiPPiHDripTzxkAfz5Xztw/HSZ2iURERE1qEZfTZOSkoJx48ahT58+uPrqq7FkyRJER0fjgw8+qPOYqVOnori42LOdOHGiscv0W5IkYeYtl6FnfChOl9kxaVEGnDKX+xIRUcvhUxiJioqCVqtFbm6u1/7c3FzExcXV6xx6vR59+/bFoUOH6mxjNBoRGhrqtQUys0GLeeMGIMSow46sIvxt5X61SyIiImowPoURg8GA/v37Iz093bNPlmWkp6cjJSWlXudwOp3YtWsXWrdu7VulAS4+3IwZNyrfXfPhuiOYt+6IyhURERE1DJ+HaSZPnox58+bh008/xb59+/DII4+grKwMEyZMAACMGzcOU6dO9bR/+eWX8b///Q9HjhzB9u3bcffdd+P48eN44IEHGu5TBIg/9W+Lp1Kr7z+y6NcslSsiIiK6dDpfDxgzZgzy8/Mxbdo05OTkoE+fPli5cqVnUmtWVhY0muqMc+bMGUycOBE5OTmIiIhA//798fPPP6NHjx4N9ykCyJOpnVFSWYWPNhzFC8t2o1tcKJITwtUui4iI6KJJohl8+YnVakVYWBiKi4sDfv4IAAgh8PAX2/DDnly0jTBj+Z+vQphFr3ZZREREXur7+5vfTdMMSZKEN29LRmKkBb+fqcDT3+zkF+oREVGzxTDSTIWa9JhzVz8YtBr8b28uXluxj4GEiIiaJYaRZqx32zBMv1GZezNv/VHM/O9+BhIiImp2GEaaubGD2uGVm3oBUJb8/t/inbA5nCpXRUREVH8MIy3APVe0w8uje0KrkbBk+0mM+eAX5Fkr1S6LiIioXhhGWohxKUn46N4BCDPrkXGiCHd/vBlHC/g9NkRE5P8YRlqQa7rG4JuHUxAVbMCB3FKMencD1mTmqV0WERHReTGMtDCdY0Ow/ImrcHlSBEptDkz45Fd8ufm42mURERHViWGkBYoNNeGLBwZhWA/lrrjPL92NWf/LhMMpq1wZERHRuRhGWiijTou5d/fH+MFJAIB//HgIo+dsxPasM+oWRkREdBaGkRZMo5EwfVQPvPGnyxBq0mHPKStuee9nPP7VdhSW2dUuj4iICADDSIsnSRJuvzwBP04Zilv7twUA/Oe3bIyYvR6bDp9WuToiIiKGkYARFWzEW7cl49+PDEaHqCDkWCtxz8eb8fkvx3nXViIiUhXDSIDp3y4C3z4+BKOS4+GQBV5cthuPf7UD+SU2tUsjIqIAxTASgEJMevzjjj6YOrwbNBKwfFc2bvznBny/8xRX3BARUZOTRDPoo7darQgLC0NxcTFCQ0PVLqdF2X2yGH/+1w7P3VoTIy144rrOuKlPPHRaZlUiIrp49f39zTBCKLc78N6aw/hi83EUlVcBANpHBeHJ6zpjVHI8tBpJ5QqJiKg5Yhghn5XbHfh803F8sO6IZ+lvm3Azbu7bBmk949CrTSgkicGEiIjqh2GELlqZzYFPNx3Dh+uOeHpKAOCGnnF4bkR3JLayqFgdERE1FwwjdMkqq5z4395cLP/tFFbvy4NTFtBrJdw3pD0m/qEDooKNapdIRER+jGGEGtS+bCteW7EP6w8WAABMeg3uuDwRYwclonNsiMrVERGRP2IYoQYnhMCP+/Pwj/SD2Pl7sWd/ckI4bu4Tjz8mx7O3hIiIPBhGqNEIIbDx0GnM33gUPx3Ih1NW/hPSaiRc2y0GD/6hAy5PilS5SiIiUhvDCDWJglIbvt95Cst2nPTqLenROhR9E8NxTdcYXNk5Cia9VsUqiYhIDQwj1OQO5ZXgo/VHsXjb757eEgAINupwbbcYDO0ajSGdohAbalKxSiIiaioMI6SaXGslth8/g01HTmPV3lxkF1d6vZ4QaVZ6TDpFIaVjK4SY9CpVSkREjYlhhPyCEAJbjhZi7YF8bDxUgF0ni1HzvzitRkK/xHD0jA9Dp5hgdIkNQfuoIEQFG3iDNSKiZo5hhPxScUUVthwtxLoD+dhwqMDznThnCzHq0N0976RbDAa0i+B35RARNTMMI9QsnCgsx8+HC3AorxQH80pxMLcUp4orcPZ/lUEGLVI6RqFzbDC6xAYjqVUQusSGIMioU6dwIiK6IIYRarZsDieO5Jch40QRth47g9X7clFcUXVOO71WQqeYECREmJEYaUG31qEY0C4C7VpZOMRDROQHGEaoxZBlgb3ZVmw6fBpZheXIzCnB0dNlyC+x1do+NtSIIZ2i0DM+DP0Sw9G7TRiHeIiIVMAwQi2aEAInCiuwP8eKHGsljhaUYeeJIuw+aYXdKXu1Neu16BAdhA7RweiTEI6e8aGICTEiJtSEYA7zEBE1GoYRCkiVVU5sOnIa24+fwb7sEmw5ehrWSketbSUJGNQ+EqndY9ExJhh92oYj3KLnEA8RUQNhGCEC4JQFjuSX4tjpcmTmWLEjqwiH80txusyOklpCil4rISHSggHtItA3MQIdooKQ2MqC2BATNBqGFCIiXzCMEF3AicJy/Hd3NrYdP4P9OSU4frq8zrY6jYT4cDM6RAchNsSE+HAzEluZ0TbCgqhgI2JCjFzZQ0R0FoYRIh+V2x0oLLNjzykrdp4owq6TxTh+uhwniyq8bm9fl3CLHq3DzGgfZUHnmBC0DjOha1wI2kSYEW42wKDjJFoiCiyNGkbmzJmDN998Ezk5OUhOTsa7776LgQMHXvC4hQsX4s4778To0aOxbNmyer8fwwipyeGUkVdiQ1ZhOQ7nl6KgxI6TReXIKlSCSmGpHWV253nPIUlA+1ZB6BwbjHatgpAYaUGvNmGIDzMhKtjIISAiapHq+/vb537lRYsWYfLkyZg7dy4GDRqEd955B2lpacjMzERMTEydxx07dgxTpkzBVVdd5etbEqlKp9UgPtyM+HAzrujQqtY21soqnCqqQHZRJTJzS5BVWI4TheXYl12C02U2CAEcKSjDkVruOKvXSogNNSkrfEJMSIg0o31UMFoFGxBi0iHMrEdCpAWh/A4fImqhfO4ZGTRoEC6//HL885//BADIsoyEhAT8+c9/xrPPPlvrMU6nE3/4wx9w3333Yf369SgqKmLPCAUMWRYoKLXhQG4pDuSW4PczFdhzShkCyiupRD1GgAAo334cFWxAVLARsWEmRAcb0SrIgMhgA1oFGdEq2IDWrp4Wk17buB+KiKgeGqVnxG63Y9u2bZg6dapnn0ajQWpqKjZt2lTncS+//DJiYmJw//33Y/369Rd8H5vNBput+oZWVqvVlzKJ/IpGIyEm1ISYUBOu7Bzl9ZrDKSO3xIac4grkl9iQU1yJY6fL8fuZchSU2lFqU+axFJYpj0ttDhw7z0RbtyCDFqFmPaJDjIgLNSE21ASLQQuLQYdgkw5BBi3MBi3Mei3aRJjRJTYEet4YjohU4lMYKSgogNPpRGxsrNf+2NhY7N+/v9ZjNmzYgI8//hgZGRn1fp+ZM2fipZde8qU0omZJp9WgTbgZbcLN521XbnfgVFElzpTbkWutRK7VhsIyG06X2lFQasfpMhvyrDbP9/qU2Z0oszuRXVyJ31Bcr1qMOg1CTDpEBSu9LOFmA0LNOgQbdQi3GJAQaUHX2BDEhSk3i9NyngsRNZBGXYtYUlKCe+65B/PmzUNUVNSFD3CZOnUqJk+e7HlutVqRkJDQGCUSNQsWgw6dYoIv2E6WBayVVSgqr0JxRRVyrJXIKa5EQakNFXYnyqucKKl0oNzmQEWVEliO5JWixOaAzSHD5go39RFs1CHUpEOISY9Qs+vnOc9rfy3UpIdRp+EN5ogIgI9hJCoqClqtFrm5uV77c3NzERcXd077w4cP49ixYxg1apRnnywrt+rW6XTIzMxEx44dzznOaDTCaDT6UhoRQRkSCrcYEG4xAACS63GMEAIFpXZUVjlRanMgx1qJ4vIqnClXbgxXanPgTJkdB/NKcSS/1HNHW/ewEYorL6pWg1bpiQk16z0TdcMtBsSGGBERZIBJr4VJr4FRp4XFoEVMiBHBJh3Mei2CjEqg4XJpopbBpzBiMBjQv39/pKen46abbgKghIv09HQ8/vjj57Tv1q0bdu3a5bXvhRdeQElJCWbPns3eDiI/IEkSokOqw3/31uefJG5zOFFa6UBJpQPWyirlZ0XVWY+9X6vZtqSyCrIA7E4Zp8vsOF1Wv56Y2kRY9IgPNyPcokeQQRlSCnJtwUat57n3fh0sNebMmPVaLq0mUpnPwzSTJ0/GvffeiwEDBmDgwIF45513UFZWhgkTJgAAxo0bhzZt2mDmzJkwmUzo1auX1/Hh4eEAcM5+ImoejDotjMFatAq+uN5LWRYos3uHmeLyKpTYqlBQYkdeSSWKK6pQWSWjssoJm0NGUUUVTpfaUFnlRIVrPgwAnCmvwpnyqkv6PFqNBItBiyCDDhFBBsSEGBFq1sOk08Ck1yLYpINFr4VRr4FBq4HZoEWwUY+IID3Mei0MOg2MOg2CjXoEGZVJwpxPQ+Qbn8PImDFjkJ+fj2nTpiEnJwd9+vTBypUrPZNas7KyoNGw65SIaqfRSAgx6RFi0iMe55+4WxenLFBa6cDvReXIK7GhuLwKpTYHylxbqc2p/LQ7UFrp3udAmd2BMtdrNofsOVeJq6cnx1qJfdmX/hmjgo2IDNLDYtB5AkqQQYsQkx4xrmGoCItyV16DToMggxbhFmWOjdnAQEOBh7eDJ6KAJMsCNocMa2WVK8Q4UVBmQ77VhlKbA5UOJyqrZFgrqlBZ5YTdIcPmkFFR5URJZRUKy+ywOWTP/lKbo15fG1BfBq0GJr3Gsxxbr9XAoJWg02qg10ow6rSeMGPUahBk1MFs0MLo6tEJMys9NWa9DgadBL1WA51GA4NOgkmvRYhRD5NBaWvQKr0+HK6ihtZod2AlImoJNBpJmTdiaJgbxAkhPKEkp7gS1ooqlNmdKK/RG3O6zI6icjvyS2wosTk8QabM5kCxa96N+5+HdqcMu1NWJgw30a2WdBrJM+yk17o3JbzU3KfTSjDqNDC7enxq3r9GmY+jg14rQauRoNNooNNI0GolzzCXQau8h1GnhcWodQUt5bw6jcRVVgGIYYSIqAFIkuRaAaRF1EXOp3EHmgq7ExVVTpTblTkypTYHHLKMKqcMu0Ogyil7emXsDifsThkllQ6vXpqSyiqU25VzKMfJcMjKsWU2JSRVVDlRs2/cIQs4XMeoyejq8TG4A5FOgl6jgVajBByjXuuZ0+Pu/TEbNDBotdBrJVeoUUKQzhV8THotdFpJed31mkmvhCe9rjoMBRmUCc4GV1jSaxmOmgLDCBGRn6gZaCKa4P3c4afKKaPKKVxhRhmSqnIK135laMpeo507DLlDU6nNNTfH7kC5TdnnkGU4nAJOWaBKFnDKSiByn8vukFFZpTw/m80VqvxFzV6bmr1DhhohRqvRQO8KS3qta/KzUeklMumV52ZXD5PB1cvkPt69T6dVzqHXaTzvZdBV91C5w5nSVoJWUt6vJYQlhhEiogBVM/yoRZaFp8fG4RSokpWQUzP42J0yqhwynELA4VQCVGWVE5Xu3iPXT7tDhlNWjnOHoSqnQKUrYDmcSu+Qw/V6uV05R83gVVLpOCcIKUNmKl2getBIgE6jgUYDaCUJQUadMhfIFXaCXENhOq1ryEwjeX6aXX/+Wo2EP/Vri95tw1T5DAwjRESkGo1GgsE1V8VfyLKAvcZQWM2g5KgRkJSAUx18HHJ12CmzO5Rl6DYnbA4lMFVWybBVKcNq7qEz93ncvVEO2btXyv0e7jlEtS05cd+3B67AVHaRyalfuwiGESIiIn+g0UgwadTtMaqLUxaorHLCIQvIsoBTKENhNbdS19J1d9gpszlQ5ZThdPVCeX46ZZTZlXv5OJwyusRe+CsnGgvDCBERUTOh1SjDMC2N//SLERERUUBiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkqmbx1X9CCACA1WpVuRIiIiKqL/fvbffv8bo0izBSUlICAEhISFC5EiIiIvJVSUkJwsLC6nxdEheKK35AlmWcOnUKISEhkCSpwc5rtVqRkJCAEydOIDQ0tMHOS+fitW4avM5Ng9e5afA6N43GvM5CCJSUlCA+Ph4aTd0zQ5pFz4hGo0Hbtm0b7fyhoaH8D72J8Fo3DV7npsHr3DR4nZtGY13n8/WIuHECKxEREamKYYSIiIhUFdBhxGg0Yvr06TAajWqX0uLxWjcNXuemwevcNHidm4Y/XOdmMYGViIiIWq6A7hkhIiIi9TGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUlVAh5E5c+YgKSkJJpMJgwYNwpYtW9QuyW/NnDkTl19+OUJCQhATE4ObbroJmZmZXm0qKyvx2GOPoVWrVggODsaf/vQn5ObmerXJysrCyJEjYbFYEBMTg6effhoOh8Orzdq1a9GvXz8YjUZ06tQJCxYsaOyP57def/11SJKESZMmefbxOjeMkydP4u6770arVq1gNpvRu3dvbN261fO6EALTpk1D69atYTabkZqaioMHD3qdo7CwEGPHjkVoaCjCw8Nx//33o7S01KvNb7/9hquuugomkwkJCQl44403muTz+Qun04kXX3wR7du3h9lsRseOHfHKK694fXEar7Xv1q1bh1GjRiE+Ph6SJGHZsmVerzflNV28eDG6desGk8mE3r17Y8WKFb5/IBGgFi5cKAwGg5g/f77Ys2ePmDhxoggPDxe5ublql+aX0tLSxCeffCJ2794tMjIyxIgRI0RiYqIoLS31tHn44YdFQkKCSE9PF1u3bhVXXHGFGDx4sOd1h8MhevXqJVJTU8WOHTvEihUrRFRUlJg6daqnzZEjR4TFYhGTJ08We/fuFe+++67QarVi5cqVTfp5/cGWLVtEUlKSuOyyy8STTz7p2c/rfOkKCwtFu3btxPjx48XmzZvFkSNHxA8//CAOHTrkafP666+LsLAwsWzZMrFz505x4403ivbt24uKigpPmxtuuEEkJyeLX375Raxfv1506tRJ3HnnnZ7Xi4uLRWxsrBg7dqzYvXu3+Ne//iXMZrP44IMPmvTzqunVV18VrVq1Ev/5z3/E0aNHxeLFi0VwcLCYPXu2pw2vte9WrFghnn/+ebFkyRIBQCxdutTr9aa6phs3bhRarVa88cYbYu/eveKFF14Qer1e7Nq1y6fPE7BhZODAgeKxxx7zPHc6nSI+Pl7MnDlTxaqaj7y8PAFA/PTTT0IIIYqKioRerxeLFy/2tNm3b58AIDZt2iSEUP7n0Wg0Iicnx9Pm/fffF6GhocJmswkhhHjmmWdEz549vd5rzJgxIi0trbE/kl8pKSkRnTt3FqtWrRJXX321J4zwOjeMv/zlL+LKK6+s83VZlkVcXJx48803PfuKioqE0WgU//rXv4QQQuzdu1cAEL/++qunzX//+18hSZI4efKkEEKI9957T0RERHiuu/u9u3bt2tAfyW+NHDlS3HfffV77brnlFjF27FghBK91Qzg7jDTlNb399tvFyJEjveoZNGiQeOihh3z6DAE5TGO327Ft2zakpqZ69mk0GqSmpmLTpk0qVtZ8FBcXAwAiIyMBANu2bUNVVZXXNe3WrRsSExM913TTpk3o3bs3YmNjPW3S0tJgtVqxZ88eT5ua53C3CbQ/l8ceewwjR44851rwOjeM7777DgMGDMBtt92GmJgY9O3bF/PmzfO8fvToUeTk5Hhdo7CwMAwaNMjrOoeHh2PAgAGeNqmpqdBoNNi8ebOnzR/+8AcYDAZPm7S0NGRmZuLMmTON/TH9wuDBg5Geno4DBw4AAHbu3IkNGzZg+PDhAHitG0NTXtOG+rskIMNIQUEBnE6n11/WABAbG4ucnByVqmo+ZFnGpEmTMGTIEPTq1QsAkJOTA4PBgPDwcK+2Na9pTk5Ordfc/dr52litVlRUVDTGx/E7CxcuxPbt2zFz5sxzXuN1bhhHjhzB+++/j86dO+OHH37AI488gieeeAKffvopgOrrdL6/I3JychATE+P1uk6nQ2RkpE9/Fi3ds88+izvuuAPdunWDXq9H3759MWnSJIwdOxYAr3VjaMprWlcbX6+5zqfWRFD+1b57925s2LBB7VJanBMnTuDJJ5/EqlWrYDKZ1C6nxZJlGQMGDMBrr70GAOjbty92796NuXPn4t5771W5upbl66+/xpdffomvvvoKPXv2REZGBiZNmoT4+Hhea/IIyJ6RqKgoaLXac1Yg5ObmIi4uTqWqmofHH38c//nPf7BmzRq0bdvWsz8uLg52ux1FRUVe7Wte07i4uFqvufu187UJDQ2F2Wxu6I/jd7Zt24a8vDz069cPOp0OOp0OP/30E/7xj39Ap9MhNjaW17kBtG7dGj169PDa1717d2RlZQGovk7n+zsiLi4OeXl5Xq87HA4UFhb69GfR0j399NOe3pHevXvjnnvuwVNPPeXp+eO1bnhNeU3rauPrNQ/IMGIwGNC/f3+kp6d79smyjPT0dKSkpKhYmf8SQuDxxx/H0qVL8eOPP6J9+/Zer/fv3x96vd7rmmZmZiIrK8tzTVNSUrBr1y6v/wFWrVqF0NBQzy+GlJQUr3O42wTKn8t1112HXbt2ISMjw7MNGDAAY8eO9Tzmdb50Q4YMOWdp+oEDB9CuXTsAQPv27REXF+d1jaxWKzZv3ux1nYuKirBt2zZPmx9//BGyLGPQoEGeNuvWrUNVVZWnzapVq9C1a1dEREQ02ufzJ+Xl5dBovH/VaLVayLIMgNe6MTTlNW2wv0t8mu7agixcuFAYjUaxYMECsXfvXvHggw+K8PBwrxUIVO2RRx4RYWFhYu3atSI7O9uzlZeXe9o8/PDDIjExUfz4449i69atIiUlRaSkpHhedy85HTZsmMjIyBArV64U0dHRtS45ffrpp8W+ffvEnDlzAmrJaW1qrqYRgte5IWzZskXodDrx6quvioMHD4ovv/xSWCwW8cUXX3javP766yI8PFx8++234rfffhOjR4+udWlk3759xebNm8WGDRtE586dvZZGFhUVidjYWHHPPfeI3bt3i4ULFwqLxdJil5vW5t577xVt2rTxLO1dsmSJiIqKEs8884ynDa+170pKSsSOHTvEjh07BAAxa9YssWPHDnH8+HEhRNNd040bNwqdTifeeustsW/fPjF9+nQu7fXVu+++KxITE4XBYBADBw4Uv/zyi9ol+S0AtW6ffPKJp01FRYV49NFHRUREhLBYLOLmm28W2dnZXuc5duyYGD58uDCbzSIqKkr83//9n6iqqvJqs2bNGtGnTx9hMBhEhw4dvN4jEJ0dRnidG8b3338vevXqJYxGo+jWrZv48MMPvV6XZVm8+OKLIjY2VhiNRnHdddeJzMxMrzanT58Wd955pwgODhahoaFiwoQJoqSkxKvNzp07xZVXXimMRqNo06aNeP311xv9s/kTq9UqnnzySZGYmChMJpPo0KGDeP75572Wi/Ja+27NmjW1/p187733CiGa9pp+/fXXokuXLsJgMIiePXuK5cuX+/x5JCFq3AaPiIiIqIkF5JwRIiIi8h8MI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUtX/A18n/BO7oqJyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb78e2e50>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb78f0310>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fb7947f40>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fold 4 Learning Curve')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb7a862e0>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fb7a86c70>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fb793ee20>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fold 5 Learning Curve')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    eval_result = joblib.load(model_path + f\"eval_fold_{fold + 1}.joblib\")\n",
    "    plt.plot(eval_result[\"train\"][\"mlogloss\"], label=\"train\")\n",
    "    plt.plot(eval_result[\"validate\"][\"mlogloss\"], label=\"validate\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Fold {fold + 1} Learning Curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, at around 2000 rounds, the learning rate begins to plateau. Although the log-loss value continuous to decrease, the rate at which it decreases is increasing lower."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7cf4a60>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7c77c10>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBoUlEQVR4nO3deXwT1f4//leSNkn3faELlLWAIMUitSLbxwouF8FdRClV8PcVikhFgYuAgFAFRUQRFATEC4oXBGURLxbLIihSKIKUQmmhUGhp6ZIutEkz8/ujEowNmDZJQzKv5+Mxj3szOWfmHWr7znmfMzMyURRFEBERkVOQ2zsAIiIish4mdiIiIifCxE5EROREmNiJiIicCBM7ERGRE2FiJyIiciJM7ERERE7Exd4BWEIQBFy8eBFeXl6QyWT2DoeIiJpIFEVUVlYiLCwMcrntxpq1tbXQarUWH0epVEKtVlshIttx6MR+8eJFREZG2jsMIiKy0Pnz5xEREWGTY9fW1qJtG08UXtZbfKzQ0FDk5eXd0sndoRO7l5cXAKDtxBmQq27df2SyjqgNl+0dArWgnKRAe4dALUCorcX5OW8Z/p7bglarReFlPc5lRMHbq/lVAU2lgDaxZ6HVapnYbeVa+V2uUkNxC/8jk3W4KFT2DoFakJy/05LSEtOpnl4yeHo1/zwCHGPK16ETOxERkbn0ogC9BU9H0YuC9YKxISZ2IiKSBAEiBDQ/s1vStyXxcjciIiInwhE7ERFJggABlhTTLevdcpjYiYhIEvSiCL3Y/HK6JX1bEkvxREREToQjdiIikgSpLJ5jYiciIkkQIEIvgcTOUjwREZET4YidiIgkgaV4IiIiJ8JV8URERORwOGInIiJJEP7cLOnvCJjYiYhIEvQWroq3pG9LYmInIiJJ0Iuw8Olu1ovFljjHTkRE5EQ4YiciIkngHDsREZETESCDHjKL+jsCluKJiIicCEfsREQkCYLYsFnS3xEwsRMRkSToLSzFW9K3JbEUT0RE5EQ4YiciIkmQyoidiZ2IiCRBEGUQRAtWxVvQtyWxFE9EROREOGInIiJJYCmeiIjIieghh96CQrXeirHYEhM7ERFJgmjhHLvIOXYiIiJqaRyxExGRJHCOnYiIyInoRTn0ogVz7A5yS1mW4omIiJwIR+xERCQJAmQQLBjPCnCMITsTOxERSYJU5thZiiciInIiHLETEZEkWL54jqV4IiKiW0bDHLsFD4FhKZ6IiIhaGkfsREQkCYKF94rnqngiIqJbCOfYiYiInIgAuSSuY+ccOxERkRPhiJ2IiCRBL8qgt+DRq5b0bUlM7EREJAl6CxfP6VmKJyIiopbGETsREUmCIMohWLAqXuCqeCIiolsHS/FERETkcDhiJyIiSRBg2cp2wXqh2BQTOxERSYLlN6hxjCK3Y0RJREREZuGInYiIJMHye8U7xliYiZ2IiCSBz2MnIiJyItdG7JZszbFkyRJERUVBrVYjLi4OBw8evGn7RYsWITo6Gm5uboiMjMTEiRNRW1tr9vk4Yr8FPHPbcTzfIxOBbjU4eSUAc3++B8eKQ/6x34PtT+O9hB/xY14Uxv/vAQCAi1yPCXceRL/IfER4a1ClVeJAQQTe+/UuFNd42Pqj0D/417AzeOzp0/Dzr0Vejg+WLu6BUyf9TbZtHaXBc0kn0CG6HCGhNfjko9vx7YYORm263V6Cx54+hQ6dyhEQWIs5b9yFA/vCWuKjkBme7Xgco7scRZDbVWSVBWB2Rh/8fiX4H/s91CYHH/RJw87zUXhp72DD/pxnPjHZ/u0jcViRFWOtsMmK1q9fj5SUFCxbtgxxcXFYtGgRBg8ejOzsbAQHN/5vYd26dZgyZQpWrlyJu+++G6dOncKoUaMgk8mwcOFCs855S4zYm/ptxpk80D4Hk+N/xpKMXnhs4+PILg3A8oe2wl9dc9N+YZ4avHbXARy61Mpov9qlHl0DS7D0cCwe2/g4Xv7fYET5lOPj+7+35ccgM/QbeAFjxh7DutWdMX7M/yH3jA/mLPgZPr6mv4mrVPW4dMkDqz69DaVXVCbbqNX1yDvjg48X9bBl6NQMD7bOwb/vOIAPj8di6PeP4WS5P1YN3AZ/1dWb9gv3qMTUnr/g4OXQRu/d9c1zRtvkX/pDEIEf8tvZ6mM4lWs3qLFka6qFCxdizJgxSEpKQteuXbFs2TK4u7tj5cqVJtvv378fffr0wTPPPIOoqCgMGjQIw4cPb1JetHtiv/ZtZubMmTh8+DB69OiBwYMH4/Lly/YOrUUkdj+K/2Z1xabszjhT7o839/RHbb0rHu188oZ95DIBC+5Nw0eH7sR5jbfRe1VaFV7YNgQ7cjvgbIUfjl4OxVs/90W3oGK08qy09cehm3jkidPYsS0KO3dE4fw5b3y0sCfqahUY9OA5k+1PZ/tj5bLu2LMrEjqdwmSbQwdDseaz23BgX7gtQ6dmeL7zMaw/0wUbczsjR+OH6Qf74Wq9C55of/Pf7YV3p+GD33vhfJV3o/dLat2NtoTwc/ilKAznqxu3pcYEUWbxBgAajcZoq6urM3k+rVaLjIwMJCQkGPbJ5XIkJCTgwIEDJvvcfffdyMjIMCTy3NxcbN++HQ8++KDZn9Puib2p32aciatcj9uCinGgIMKwT4QMBy6EIyak6Ib9xsYeQulVN2zM7mLWebyUWggioKkzPeoj23NxEdAhuhyZGddLb6IoQ2ZGMDp3LbVjZGQLrnI9uvkX4+fC61+4RMiwvzACPQNv/Ls9vlsGrtS64b+5nf/xHAHqGgwIz8d/z/xzW7KuyMhI+Pj4GLbU1FST7UpKSqDX6xESYjy1GhISgsLCQpN9nnnmGcyePRv33HMPXF1d0b59ewwYMAD//ve/zY7PrnPs177NTJ061bDvZt9m6urqjL4ZaTSaFonTVnzVtXCRi7hy1c1o/5Wr7mjrW26yzx2hl/BY9Ek8svEJs86hVNTj1bgD2JbTEdU6paUhUzN5+9RBoRBRVmr85aq8TIXI1qykOBs/1Z+/27XGv9sltW5o511usk9s0CU80T4bQ75/zKxzPNr2FKp1rvjhfFtLw5UMwcJ7xV+7Qc358+fh7X29SqJSWW/QlJ6ejnnz5uHjjz9GXFwccnJyMGHCBMyZMwfTp0836xh2Tew3+zZz8mTjclVqaipmzZrVUuHdctxdtXhnYBpm7OmP8r/9wTDFRa7H+wn/gwzArL39bB8gETWLh4sW78b/hH//2g9ldf/8uw0Aj7fLxndnO0ArcA20uSx/ultDX29vb6PEfiOBgYFQKBQoKjKu0hQVFSE0tPEaCgCYPn06nnvuOYwePRoA0L17d1RXV+PFF1/EtGnTIJf/c/wO9V/E1KlTkZKSYnit0WgQGRlpx4gsU16rRr0gQ4Cb8WKaALcalFx1b9S+tbcGEd6VRgvh5LKGpw0dG7MMD64fjvMaHwDXkvpOhHlVIWnLwxyt25mmQgW9XgY/f+O5OF+/OpSWqu0UFdlKWd2fv9tq49/tQPVVlJj4Ut7aU4NIz0p82n+HYd+13+2TT3+KQVufQn6Vj+G9XkGX0N6nHBN+Tmh0LLp1KJVKxMbGIi0tDcOGDQMACIKAtLQ0JCcnm+xTU1PTKHkrFA1rbEQzHxtr18Te1G8zKpXKqiUPe9MJCvxRHIS7wi8g7WxDOU0GEXeFF2DtH90atc8t98XDXz9ptO/lOw/CQ6lD6s99UFjlCeB6Um/jU47ELUNRXsfEYW/19XLkZPuixx2XDZejyWQiYmIvY8um9naOjqxNJyhwvDQId4cU4McL13+37w4twBenbmvU/ozGFw9sM55eS7n9N3i4ajEnow8u1XgavfdE+5M4diUQJ8sDbPchnJAeMugtuMlMc/qmpKQgMTERvXr1Qu/evbFo0SJUV1cjKSkJADBy5EiEh4cb5umHDBmChQsXomfPnoZS/PTp0zFkyBBDgv8ndk3szfk242w+P9YDqQN24XhxEI5dDsHI7r/DzVWHTdkNC2LeHpiGomoPvH/wLmj1LjhdZvyLXKlt+KJzbb+LXI9F9/0PXQOL8dL3D0IhExHo1nDpXEWdCjrBvP8wyPo2/bcjUqYewulsP5zK8sPQx3OgUuux8/s2AIBXpx7ClRI1Vi9v+FLn4iKgdZTG8P8DAq+iXYdyXL3qgksFDX/o1W71CAuvMpwjJLQa7TqUo1KjRPHlxlUfajkrT3bHgvh0HCsNwu9XgjEq+hjcXHTYkBsNAFgQvwtFNR5492gctIILTlcY389A82eV7e/7PV20eKB1LlIPx7fMB3Ei1irFN8VTTz2F4uJizJgxA4WFhYiJicGOHTsMU9D5+flGI/Q33ngDMpkMb7zxBgoKChAUFIQhQ4Zg7ty5Zp/T7qX4f/o24+y+P9MBfuqreLnXbwh0r0FWSSBe3P4vXPmzFN/Ks8pwiYU5gt2rcW/UWQDA5if+a/TeyO8exm+XeFmUvez5KQLevnV4LukE/PzrkJvjgxmv90F5WUNFJSikBsJfKm3+gVfx0YpdhtePP30ajz99Gr9nBmLKKw1rJjpGl+GdRXsNbV5MPgYA2LmjNd5/u1cLfCq6ke35HRCgrsUrtx9CkLoGJ8oC8fxPD+JKbcPvdph70363r3moTQ5kALacY6XHUSQnJ99wsJqenm702sXFBTNnzsTMmTObfT6ZaG7R3oY++ugjLFiwwPBtZvHixYiLi/vHfhqNBj4+Pmg/ZR4UapabnV3bL298mRA5n1MvBtk7BGoBQm0tzk17AxUVFWYtSGuOa7lixq8JUHu6Nvs4tVU6zI770aaxWoPdR+zAzb/NEBERWYM9SvH2cEskdiIiIluTymNbHSNKIiIiMgtH7EREJAmihc9jFx3keexM7EREJAksxRMREZHD4YidiIgk4a+PXm1uf0fAxE5ERJKgt/Dpbpb0bUmOESURERGZhSN2IiKSBJbiiYiInIgAOQQLCtWW9G1JjhElERERmYUjdiIikgS9KIPegnK6JX1bEhM7ERFJAufYiYiInIho4dPdRN55joiIiFoaR+xERCQJesigt+BBLpb0bUlM7EREJAmCaNk8uSBaMRgbYimeiIjIiXDETkREkiBYuHjOkr4tiYmdiIgkQYAMggXz5Jb0bUmO8fWDiIiIzMIROxERSQLvPEdEROREpDLH7hhREhERkVk4YiciIkkQYOG94h1k8RwTOxERSYJo4ap4kYmdiIjo1iGVp7txjp2IiMiJcMRORESSIJVV8UzsREQkCSzFExERkcPhiJ2IiCRBKveKZ2InIiJJYCmeiIiIHA5H7EREJAlSGbEzsRMRkSRIJbGzFE9EROREOGInIiJJkMqInYmdiIgkQYRll6yJ1gvFppjYiYhIEqQyYuccOxERkRPhiJ2IiCRBKiN2JnYiIpIEqSR2luKJiIicCEfsREQkCVIZsTOxExGRJIiiDKIFydmSvi2JpXgiIiInwhE7ERFJAp/HTkRE5ESkMsfOUjwREZET4YidiIgkQSqL55jYiYhIEqRSimdiJyIiSZDKiJ1z7ERERE7EKUbsUR+fgItMae8wyMYuPdvN3iFQC/LoUGbvEKgF6GvqWuxcooWleEcZsTtFYiciIvonIgBRtKy/I2ApnoiIyIlwxE5ERJIgQAYZ7zxHRETkHLgqnoiIiBwOR+xERCQJgiiDjDeoISIicg6iaOGqeAdZFs9SPBERkRPhiJ2IiCRBKovnmNiJiEgSpJLYWYonIiJJuPZ0N0u25liyZAmioqKgVqsRFxeHgwcP3rR9eXk5xo0bh1atWkGlUqFTp07Yvn272efjiJ2IiMhG1q9fj5SUFCxbtgxxcXFYtGgRBg8ejOzsbAQHBzdqr9Vqcd999yE4OBgbNmxAeHg4zp07B19fX7PPycRORESSYI9V8QsXLsSYMWOQlJQEAFi2bBm2bduGlStXYsqUKY3ar1y5EqWlpdi/fz9cXV0BAFFRUU06J0vxREQkCQ2JXWbB1nAcjUZjtNXVmX5CnVarRUZGBhISEgz75HI5EhIScODAAZN9vvvuO8THx2PcuHEICQlBt27dMG/ePOj1erM/JxM7ERFRE0RGRsLHx8ewpaammmxXUlICvV6PkJAQo/0hISEoLCw02Sc3NxcbNmyAXq/H9u3bMX36dLz33nt46623zI6PpXgiIpIEa62KP3/+PLy9vQ37VSqVxbFdIwgCgoOD8emnn0KhUCA2NhYFBQVYsGABZs6cadYxmNiJiEgSRFj2TPVrfb29vY0S+40EBgZCoVCgqKjIaH9RURFCQ0NN9mnVqhVcXV2hUCgM+7p06YLCwkJotVoolcp/PC9L8URERDagVCoRGxuLtLQ0wz5BEJCWlob4+HiTffr06YOcnBwIgmDYd+rUKbRq1cqspA4wsRMRkURYtnCueWX8lJQULF++HJ9//jmysrLw0ksvobq62rBKfuTIkZg6daqh/UsvvYTS0lJMmDABp06dwrZt2zBv3jyMGzfO7HOyFE9ERNJgrVp8Ezz11FMoLi7GjBkzUFhYiJiYGOzYscOwoC4/Px9y+fUxdmRkJH744QdMnDgRt99+O8LDwzFhwgRMnjzZ7HMysRMRkTRYuHgOzeybnJyM5ORkk++lp6c32hcfH49ffvmlWecCWIonIiJyKhyxExGRJEjleexM7EREJAl8uhsRERE5HI7YiYhIGkRZsxfAGfo7ACZ2IiKSBKnMsbMUT0RE5EQ4YiciImmwww1q7IGJnYiIJEEqq+LNSuzfffed2Qd8+OGHmx0MERERWcasxD5s2DCzDiaTyaDX6y2Jh4iIyHYcpJxuCbMS+18fH0dEROSIpFKKt2hVfG1trbXiICIisi3RCpsDaHJi1+v1mDNnDsLDw+Hp6Ync3FwAwPTp0/HZZ59ZPUAiIiIyX5MT+9y5c7F69WrMnz8fSqXSsL9bt25YsWKFVYMjIiKyHpkVtltfkxP7mjVr8Omnn2LEiBFQKBSG/T169MDJkyetGhwREZHVsBRvWkFBATp06NBovyAI0Ol0VgmKiIiImqfJib1r167Yu3dvo/0bNmxAz549rRIUERGR1UlkxN7kO8/NmDEDiYmJKCgogCAI+Oabb5CdnY01a9Zg69attoiRiIjIchJ5uluTR+xDhw7Fli1b8OOPP8LDwwMzZsxAVlYWtmzZgvvuu88WMRIREZGZmnWv+L59+2Lnzp3WjoWIiMhmpPLY1mY/BObQoUPIysoC0DDvHhsba7WgiIiIrI5PdzPtwoULGD58OH7++Wf4+voCAMrLy3H33Xfjq6++QkREhLVjJCIiIjM1eY599OjR0Ol0yMrKQmlpKUpLS5GVlQVBEDB69GhbxEhERGS5a4vnLNkcQJNH7Lt378b+/fsRHR1t2BcdHY0PP/wQffv2tWpwRERE1iITGzZL+juCJif2yMhIkzei0ev1CAsLs0pQREREVieROfYml+IXLFiA8ePH49ChQ4Z9hw4dwoQJE/Duu+9aNTgiIiJqGrNG7H5+fpDJrs8tVFdXIy4uDi4uDd3r6+vh4uKC559/HsOGDbNJoERERBaRyA1qzErsixYtsnEYRERENiaRUrxZiT0xMdHWcRAREZEVNPsGNQBQW1sLrVZrtM/b29uigIiIiGxCIiP2Ji+eq66uRnJyMoKDg+Hh4QE/Pz+jjYiI6JYkkae7NTmxv/7669i1axeWLl0KlUqFFStWYNasWQgLC8OaNWtsESMRERGZqcml+C1btmDNmjUYMGAAkpKS0LdvX3To0AFt2rTB2rVrMWLECFvESUREZBmJrIpv8oi9tLQU7dq1A9Awn15aWgoAuOeee7Bnzx7rRkdERGQl1+48Z8nmCJo8Ym/Xrh3y8vLQunVrdO7cGV9//TV69+6NLVu2GB4KQzf3r2cu4rEXLsAvUIu8k55Y+lZ7nDrmdcP29wwuxnMTziEkvBYXz7lh5bttcWiPv8m2yW+exoNPF+KTee3w7Zpww/5VaQcREl5n1HbVe1H47/JI63woMtuTsceRGJ+JAM8anCoKwDs/3IM/LoaYbPt/0bl4oc9hRPpXwEUuIL/UB1/82gPbjkWbbD/tgd14PPYEFvzvbqw72MOWH4PM4L69FB6bSiEvr4cuSoXKMaHQdXK7YXtZlR6ea4uh/kUDeaUAfbArNM+HQNvLEwDgsaEE6l8qobighaiSQRfthsrEYOjDVS31kcgBNHnEnpSUhKNHjwIApkyZgiVLlkCtVmPixIl47bXXmnSsPXv2YMiQIQgLC4NMJsPmzZubGo7D6fdAMcZMycW6Ja0x/tGeyM32wJwVx+HjrzXZvktPDSa/dxL/2xCK8Y/cgQM/BmD6RyfQpmN1o7bxCSWI7lGJkiKlyWN98UEbjLgnzrB99x/eArilDeqag1fv+xmf7O2FZ1Y8jlNFAfh4+Fb4udeYbF9Rq8KKn+9A4qpH8eTyJ/Ht0c54c8hPiG+X36jtwOhcdA8vwmWNh60/BplBvU8Dr5WXUfV0IEoWtkV9lBp+s/IhL6833UEnwv/NfCgua1H+egRKlrRDxdhQCAHXx1/KP2pQ84AfSudHoezN1oC+oY+sVmihT+XguHjOtIkTJ+Lll18GACQkJODkyZNYt24djhw5ggkTJjTpWNXV1ejRoweWLFnS1DAc1iOjCrDjv6HY+U0ozp/xwEczO6CuVo5BjxWZbD/0uQJk7PPHxpUROJ/rji8WR+HMCU8MGXHRqF1AcB1eeuMMFrwWDX296XmgmmoFykqUhq3uqsLqn49u7tm4o/jmSFd8d7Qzckv8MXd7f9TqXDEs5qTJ9hnnwvFTdjvkXfHDhTIffPnb7ThdFICekYVG7YK8qjB58D78e3MC6oUm/1qTDbh/ewU1g3xx9V5f6CNV0LwUClElh1taucn2bmnlkFXqUT41Erou7tCHKKHr5oH6tmpDm7KZrXH1Xl/Ut1ahvq0aFS+HQVFcD5cztS30qcgRWHQdOwC0adMGbdq0aVbfBx54AA888IClITgMF1cBHW6rxNefXn9mvSjKkHnAF51jNCb7dI6pxKbV4Ub7Mn72Q/y9VwyvZTIRk+ZnY+NnEcjPufFo7Ykx5zF8bD6KL6qQvjUYmz4Ph6B3jMUgzsBFrkeXVsVY+fMdhn0iZPj1bDhuDzf9xc6YiN5RBYgKKMcHu+4y7JVBxFtD0/D5gRjklpieoqEWphPheqYW1Y8FXt8nl0HbwwOu2VdNdlEfrISusxu8PymE6mAlBB8X1Pb1RvWjAYDC9O+pvKZhpC568sucOWSw8OluVovEtsxK7IsXLzb7gNdG87ZQV1eHurrr88QajelkeKvy9tNB4QKUXTEulZeXKBHZ1vQvu1+gFuVXXP/W3hV+gddL90+MuQC9XoZvv7hxaf27L8KQc8ITleWu6NpTg8SUs/AP1mL52+0s+ETUFH7utXCRiyitNp5jvVLljqiA8hv281TV4YcJa+CqECCIMqR+3xe/5l1fG5F09xHoBTm+/K27rUKnJpJX1kMmAIKvcVVM76OA8kKdyT6KIh2Ux2pwtZ83yqZHwqVQB+9PCgG9iOqngxp3EER4fVYEbRc31LdRN36fJMusxP7++++bdTCZTGbTxJ6amopZs2bZ7PiOqMNtlXj4uQK8/FhP3Oz75KbV16sEZ095QKeTYfysHKx6Lwr1On7bv5VV1ynx9PIn4abUIS7qAl69bz8ulHsj41w4uoQWY3jv3/HMiifgOOMJMkkEBB8FNGNbAQoZ6ju4QX5FB4/NV0wmdu9PC+F6rg5XUptXMZUkiVzuZlZiz8vLs3UcZpk6dSpSUlIMrzUaDSIjHWdVt6bMFfp6wC/AeKGcb6AWpSWuJvuUlSjhG6D7W3sdykoaRv23xWrgG6DD57sOGt5XuACjJ+diWGIBku7tbfK42b97wcVVREhELQry3C35WGSmsho16gUZ/D2MqzMBnjW4UnXjn4EIGc6X+QAAThUFom1gGZ6/+wgyzoWjZ+uL8Pe4iu0vf2Fo7yIXkZJwACN6H8NDHz1rmw9DNyV4uUCUA/JyvdF+RYUegp/pP7uCnwtEBYzK7vURKijK9IBOBFyv7/f6tBCq36pQOq8NhEDTfzvIBIncUtbiOfaWpFKpoFI57mUd9To5cv7wQo/4chxIa5h7k8lExNxVji1rTZfRT2Z6ISa+3OjStZ53l+FkZsPlcbu+C0bmAV+jPnNWHMeub4Oxc5PpS6gAoF3nauj1QMUV/lFoKfWCAlmXghDX9gLST7UF0DA/3juqAOsPdTP7ODIZoHRpSBjbjkXj17wIo/c/Hr4N2451wrdHTV8SRy3AVQZdezWUv1ej7q4/L2UVRCh/r0bNg6Zvva3t7Aa3PRpAEAF5QxJ3uaiF3s/lelIXRXgtL4L6l0qUvtUG+hDTV8CQtDlUYncGm1aHI+XtbJw+7oVTv3thaGIBVG4Cdn7TkIRffTsbVy4rsXphwx/+b78IxztrfscjSRfwW7o/+j9UjI63VeHDGR0BAJXlrqgsN07O+noZykqUhpF45xgNom+vxO+/+uBqtQKdYyrx4tRc/LQlGFUaJvaW9J9fe2D2w7tw4lIQjheE4Jm43+HmqsO3RzsDAOY8nIbLlR748KeGxXHP330Yf1wKwoUyHygVetzT4Rwe6n4Kqd/3BQBUXFWj4qrx/Gq9IEdJtRvOlfLZDfZUMzQAPh9chK6DGrqObvDYUgpZrYCr9/oCAHwWXYQ+wAVVzwU3tL/fD+7by+C1ogg1D/nB5ZIWHhtKUPOv6wsivT8phHqPBmX/joDoJoe8rOHSOcFdDqg4pfaPOGK3vaqqKuTk5Bhe5+XlITMzE/7+/mjdurUdI7OdPd8Hwdtfh+fGn4NfkBa5WZ6YMeY2lP+5oC4orA7CX/7jyTrijfmTojHylXMYNfEsCs66YU5yV5w7bf61yjqtHP0fLMaI5HNwVYoouqDC5s/D8c2q8H/uTFb1vxMd4Od+FS/1/w0BHjXILgrEuC//hdLqhi9hoT5VEP4yj6dW6vDvB/Yi2KsKdfUuOFviize+vRf/O9HBXh+BzFR7jzfkFfXw+rIY8jI9dG1VKJvZGoJvw59dRbHOaFmEEOSKspmR8FpZhMBXyqH3d0HNv/wbVsX/yX1HOQAg4A3j+xhUjG9l+MJAN2bp3eMc5c5zMlEU7RZqeno6Bg4c2Gh/YmIiVq9e/Y/9NRoNfHx8cK/3s3CRsSTl7C49a365mhyfMKjM3iFQC9DX1CFr+HxUVFTY7LHf13JF1Ny5kKubfwWBUFuLs9Om2TRWa7DriH3AgAGw4/cKIiKSEomU4ps1KbN37148++yziI+PR0FBAQDgiy++wL59+6waHBERkdXwlrKmbdy4EYMHD4abmxuOHDliuGFMRUUF5s2bZ/UAiYiIyHxNTuxvvfUWli1bhuXLl8PV9fqK6j59+uDw4cNWDY6IiMha+NjWG8jOzka/fv0a7ffx8UF5ebk1YiIiIrI+idx5rskj9tDQUKNL1K7Zt28f2rXjfceJiOgWxTl208aMGYMJEybg119/hUwmw8WLF7F27VpMmjQJL730ki1iJCIiIjM1uRQ/ZcoUCIKAe++9FzU1NejXrx9UKhUmTZqE8ePH2yJGIiIii0nlBjVNTuwymQzTpk3Da6+9hpycHFRVVaFr167w9PS0RXxERETWIZHr2Jt9gxqlUomuXbtaMxYiIiKyUJMT+8CBAyGT3Xhl4K5duywKiIiIyCYsvWTNWUfsMTExRq91Oh0yMzNx/PhxJCYmWisuIiIi62Ip3rT333/f5P4333wTVVVVFgdEREREzWe1B/g+++yzWLlypbUOR0REZF0SuY7dak93O3DgANQWPA6PiIjIlni52w08+uijRq9FUcSlS5dw6NAhTJ8+3WqBERERUdM1ObH7+PgYvZbL5YiOjsbs2bMxaNAgqwVGRERETdekxK7X65GUlITu3bvDz8/PVjERERFZn0RWxTdp8ZxCocCgQYP4FDciInI4Unlsa5NXxXfr1g25ubm2iIWIiIgs1OTE/tZbb2HSpEnYunUrLl26BI1GY7QRERHdspz8UjegCXPss2fPxquvvooHH3wQAPDwww8b3VpWFEXIZDLo9XrrR0lERGQpzrEbmzVrFqqrq/HTTz8Ztl27dhm2a6+JiIjouiVLliAqKgpqtRpxcXE4ePCgWf2++uoryGQyDBs2rEnnM3vELooNX1X69+/fpBMQERHdCuxxg5r169cjJSUFy5YtQ1xcHBYtWoTBgwcjOzsbwcHBN+x39uxZTJo0CX379m3yOZs0x36zp7oRERHd0qx0S9m/ry2rq6u74SkXLlyIMWPGICkpCV27dsWyZcvg7u5+01uw6/V6jBgxArNmzUK7du2a/DGblNg7deoEf3//m25ERETOLDIyEj4+PoYtNTXVZDutVouMjAwkJCQY9snlciQkJODAgQM3PP7s2bMRHByMF154oVnxNekGNbNmzWp05zkiIiJHYK1S/Pnz5+Ht7W3Yr1KpTLYvKSmBXq9HSEiI0f6QkBCcPHnSZJ99+/bhs88+Q2ZmZrPjbFJif/rpp286J0BERHTLstKqeG9vb6PEbi2VlZV47rnnsHz5cgQGBjb7OGYnds6vExERmS8wMBAKhQJFRUVG+4uKihAaGtqo/ZkzZ3D27FkMGTLEsE8QBACAi4sLsrOz0b59+388r9lz7NdWxRMRETmkFn4eu1KpRGxsLNLS0gz7BEFAWloa4uPjG7Xv3Lkzjh07hszMTMP28MMPY+DAgcjMzERkZKRZ5zV7xH7tWwMREZEjssflbikpKUhMTESvXr3Qu3dvLFq0CNXV1UhKSgIAjBw5EuHh4UhNTYVarUa3bt2M+vv6+gJAo/030+THthIRETkkO9x57qmnnkJxcTFmzJiBwsJCxMTEYMeOHYYFdfn5+ZDLm3x395tiYiciIrKh5ORkJCcnm3wvPT39pn1Xr17d5PMxsRMRkTRI5F7xTOxERCQJ9phjtwfrFvaJiIjIrjhiJyIiaWApnoiIyHmwFE9EREQOhyN2IiKSBpbiiYiInIhEEjtL8URERE6EI3YiIpIE2Z+bJf0dARM7ERFJg0RK8UzsREQkCbzcjYiIiBwOR+xERCQNLMUTERE5GQdJzpZgKZ6IiMiJcMRORESSIJXFc0zsREQkDRKZY2cpnoiIyIlwxE5ERJLAUjwREZEzYSmeiIiIHI1TjNj1mkrIZK72DoNsLPTzo/YOgVrQ92/8bO8QqAVoKgX4tdC5WIonIiJyJhIpxTOxExGRNEgksXOOnYiIyIlwxE5ERJLAOXYiIiJnwlI8ERERORqO2ImISBJkogiZ2PxhtyV9WxITOxERSQNL8URERORoOGInIiJJ4Kp4IiIiZ8JSPBERETkajtiJiEgSWIonIiJyJhIpxTOxExGRJEhlxM45diIiIifCETsREUkDS/FERETOxVHK6ZZgKZ6IiMiJcMRORETSIIoNmyX9HQATOxERSQJXxRMREZHD4YidiIikgaviiYiInIdMaNgs6e8IWIonIiJyIhyxExGRNLAUT0RE5DyksiqeiZ2IiKRBItexc46diIjIiXDETkREksBSPBERkTORyOI5luKJiIicCEfsREQkCSzFExEROROuiiciIiJHwxE7ERFJAkvxREREzoSr4omIiMjRcMRORESSwFI8ERGRMxHEhs2S/g6AiZ2IiKSBc+xERETkaDhiJyIiSZDBwjl2q0ViW0zsREQkDbzzHBEREVlqyZIliIqKglqtRlxcHA4ePHjDtsuXL0ffvn3h5+cHPz8/JCQk3LS9KUzsREQkCdcud7Nka6r169cjJSUFM2fOxOHDh9GjRw8MHjwYly9fNtk+PT0dw4cPx08//YQDBw4gMjISgwYNQkFBgdnnZGInIiJpEK2wNdHChQsxZswYJCUloWvXrli2bBnc3d2xcuVKk+3Xrl2LsWPHIiYmBp07d8aKFSsgCALS0tLMPicTOxERURNoNBqjra6uzmQ7rVaLjIwMJCQkGPbJ5XIkJCTgwIEDZp2rpqYGOp0O/v7+ZsfHxE5ERJIgE0WLNwCIjIyEj4+PYUtNTTV5vpKSEuj1eoSEhBjtDwkJQWFhoVkxT548GWFhYUZfDv4JV8UTEZE0CH9ulvQHcP78eXh7ext2q1Qqi8K6kbfffhtfffUV0tPToVarze7HxE5ERNQE3t7eRon9RgIDA6FQKFBUVGS0v6ioCKGhoTft++677+Ltt9/Gjz/+iNtvv71J8bEUT0REkmCtUry5lEolYmNjjRa+XVsIFx8ff8N+8+fPx5w5c7Bjxw706tWryZ+TI3YiIpIGO9wrPiUlBYmJiejVqxd69+6NRYsWobq6GklJSQCAkSNHIjw83DBP/84772DGjBlYt24doqKiDHPxnp6e8PT0NOucTOxERCQNdrjz3FNPPYXi4mLMmDEDhYWFiImJwY4dOwwL6vLz8yGXXy+eL126FFqtFo8//rjRcWbOnIk333zTrHMysRMREdlQcnIykpOTTb6Xnp5u9Prs2bMWn4+JnYiIJKG5d4/7a39HwMRuB0NGleDxly7DP6geuSfc8PEb4cjOdL9h+77/Kkfi64UIidCiIE+Fz+a2wm+7/roiU8TI14pw/zNX4Omtx4lDHlg8JQIX865fghHerg5jpl9E1zur4eIqIi9LjTXzW+HofvPmbMh6/jXiEh4ffRF+QVrknvTA0tltcep3rxu2v+f+Eox85TxCImpRcNYNqxa0wW+7/Uy2TZ59Bg8NL8Inc6OweXWYrT4Cmem7VYHYsDQYpcUuaNf1Ksa+VYDOPWtMtq3XAV99GIIf/+uPkkJXRLSvwwvTLuLOgZWGNl+8G4r/LDReTR3Rvhaf7T1p08/hNPgQGLKF/g+X4cWZF7F2YSjGDe6E3BNqzF2XC58Ancn2XXtVY+rH57DjS3+MHdQJ+3d4Y+bKs2gTfdXQ5slxxRj6fDE+nBKBCf/qiNoaOeaty4Wr6voFm7M/z4VcIWLyE+2RfH8n5J5ww+w1efALMn1eso1+D5bgxX+fxdqPIjB+WA/kZXngrZUn4OOvNdm+S08Nprx/Cj9sCEby0B448KM/pn98Em06Vjdqe/d9V9A5phIlhUpbfwwyQ/q3vvh0VhhGpBRiyQ/ZaNf1KqY90w7lJabHU6vfaYXt/wnA2LcuYHn6STz0XAlmv9AWOcfcjNq1ib6KLzOPG7aFm0+3xMchB2LXxJ6amoo777wTXl5eCA4OxrBhw5CdnW3PkGzu0RdLsGOdP/633h/5p9VYPDkCdVdlGDy81GT7YaOLcegnL2xYGozzOWqsWdAKOcfcMDTpyp8tRAwbXYwvPwjBgR98kJflhvkvt0ZAiA53318BAPD2r0dEey2+/igYeVluuJinwsq5raB2FxDVubaFPjkBwCPPX8T360Owc2MI8nPc8eGMdqi7qsCgx00/EGJo4iUc2uuHjSvCcf6MO75Y1BpnTnhgyHPGd60KCKnDSzPyMD+lE/T1jvLUaOf2zadBuP+ZKxj8dCnadKrDy+9cgMpNwA9fmr41aNpGfzw9/jJ631uJVm20GJJ4BXf+nwYbPwkyaqdQAP7B9YbNJ0DfEh/HKcgEyzdHYNfEvnv3bowbNw6//PILdu7cCZ1Oh0GDBqG6uvFoxBm4uAroeHsNDu+9XnYVRRmO7PVC11jT5bkusTU4ste4TJux2wtdYhv+jUJbaxEQUm90zJpKBU4ecUeXP4+pKVXgfI4KCU+UQeWmh1wh4qHnrqCs2AWnfzceDZDtuLgK6HhbFTL3+xj2iaIMmft90KVnpck+XXpWGrUHgIy9vugSc729TCZi0oLT2LAiDPk5N57SoZaj08pw+nd33NG3yrBPLgd69q3CiQyPG/ZRqowzh0ot4I+DxtNlBXlKDO95GxLv6oK3x7XG5Quu1v8AzupaKd6SzQHYdY59x44dRq9Xr16N4OBgZGRkoF+/fo3a19XVGd1sX6PR2DxGa/L210PhApQXG/+zl5W4ILKD6YcI+AXVo+xvpbuyYhf4BdcDaPjmDjQ+ZnmxC/yDr5XZZZjyVDvMXHkWm08fhygA5SUumDaiLaoquMyipXj71UPhApSVGJfKy664IqL9VZN9/AJ1KCsx/sNdVuJqNIXyxIsFEPQyfPt5K+sHTc2iKVVA0Mvg+7epLr9AHc7nmL79aGz/Smz8NAjd76pCqygtjuz1xM/bfSH8Jdd3vqMakxZdRUT7OpRedsV/3gvFq490xCc/nYS7p4MMJ8nmbqk59oqKhtLxjZ5ik5qaanTj/cjIyJYMz4GJSJ5XgPISF7z6SAe8/FBH7N/hg1mrz/4l+ZMj6nBbFYYmXsJ7kzsCYAnekb005wLC22oxul8XPNSmBz6eFoFBT12B7C9/pe/8v0r0G1KBdl1r0WtAJd76Ty6qNArs+c7XbnE7FDs8ttUebpnhmiAIeOWVV9CnTx9069bNZJupU6ciJSXF8Fqj0ThUcteUKqCvB3yD6o32+wXWo6zY9I+irNgFfoF/ax9Uj7LLDe1L//xf36B6lF6+PrLzDarHmT8ayuwx91Shd4IGj3fphpoqBQDgo2PuuKNfFhKeLMXXHxk/eYhsQ1PmAn094BdovFDOL0CHsmLT5dSyElf4BTYe9V1r3+1ODXwDdFiz+5DhfYULMHrKWQxLvIRRA2Ot/CnIHN7+DVNe5cWmqi31Jvv4Bujx5qo8aGtl0JS5ICBUh8/mtkJoa9PVPADw9NEjol0dLp61zUNInE1zbgv79/6O4JYZsY8bNw7Hjx/HV199dcM2KpXKcPN9c2/Cfyup18lx+nd39LzHeH405p4qnMgwPTealeGOmL/M0wHAHf0qkfXnPF1hvhJXilyMjunuqUfnnjXI+vOYKreGEp3wt0qdIMog5yCvxdTr5Dj9hydi4isM+2QyETF3VyDriOnL3bKOeBm1B4CefSqQldnQPm1zEMb+qwfGPXx9KylUYuOKcEx7vqvtPgzdlKtSRMfba3Bk3/X5cUEAMvd5omvszdcQKdUiAlvpoK8H9m33RfzgG085Xq2W4+I5JStvZOSWGLEnJydj69at2LNnDyIiIuwdjk1982kgJi06j1NH3ZF9xB2PjCmG2l3A/75qmH547YN8lBS6YlVqw3zp5hVBWLAxB4/9f5dxMM0b/YeWo+PtV7HotWv/TjJsXhGE4RMuoyBPhcJ8JRJfL8SVIlfs39Gw6CorwwNVFQq89sF5rH0/BHW1cjww4gpCI7U4mOZYX44c3aaVYXh1/mmcPu6J7N89MWzUJajc9Ni5MRgA8Or807hSpMTq99oAAL79vBXmr/0Djz5fgIPpfuj/UAk6dqvC4jfaAQAqy11RWW48KtTXy1BW4oqCPC6MtKdHXyzGu6+0RqceNYjuWYNNy4NQWyPHoKcbroCZ/3JrBIbq8Py/LwEATh52R0mhK9rfdhUlhQ3z56IAPDn2+hUTn84Kw12DKhAcocOVQhd88W4rKOTAgEfK7PIZHY5ErmO3a2IXRRHjx4/Hpk2bkJ6ejrZt29oznBax+zs/+AToMfK1QvgF1SP3DzdMG9EW5X8ukAoK1xqNrE8c8sDb49ogcXIhRk0pxMU8FWY9H4Vz2df/aH+9JAhqdwET5l+Ap7cef/zmgWkj2kFX11CQ0ZS6YNoz7TBqyiW88/UZKFxFnMtW482kKOSe4B//lrRneyB8/HV4dkI+/IN0OJPlgekvdEX5lYYFdcFhdUZ/O7KOeOOdlI5InJiPUa/mo+CsGnPGdsa506ZXVtOtY8DQclRcccGaBa1QVuyCdrddxdy1uYZSfHGBEn+5RTi0dTJ8/k4rXMpXws1dwJ33avD64nPw9Ll+OVvJJVekjo1CZZkCPgH1uO3Oaizaegq+vOTNPCIsex67Y+R1yETRfl9Bxo4di3Xr1uHbb79FdHS0Yb+Pjw/c3P454Wg0Gvj4+GAAhsJFxks+nJ3cg8lMSr4//bO9Q6AWoKkU4NcpFxUVFTabXr2WK/6v5xS4KNTNPk69vha7jrxt01itwa5z7EuXLkVFRQUGDBiAVq1aGbb169fbMywiIiKHZfdSPBERUYsQYeEcu9UisalbYvEcERGRzUlk8dwtc7kbERERWY4jdiIikgYBlt2g0UHu2svETkREksA7zxEREZHD4YidiIikQSKL55jYiYhIGiSS2FmKJyIiciIcsRMRkTRIZMTOxE5ERNLAy92IiIicBy93IyIiIofDETsREUkD59iJiIiciCACMguSs+AYiZ2leCIiIifCETsREUkDS/FERETOxMLEDsdI7CzFExERORGO2ImISBpYiiciInIiggiLyulcFU9EREQtjSN2IiKSBlFo2Czp7wCY2ImISBo4x05EROREOMdOREREjoYjdiIikgaW4omIiJyICAsTu9UisSmW4omIiJwIR+xERCQNLMUTERE5EUEAYMG16IJjXMfOUjwREZET4YidiIikgaV4IiIiJyKRxM5SPBERkRPhiJ2IiKRBIreUZWInIiJJEEUBogVPaLOkb0tiYiciImkQRctG3ZxjJyIiopbGETsREUmDaOEcu4OM2JnYiYhIGgQBkFkwT+4gc+wsxRMRETkRjtiJiEgaWIonIiJyHqIgQLSgFO8ol7uxFE9EROREOGInIiJpYCmeiIjIiQgiIHP+xM5SPBERkRPhiJ2IiKRBFAFYch27Y4zYmdiJiEgSREGEaEEpXmRiJyIiuoWIAiwbsfNyNyIiImphHLETEZEksBRPRETkTCRSinfoxH7t21M9dBbdc4Acg1zU2jsEakGaSsf4I0qW0VQ1/JxbYjRsaa6oh856wdiQQyf2yspKAMA+bLdzJNQiqu0dALUkv072joBaUmVlJXx8fGxybKVSidDQUOwrtDxXhIaGQqlUWiEq25GJjjJpYIIgCLh48SK8vLwgk8nsHU6L0Wg0iIyMxPnz5+Ht7W3vcMiG+LOWDqn+rEVRRGVlJcLCwiCX2249d21tLbRay6t+SqUSarXaChHZjkOP2OVyOSIiIuwdht14e3tL6g+AlPFnLR1S/FnbaqT+V2q1+pZPyNbCy92IiIicCBM7ERGRE2Fid0AqlQozZ86ESqWydyhkY/xZSwd/1mQtDr14joiIiIxxxE5EROREmNiJiIicCBM7ERGRE2FiJyIiciJM7A5myZIliIqKglqtRlxcHA4ePGjvkMgG9uzZgyFDhiAsLAwymQybN2+2d0hkI6mpqbjzzjvh5eWF4OBgDBs2DNnZ2fYOixwYE7sDWb9+PVJSUjBz5kwcPnwYPXr0wODBg3H58mV7h0ZWVl1djR49emDJkiX2DoVsbPfu3Rg3bhx++eUX7Ny5EzqdDoMGDUJ1NR+OQM3Dy90cSFxcHO6880589NFHABrulR8ZGYnx48djypQpdo6ObEUmk2HTpk0YNmyYvUOhFlBcXIzg4GDs3r0b/fr1s3c45IA4YncQWq0WGRkZSEhIMOyTy+VISEjAgQMH7BgZEVlTRUUFAMDf39/OkZCjYmJ3ECUlJdDr9QgJCTHaHxISgsLCQjtFRUTWJAgCXnnlFfTp0wfdunWzdzjkoBz66W5ERM5k3LhxOH78OPbt22fvUMiBMbE7iMDAQCgUChQVFRntLyoqQmhoqJ2iIiJrSU5OxtatW7Fnzx5JP46aLMdSvINQKpWIjY1FWlqaYZ8gCEhLS0N8fLwdIyMiS4iiiOTkZGzatAm7du1C27Zt7R0SOTiO2B1ISkoKEhMT0atXL/Tu3RuLFi1CdXU1kpKS7B0aWVlVVRVycnIMr/Py8pCZmQl/f3+0bt3ajpGRtY0bNw7r1q3Dt99+Cy8vL8OaGR8fH7i5udk5OnJEvNzNwXz00UdYsGABCgsLERMTg8WLFyMuLs7eYZGVpaenY+DAgY32JyYmYvXq1S0fENmMTCYzuX/VqlUYNWpUywZDToGJnYiIyIlwjp2IiMiJMLETERE5ESZ2IiIiJ8LETkRE5ESY2ImIiJwIEzsREZETYWInIiJyIkzsREREToSJnchCo0aNwrBhwwyvBwwYgFdeeaXF40hPT4dMJkN5efkN28hkMmzevNnsY7755puIiYmxKK6zZ89CJpMhMzPTouMQkXmY2MkpjRo1CjKZDDKZDEqlEh06dMDs2bNRX19v83N/8803mDNnjlltzUnGRERNwYfAkNO6//77sWrVKtTV1WH79u0YN24cXF1dMXXq1EZttVotlEqlVc7r7+9vleMQETUHR+zktFQqFUJDQ9GmTRu89NJLSEhIwHfffQfgevl87ty5CAsLQ3R0NADg/PnzePLJJ+Hr6wt/f38MHToUZ8+eNRxTr9cjJSUFvr6+CAgIwOuvv46/P27h76X4uro6TJ48GZGRkVCpVOjQoQM+++wznD171vCgFz8/P8hkMsNDPwRBQGpqKtq2bQs3Nzf06NEDGzZsMDrP9u3b0alTJ7i5uWHgwIFGcZpr8uTJ6NSpE9zd3dGuXTtMnz4dOp2uUbtPPvkEkZGRcHd3x5NPPomKigqj91esWIEuXbpArVajc+fO+Pjjj5scCxFZBxM7SYabmxu0Wq3hdVpaGrKzs7Fz505s3boVOp0OgwcPhpeXF/bu3Yuff/4Znp6euP/++w393nvvPaxevRorV67Evn37UFpaik2bNt30vCNHjsSXX36JxYsXIysrC5988gk8PT0RGRmJjRs3AgCys7Nx6dIlfPDBBwCA1NRUrFmzBsuWLcMff/yBiRMn4tlnn8Xu3bsBNHwBefTRRzFkyBBkZmZi9OjRmDJlSpP/Tby8vLB69WqcOHECH3zwAZYvX47333/fqE1OTg6+/vprbNmyBTt27MCRI0cwduxYw/tr167FjBkzMHfuXGRlZWHevHmYPn06Pv/88ybHQ0RWIBI5ocTERHHo0KGiKIqiIAjizp07RZVKJU6aNMnwfkhIiFhXV2fo88UXX4jR0dGiIAiGfXV1daKbm5v4ww8/iKIoiq1atRLnz59veF+n04kRERGGc4miKPbv31+cMGGCKIqimJ2dLQIQd+7caTLOn376SQQglpWVGfbV1taK7u7u4v79+43avvDCC+Lw4cNFURTFqVOnil27djV6f/LkyY2O9XcAxE2bNt3w/QULFoixsbGG1zNnzhQVCoV44cIFw77vv/9elMvl4qVLl0RRFMX27duL69atMzrOnDlzxPj4eFEURTEvL08EIB45cuSG5yUi6+EcOzmtrVu3wtPTEzqdDoIg4JlnnsGbb75peL979+5G8+pHjx5FTk4OvLy8jI5TW1uLM2fOoKKiApcuXUJcXJzhPRcXF/Tq1atROf6azMxMKBQK9O/f3+y4c3JyUFNTg/vuu89ov1arRc+ePQEAWVlZRnEAQHx8vNnnuGb9+vVYvHgxzpw5g6qqKtTX18Pb29uoTevWrREeHm50HkEQkJ2dDS8vL5w5cwYvvPACxowZY2hTX18PHx+fJsdDRJZjYienNXDgQCxduhRKpRJhYWFwcTH+z93Dw8PodVVVFWJjY7F27dpGxwoKCmpWDG5ubk3uU1VVBQDYtm2bUUIFGtYNWMuBAwcwYsQIzJo1C4MHD4aPjw+++uorvPfee02Odfny5Y2+aCgUCqvFSkTmY2Inp+Xh4YEOHTqY3f6OO+7A+vXrERwc3GjUek2rVq3w66+/ol+/fgAaRqYZGRm44447TLbv3r07BEHA7t27kZCQ0Oj9axUDvV5v2Ne1a1eoVCrk5+ffcKTfpUsXw0LAa3755Zd//pB/sX//frRp0wbTpk0z7Dt37lyjdvn5+bh48SLCwsIM55HL5YiOjkZISAjCwsKQm5uLESNGNOn8RGQbXDxH9KcRI0YgMDAQQ4cOxd69e5GXl4f09HS8/PLLuHDhAgBgwoQJePvtt7F582acPHkSY8eOvek16FFRUUhMTMTzzz+PzZs3G4759ddfAwDatGkDmUyGrVu3ori4GFVVVfDy8sKkSZMwceJEfP755zhz5gwOHz6MDz/80LAg7f/9v/+H06dP47XXXkN2djbWrVuH1atXN+nzduzYEfn5+fjqq69w5swZLF682ORCQLVajcTERBw9ehR79+7Fyy+/jCeffBKhoaEAgFmzZiE1NRWLFy/GqVOncOzYMaxatQoLFy5sUjxEZB1M7ER/cnd3x549e9C6dWs8+uij6NKlC1544QXU1tYaRvCvvvoqnnvuOSQmJiI+Ph5eXl545JFHbnrcpUuX4vHHH8fYsWPRuXNnjBkzBtXV1QCA8PBwzJo1C1OmTEFISAiSk5MBAHPmzMH06dORmpqKLl264P7778e2bdvQtm1bAA3z3hs3bsTmzZvRo0cPLFu2DPPmzWvS53344YcxceJEJCcnIyYmBvv378f06dMbtevQoQMeffRRPPjggxg0aBBuv/12o8vZRo8ejRUrVmDVqlXo3r07+vfvj9WrVxtiJaKWJRNvtOqHiIiIHA5H7ERERE6EiZ2IiMiJMLETERE5ESZ2IiIiJ8LETkRE5ESY2ImIiJwIEzsREZETYWInIiJyIkzsREREToSJnYiIyIkwsRMRETmR/x+UzxiNdJAyjwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7dc82b0>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7fc5850>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7fa8130>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    # Compute predictions for the current fold, summing up the counts across the rows of the matrices for each true label\n",
    "    ConfusionMatrixDisplay(\n",
    "        confusion_matrix(\n",
    "            y_true=oof[f\"fold_{fold + 1}\"][\"target\"],\n",
    "            y_pred=np.argmax(oof[f\"fold_{fold + 1}\"][\"prediction\"], axis=1),\n",
    "            labels=[0, 1, 2],\n",
    "            normalize=\"true\",\n",
    "        )\n",
    "    ).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nature of the problem, we would likely wish to focus on the top row. Specifically, we would want to maximize the top left corner, which corresponds to cases where the model correctly classified patient as a member of the '<30' group, i.e., the patient was readmitted into the hospital within 30 days. This is because the cost of miss-classifying a patient who is a high-risk in terms of within 30-day readmission is very high. \n",
    "\n",
    "* Even though our model out performs the random guessing model. It still remains suboptimal in terms of our objective--- maximizing the classifier's ability to correctly identify patients who are high-risk of readmission. \n",
    "\n",
    "* For the first fold, the classifier correctly classified class 0 ('<30') patients $43\\%$ of the time; however, its false negative rate is $57\\%$, which is still too costly. This performance in terms correctly classifying the with-30 group is consistent across all folds.\n",
    "\n",
    "* The most significant improvements of the model's performance on correctly classifiying the within-30 group comes from using sample weights (not resampling techniques such as SMOTE).\n",
    "\n",
    "* In maximizing the model's ability to correctly classify the within-30 group (class 0), we have lost some accuracy in predicting the above 30 group. Therefore, there is some trade-off between the two minority groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the feature importance for each fold\n",
    "for i in range(5):\n",
    "    feat_imp_list[i].sort_values(by=f\"importance_{i + 1}\", ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "      <th>importance_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insulin</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number_inpatient</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_outpatient_mean_by_patient_nbr</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>number_inpatient_mean_by_patient_nbr</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number_diagnoses_mean_by_patient_nbr</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>number_diagnoses_sum_by_patient_nbr</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_in_hospital_sum_by_patient_nbr</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_procedures_mean_by_patient_nbr</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_medications_median_by_patient_nbr</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>payer_code</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_medications_max_by_patient_nbr</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time_in_hospital</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>time_in_hospital_mean_by_patient_nbr</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>discharge_disposition_id</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num_lab_procedures_median_by_patient_nbr</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_medications_mean_by_patient_nbr</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_medications_sum_by_patient_nbr</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_lab_procedures_max_by_patient_nbr</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num_lab_procedures_mean_by_patient_nbr</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num_lab_procedures_sum_by_patient_nbr</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>num_medications</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>num_lab_procedures</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>diag_2</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diag_3</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>diag_1</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  importance_1  importance_2  \\\n",
       "0                                    insulin       10659.0       10659.0   \n",
       "1                           number_inpatient       11069.0       11069.0   \n",
       "2      number_outpatient_mean_by_patient_nbr       12745.0       12745.0   \n",
       "3       number_inpatient_mean_by_patient_nbr       13279.0       13279.0   \n",
       "4       number_diagnoses_mean_by_patient_nbr       13486.0       13486.0   \n",
       "5        number_diagnoses_sum_by_patient_nbr       13947.0       13947.0   \n",
       "6        time_in_hospital_sum_by_patient_nbr       14133.0       14133.0   \n",
       "7         num_procedures_mean_by_patient_nbr       14440.0       14440.0   \n",
       "8      num_medications_median_by_patient_nbr       15062.0       15062.0   \n",
       "9                                 payer_code       15410.0       15410.0   \n",
       "10        num_medications_max_by_patient_nbr       15850.0       15850.0   \n",
       "11                          time_in_hospital       16160.0       16160.0   \n",
       "12      time_in_hospital_mean_by_patient_nbr       18697.0       18697.0   \n",
       "13                  discharge_disposition_id       19496.0       19496.0   \n",
       "14  num_lab_procedures_median_by_patient_nbr       19887.0       19887.0   \n",
       "15       num_medications_mean_by_patient_nbr       20726.0       20726.0   \n",
       "16        num_medications_sum_by_patient_nbr       21302.0       21302.0   \n",
       "17     num_lab_procedures_max_by_patient_nbr       21864.0       21864.0   \n",
       "18    num_lab_procedures_mean_by_patient_nbr       24422.0       24422.0   \n",
       "19     num_lab_procedures_sum_by_patient_nbr       24813.0       24813.0   \n",
       "20                           num_medications       25941.0       25941.0   \n",
       "21                        num_lab_procedures       33480.0       33480.0   \n",
       "22                                    diag_2       42860.0       42860.0   \n",
       "23                                    diag_3       43477.0       43477.0   \n",
       "24                                    diag_1       44406.0       44406.0   \n",
       "\n",
       "    importance_3  importance_4  importance_5  \n",
       "0        10659.0       10659.0       10659.0  \n",
       "1        11069.0       11069.0       11069.0  \n",
       "2        12745.0       12745.0       12745.0  \n",
       "3        13279.0       13279.0       13279.0  \n",
       "4        13486.0       13486.0       13486.0  \n",
       "5        13947.0       13947.0       13947.0  \n",
       "6        14133.0       14133.0       14133.0  \n",
       "7        14440.0       14440.0       14440.0  \n",
       "8        15062.0       15062.0       15062.0  \n",
       "9        15410.0       15410.0       15410.0  \n",
       "10       15850.0       15850.0       15850.0  \n",
       "11       16160.0       16160.0       16160.0  \n",
       "12       18697.0       18697.0       18697.0  \n",
       "13       19496.0       19496.0       19496.0  \n",
       "14       19887.0       19887.0       19887.0  \n",
       "15       20726.0       20726.0       20726.0  \n",
       "16       21302.0       21302.0       21302.0  \n",
       "17       21864.0       21864.0       21864.0  \n",
       "18       24422.0       24422.0       24422.0  \n",
       "19       24813.0       24813.0       24813.0  \n",
       "20       25941.0       25941.0       25941.0  \n",
       "21       33480.0       33480.0       33480.0  \n",
       "22       42860.0       42860.0       42860.0  \n",
       "23       43477.0       43477.0       43477.0  \n",
       "24       44406.0       44406.0       44406.0  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = reduce(\n",
    "    lambda x, y: pd.merge(\n",
    "        x.iloc[-top_num_features:], y.iloc[-top_num_features:], on=\"feature\", how=\"left\"\n",
    "    ),\n",
    "    feat_imp_list,\n",
    ")\n",
    "feat_imp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average importance across all five folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "      <th>importance_5</th>\n",
       "      <th>avg_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insulin</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>10659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number_inpatient</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "      <td>11069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_outpatient_mean_by_patient_nbr</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>12745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>number_inpatient_mean_by_patient_nbr</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>13279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number_diagnoses_mean_by_patient_nbr</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>13486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>number_diagnoses_sum_by_patient_nbr</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "      <td>13947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_in_hospital_sum_by_patient_nbr</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>14133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_procedures_mean_by_patient_nbr</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>14440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_medications_median_by_patient_nbr</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>15062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>payer_code</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "      <td>15410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_medications_max_by_patient_nbr</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>15850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time_in_hospital</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>16160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>time_in_hospital_mean_by_patient_nbr</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>18697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>discharge_disposition_id</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>19496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num_lab_procedures_median_by_patient_nbr</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "      <td>19887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_medications_mean_by_patient_nbr</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "      <td>20726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_medications_sum_by_patient_nbr</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "      <td>21302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_lab_procedures_max_by_patient_nbr</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "      <td>21864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num_lab_procedures_mean_by_patient_nbr</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "      <td>24422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num_lab_procedures_sum_by_patient_nbr</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>24813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>num_medications</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "      <td>25941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>num_lab_procedures</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "      <td>33480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>diag_2</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "      <td>42860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diag_3</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "      <td>43477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>diag_1</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>44406.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  importance_1  importance_2  \\\n",
       "0                                    insulin       10659.0       10659.0   \n",
       "1                           number_inpatient       11069.0       11069.0   \n",
       "2      number_outpatient_mean_by_patient_nbr       12745.0       12745.0   \n",
       "3       number_inpatient_mean_by_patient_nbr       13279.0       13279.0   \n",
       "4       number_diagnoses_mean_by_patient_nbr       13486.0       13486.0   \n",
       "5        number_diagnoses_sum_by_patient_nbr       13947.0       13947.0   \n",
       "6        time_in_hospital_sum_by_patient_nbr       14133.0       14133.0   \n",
       "7         num_procedures_mean_by_patient_nbr       14440.0       14440.0   \n",
       "8      num_medications_median_by_patient_nbr       15062.0       15062.0   \n",
       "9                                 payer_code       15410.0       15410.0   \n",
       "10        num_medications_max_by_patient_nbr       15850.0       15850.0   \n",
       "11                          time_in_hospital       16160.0       16160.0   \n",
       "12      time_in_hospital_mean_by_patient_nbr       18697.0       18697.0   \n",
       "13                  discharge_disposition_id       19496.0       19496.0   \n",
       "14  num_lab_procedures_median_by_patient_nbr       19887.0       19887.0   \n",
       "15       num_medications_mean_by_patient_nbr       20726.0       20726.0   \n",
       "16        num_medications_sum_by_patient_nbr       21302.0       21302.0   \n",
       "17     num_lab_procedures_max_by_patient_nbr       21864.0       21864.0   \n",
       "18    num_lab_procedures_mean_by_patient_nbr       24422.0       24422.0   \n",
       "19     num_lab_procedures_sum_by_patient_nbr       24813.0       24813.0   \n",
       "20                           num_medications       25941.0       25941.0   \n",
       "21                        num_lab_procedures       33480.0       33480.0   \n",
       "22                                    diag_2       42860.0       42860.0   \n",
       "23                                    diag_3       43477.0       43477.0   \n",
       "24                                    diag_1       44406.0       44406.0   \n",
       "\n",
       "    importance_3  importance_4  importance_5  avg_importance  \n",
       "0        10659.0       10659.0       10659.0         10659.0  \n",
       "1        11069.0       11069.0       11069.0         11069.0  \n",
       "2        12745.0       12745.0       12745.0         12745.0  \n",
       "3        13279.0       13279.0       13279.0         13279.0  \n",
       "4        13486.0       13486.0       13486.0         13486.0  \n",
       "5        13947.0       13947.0       13947.0         13947.0  \n",
       "6        14133.0       14133.0       14133.0         14133.0  \n",
       "7        14440.0       14440.0       14440.0         14440.0  \n",
       "8        15062.0       15062.0       15062.0         15062.0  \n",
       "9        15410.0       15410.0       15410.0         15410.0  \n",
       "10       15850.0       15850.0       15850.0         15850.0  \n",
       "11       16160.0       16160.0       16160.0         16160.0  \n",
       "12       18697.0       18697.0       18697.0         18697.0  \n",
       "13       19496.0       19496.0       19496.0         19496.0  \n",
       "14       19887.0       19887.0       19887.0         19887.0  \n",
       "15       20726.0       20726.0       20726.0         20726.0  \n",
       "16       21302.0       21302.0       21302.0         21302.0  \n",
       "17       21864.0       21864.0       21864.0         21864.0  \n",
       "18       24422.0       24422.0       24422.0         24422.0  \n",
       "19       24813.0       24813.0       24813.0         24813.0  \n",
       "20       25941.0       25941.0       25941.0         25941.0  \n",
       "21       33480.0       33480.0       33480.0         33480.0  \n",
       "22       42860.0       42860.0       42860.0         42860.0  \n",
       "23       43477.0       43477.0       43477.0         43477.0  \n",
       "24       44406.0       44406.0       44406.0         44406.0  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[\"avg_importance\"] = feat_imp.iloc[:, 1:].apply(lambda x: x.mean(), axis=1)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABfYAAAPeCAYAAABOUktMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVRV9f7/8ddBmQ+DBIEDiibghEhOqKXkhEOUmnNJmDlcRyqHr5XhLJmaY9eycsoyTTPTnHKqsAtoUpqziXiLNAdUtEDg/P7wx7keAQFT6ejzsdZZt733Z38+7z251n3vD+9tMJlMJgEAAAAAAAAAAKtgU9IBAAAAAAAAAACAoiOxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAAAAAACAFSGxDwAAAOC+kJWVpZEjR8rX11c2Njbq0KFDSYd0z0VFRcnPz6+kw8ADqKDnz2AwaOzYsfc8nvT0dL344ovy8fGRwWBQdHR0sfYvatxjx46VwWC4vSABAPgbSpd0AAAAAACK7p133tGgQYPUoEEDxcfHl3Q4/ygffvih3nrrLUVHR+vRRx9VxYoV78o4H3/8sc6cOVPsRCEKd+DAAa1YsYIXFFboXj1/RTV58mQtWrRIY8aM0SOPPKLq1auXaDwAANxpJPYBAAAAK7Js2TL5+fkpISFBx44dU9WqVUs6pH+Mbdu2qXz58nr77bfv6jgff/yx9u/f/49M7C9YsEA5OTklHcZtO3DggMaNG6ewsDAS+1amoOfvzz//VOnS9z71sG3bNoWGhiomJuaejw0AwL1AKR4AAADASpw4cUK7du3SjBkz5OXlpWXLlt3zGHJycvTXX3/d83GL4syZM3J3dy/pMG7b1atX/3Yftra2sre3vwPR3Ft//fWXVb+QKClXrlwp6RDMCnr+HBwcSiSxb+3/HgAAUBgS+wAAAICVWLZsmcqUKaP27durc+fOFon9a9euycPDQ717986z36VLl+Tg4KDhw4eb12VkZCgmJkZVq1aVvb29fH19NXLkSGVkZFjsazAYNHjwYC1btkw1a9aUvb29Nm7cKEmaNm2aGjdurIceekiOjo6qW7euPvvsszzj//nnnxo6dKg8PT3l4uKip556Sr/++mu+Nax//fVXvfDCC/L29pa9vb1q1qypDz/88JbnJTk5WQaDQdu3b9fPP/8sg8Egg8GgHTt2SLr+MmLmzJmqWbOmHBwc5O3trf79++vChQsW/XzxxRdq3769ypUrJ3t7ez3yyCOaMGGCsrOzzW3CwsK0fv16nTx50jxO7szyRYsWyWAwKDk52aLfHTt2WMST20+tWrW0Z88eNW3aVE5OTnr11VeLdW3yc3MJm9xzM23aNM2bN09VqlSRk5OTWrdurVOnTslkMmnChAmqUKGCHB0d9fTTT+v8+fMWffr5+enJJ5/U5s2bVadOHTk4OKhGjRpavXp1nvF/+eUXdenSRR4eHnJyclJoaKjWr1+f7/lYvny5Xn/9dZUvX15OTk6aPXu2unTpIkl64okn8lzHolyfG8/tgQMH9MQTT8jJyUnly5fX1KlT88T7119/aezYsQoICJCDg4PKli2rTp066fjx4+Y2Rb1/8vPTTz8pKipKVapUkYODg3x8fPTCCy/o3Llzedr++uuv6tOnj/n4KleurH/961/KzMyU9L/7a+fOnRo4cKAefvhhVahQwbz/O++8Y35Gy5Urp0GDBiktLc1ijKNHj+qZZ56Rj4+PHBwcVKFCBXXv3l0XL140t9myZYsee+wxubu7y2g0KjAw0Hxv5qew5+/G5/yzzz4zH8PN3n33XRkMBu3fv9+87tChQ+rcubM8PDzk4OCgevXqae3atbc857n314kTJ7R+/XpzPLnP5ZkzZ9SnTx95e3vLwcFBwcHBWrx48S37zPXdd9+pfv36cnBw0COPPKJ3330333bFPYcAANwOSvEAAAAAVmLZsmXq1KmT7Ozs1KNHD/373/9WYmKi6tevL1tbW3Xs2FGrV6/Wu+++Kzs7O/N+a9asUUZGhrp37y7peqLyqaee0nfffad+/fqpevXq2rdvn95++20dOXJEa9assRh327ZtWrFihQYPHixPT09z4njWrFl66qmn9OyzzyozM1PLly9Xly5dtG7dOrVv3968f1RUlFasWKFevXopNDRUO3futNie6/Tp0woNDTW/TPDy8tKGDRvUp08fXbp0qcDSN15eXlq6dKkmTZqk9PR0TZkyRZLMNbX79++vRYsWqXfv3ho6dKhOnDihuXPnau/evYqLi5Otra2k64lTo9Gol19+WUajUdu2bdMbb7yhS5cu6a233pIkvfbaa7p48aL++9//mkuOGI3GYl7J686dO6e2bduqe/fueu655+Tt7V3sa1NUy5YtU2ZmpoYMGaLz589r6tSp6tq1q5o3b64dO3Zo1KhROnbsmObMmaPhw4fneZly9OhRdevWTQMGDNDzzz+vhQsXqkuXLtq4caNatWol6fr1a9y4sa5evaqhQ4fqoYce0uLFi/XUU0/ps88+U8eOHS36nDBhguzs7DR8+HBlZGSodevWGjp0qGbPnq1XX33VfP1y/7co1yfXhQsX1KZNG3Xq1Eldu3bVZ599plGjRikoKEht27aVJGVnZ+vJJ5/U1q1b1b17dw0bNkyXL1/Wli1btH//fj3yyCOSin7/5GfLli365Zdf1Lt3b/n4+Ojnn3/We++9p59//ln/+c9/zB9d/e2339SgQQOlpaWpX79+qlatmn799Vd99tlnunr1qsXzPHDgQHl5eemNN94wz9gfO3asxo0bp5YtW+pf//qXDh8+bP73ITfGzMxMhYeHKyMjQ0OGDJGPj49+/fVXrVu3TmlpaXJzc9PPP/+sJ598UrVr19b48eNlb2+vY8eOKS4ursBjLOz5u1H79u1lNBq1YsUKNWvWzGLbp59+qpo1a6pWrVqSpJ9//llNmjRR+fLl9X//939ydnbWihUr1KFDB61atSrP/ZSrevXqWrp0qV566SVVqFBBr7zyijnOP//8U2FhYTp27JgGDx6sypUra+XKlYqKilJaWpqGDRtW4HHu27dPrVu3lpeXl8aOHausrCzFxMTI29vbot3tnEMAAG6LCQAAAMA/3u7du02STFu2bDGZTCZTTk6OqUKFCqZhw4aZ22zatMkkyfTll19a7NuuXTtTlSpVzMtLly412djYmL799luLdvPnzzdJMsXFxZnXSTLZ2NiYfv755zwxXb161WI5MzPTVKtWLVPz5s3N6/bs2WOSZIqOjrZoGxUVZZJkiomJMa/r06ePqWzZsqazZ89atO3evbvJzc0tz3g3a9asmalmzZoW67799luTJNOyZcss1m/cuDHP+vz679+/v8nJycn0119/mde1b9/eVKlSpTxtFy5caJJkOnHihMX67du3mySZtm/fbhGrJNP8+fMt2hbn2uTn+eeft4jtxIkTJkkmLy8vU1pamnn96NGjTZJMwcHBpmvXrpnX9+jRw2RnZ2dxvJUqVTJJMq1atcq87uLFi6ayZcuaQkJCzOuio6NNkixiv3z5sqly5comPz8/U3Z2tsX5qFKlSp5zvnLlyjznKldRr0/uuV2yZIl5XUZGhsnHx8f0zDPPmNd9+OGHJkmmGTNm5Ok3JyfHZDIV7/7JT34xf/LJJyZJpm+++ca8LjIy0mRjY2NKTEwsMJbc++uxxx4zZWVlmbefOXPGZGdnZ2rdurX5HJtMJtPcuXNNkkwffvihyWQymfbu3WuSZFq5cmWB8b799tsmSaY//vjjlseVn/yeP5PJlOc579Gjh+nhhx+2OIbU1FSTjY2Nafz48eZ1LVq0MAUFBVlc25ycHFPjxo1N/v7+hcZTqVIlU/v27S3WzZw50yTJ9NFHH5nXZWZmmho1amQyGo2mS5cuFRh3hw4dTA4ODqaTJ0+a1x04cMBUqlQp042plb9zDgEAKA5K8QAAAABWYNmyZfL29tYTTzwh6Xp5i27dumn58uXmUiTNmzeXp6enPv30U/N+Fy5c0JYtW9StWzfzupUrV6p69eqqVq2azp49a/41b95ckrR9+3aLsZs1a6YaNWrkicnR0dFinIsXL+rxxx/XDz/8YF6fW7Zn4MCBFvsOGTLEYtlkMmnVqlWKiIiQyWSyiCs8PFwXL1606LeoVq5cKTc3N7Vq1cqiz7p168poNFoc643Hc/nyZZ09e1aPP/64rl69qkOHDhV77MLY29vnKZ1U3GtTVF26dJGbm5t5uWHDhpKk5557zqL+ecOGDZWZmalff/3VYv9y5cpZzJB2dXVVZGSk9u7dq99//12S9NVXX6lBgwZ67LHHzO2MRqP69eun5ORkHThwwKLP559/3uKcF6Y418doNOq5554zL9vZ2alBgwb65ZdfzOtWrVolT0/PPPeiJPNM+uLcP4XF/Ndff+ns2bMKDQ2VJPP9nJOTozVr1igiIkL16tUrMJZcffv2ValSpczLX3/9tTIzMxUdHS0bGxuLdq6uruZSSLnXf9OmTQV+zyG3Jv0XX3xx17550K1bN505c8aiNNVnn32mnJwc879T58+f17Zt29S1a1fztT579qzOnTun8PBwHT16NM89WhRfffWVfHx81KNHD/M6W1tbDR06VOnp6fmWCJKu/3XHpk2b1KFDB1WsWNG8vnr16goPD7doey/OIQAAEjX2AQAAgH+87OxsLV++XE888YROnDihY8eO6dixY2rYsKFOnz6trVu3SpJKly6tZ555Rl988YW5Hvvq1at17do1i8T+0aNH9fPPP8vLy8viFxAQIOl6DeobVa5cOd+41q1bp9DQUDk4OMjDw0NeXl7697//bVGv++TJk7KxscnTR9WqVS2W//jjD6Wlpem9997LE1du8vvmuIri6NGjunjxoh5++OE8/aanp1v0+fPPP6tjx45yc3OTq6urvLy8zMnhG4/pTilfvrxFiZXceItzbYrqxmSk9L8kr6+vb77rb64fX7Vq1TwJ5tyYcmuXnzx5UoGBgXnGzi3JcvLkSYv1Bd1XBSnO9alQoUKeeMuUKWNxXMePH1dgYOAtP+xanPsnP+fPn9ewYcPk7e0tR0dHeXl5mY87N+Y//vhDly5dMpegKczN5y33vN587u3s7FSlShXz9sqVK+vll1/W+++/L09PT4WHh2vevHkW565bt25q0qSJXnzxRXl7e6t79+5asWLFHU1Qt2nTRm5ubhYvID/99FPVqVPHfE8dO3ZMJpNJY8aMyXPeY2JiJN3es3Dy5En5+/tbvACRCr5Hc/3xxx/6888/5e/vn2fbzef9XpxDAAAkauwDAAAA/3jbtm1Tamqqli9fruXLl+fZvmzZMrVu3VqS1L17d7377rvasGGDOnTooBUrVqhatWoKDg42t8/JyVFQUJBmzJiR73g3J3vzm1X97bff6qmnnlLTpk31zjvvqGzZsrK1tdXChQv18ccfF/sYc5Nezz33nJ5//vl829SuXfu2+n344YctPjR8Iy8vL0lSWlqamjVrJldXV40fP16PPPKIHBwc9MMPP2jUqFFFSsrdnEjOdfPHXXPld16Le22K6sYZ3kVZbzKZbmuc4ijObP3iXp87dVxFvX8K0rVrV+3atUsjRoxQnTp1ZDQalZOTozZt2tx2orc45+1m06dPV1RUlL744gtt3rxZQ4cO1ZQpU/Sf//zH/AHlb775Rtu3b9f69eu1ceNGffrpp2revLk2b95c4HktDnt7e3Xo0EGff/653nnnHZ0+fVpxcXGaPHmyuU3uuRk+fHieGfG5bn45+E9xL84hAAASiX0AAADgH2/ZsmV6+OGHNW/evDzbVq9erc8//1zz58+Xo6OjmjZtqrJly+rTTz/VY489pm3btum1116z2OeRRx7Rjz/+qBYtWhSYjC7MqlWr5ODgoE2bNsne3t68fuHChRbtKlWqpJycHJ04ccJituuxY8cs2nl5ecnFxUXZ2dlq2bLlbcWUn0ceeURff/21mjRpcsuE6I4dO3Tu3DmtXr1aTZs2Na8/ceJEnrYFnbMyZcpIup6EvlFBs4ALivfvXpu7IXcG9Y0xHTlyRJLMH1OuVKmSDh8+nGff3DI5lSpVKnScgo65ONenqB555BHFx8fr2rVrBX4At6j3T34uXLigrVu3aty4cXrjjTfM648ePWrRzsvLS66urtq/f3/xD0L/O6+HDx9WlSpVzOszMzN14sSJPM9TUFCQgoKC9Prrr2vXrl1q0qSJ5s+fr4kTJ0qSbGxs1KJFC7Vo0UIzZszQ5MmT9dprr2n79u137Nns1q2bFi9erK1bt+rgwYMymUwWf1WUexy2trZ39N+DSpUq6aefflJOTo7FrP3C7lEvLy85OjrmuXaS8r3n78U5BACAUjwAAADAP9iff/6p1atX68knn1Tnzp3z/AYPHqzLly9r7dq1kq4nlDp37qwvv/xSS5cuVVZWlkXCTLo+i/jXX3/VggUL8h3vypUrhcZVqlQpGQwGi9noycnJWrNmjUW73Nm277zzjsX6OXPm5OnvmWee0apVq/JNcP7xxx+FxpSfrl27Kjs7WxMmTMizLSsry5yEz51Fe+OM7szMzDxxS5Kzs3O+pXkeeeQRSdI333xjXpedna333nuvWPH+3WtzN/z222/6/PPPzcuXLl3SkiVLVKdOHfn4+EiS2rVrp4SEBH3//ffmdleuXNF7770nPz+/fL/TcDNnZ2dJeV+OFOf6FNUzzzyjs2fPau7cuXm25Y5T1PsnP/nFLEkzZ860WLaxsVGHDh305Zdfavfu3QXGUpCWLVvKzs5Os2fPtmj7wQcf6OLFi2rfvr2k69csKyvLYt+goCDZ2NiYS3edP38+T/916tSRJHObO6Fly5by8PDQp59+qk8//VQNGjSwKDH08MMPKywsTO+++65SU1Pz7H+7/x60a9dOv//+u0UZoKysLM2ZM0dGo1HNmjXLd79SpUopPDxca9asUUpKinn9wYMHtWnTJou29+ocAgDAjH0AAADgH2zt2rW6fPmynnrqqXy3h4aGysvLS8uWLTMn8Lt166Y5c+YoJiZGQUFB5vrRuXr16qUVK1ZowIAB2r59u5o0aaLs7GwdOnRIK1as0KZNm/L9iOeN2rdvrxkzZqhNmzbq2bOnzpw5o3nz5qlq1ar66aefzO3q1q2rZ555RjNnztS5c+cUGhqqnTt3mmd73zhDOzY2Vtu3b1fDhg3Vt29f1ahRQ+fPn9cPP/ygr7/+Ot+EWWGaNWum/v37a8qUKUpKSlLr1q1la2uro0ePauXKlZo1a5Y6d+6sxo0bq0yZMnr++ec1dOhQGQwGLV26NN+kat26dfXpp5/q5ZdfVv369WU0GhUREaGaNWsqNDRUo0eP1vnz5+Xh4aHly5fnSabeyp24NndDQECA+vTpo8TERHl7e+vDDz/U6dOnLf5C4//+7//0ySefqG3btho6dKg8PDy0ePFinThxQqtWrcpT1zw/derUUalSpfTmm2/q4sWLsre3V/PmzYt1fYoqMjJSS5Ys0csvv6yEhAQ9/vjjunLlir7++msNHDhQTz/9dJHvn/y4urqqadOmmjp1qq5du6by5ctr8+bN+f6VweTJk7V582Y1a9ZM/fr1U/Xq1ZWamqqVK1fqu+++M3+QNT9eXl4aPXq0xo0bpzZt2uipp57S4cOH9c4776h+/frm7xBs27ZNgwcPVpcuXRQQEKCsrCwtXbrU/FJNksaPH69vvvlG7du3V6VKlXTmzBm98847qlChgsVHkf8uW1tbderUScuXL9eVK1c0bdq0PG3mzZunxx57TEFBQerbt6+qVKmi06dP6/vvv9d///tf/fjjj8Uet1+/fnr33XcVFRWlPXv2yM/PT5999pni4uI0c+ZMubi4FLjvuHHjtHHjRj3++OMaOHCg+YVAzZo1Lf7Nu1fnEAAAmQAAAAD8Y0VERJgcHBxMV65cKbBNVFSUydbW1nT27FmTyWQy5eTkmHx9fU2STBMnTsx3n8zMTNObb75pqlmzpsne3t5UpkwZU926dU3jxo0zXbx40dxOkmnQoEH59vHBBx+Y/P39Tfb29qZq1aqZFi5caIqJiTHd/H8zrly5Yho0aJDJw8PDZDQaTR06dDAdPnzYJMkUGxtr0fb06dOmQYMGmXx9fU22trYmHx8fU4sWLUzvvfdeoeeqWbNmppo1a+a77b333jPVrVvX5OjoaHJxcTEFBQWZRo4cafrtt9/MbeLi4kyhoaEmR0dHU7ly5UwjR440bdq0ySTJtH37dnO79PR0U8+ePU3u7u4mSaZKlSqZtx0/ftzUsmVLk729vcnb29v06quvmrZs2ZKnj1vFWtRrk5/nn3/eIp4TJ06YJJneeusti3bbt283STKtXLnSYv3ChQtNkkyJiYnmdZUqVTK1b9/etGnTJlPt2rXN1/vmfXOPv3PnziZ3d3eTg4ODqUGDBqZ169YVaexcCxYsMFWpUsVUqlQpi/NW1OtT0Lm9+dyYTCbT1atXTa+99pqpcuXK5vutc+fOpuPHj1u0K8r9k5///ve/po4dO5rc3d1Nbm5upi5duph+++03kyRTTEyMRduTJ0+aIiMjTV5eXiZ7e3tTlSpVTIMGDTJlZGSYTKb8r82N5s6da6pWrZrJ1tbW5O3tbfrXv/5lunDhgnn7L7/8YnrhhRdMjzzyiMnBwcHk4eFheuKJJ0xff/21uc3WrVtNTz/9tKlcuXImOzs7U7ly5Uw9evQwHTly5JbHaTIVfN7zO1aTyWR+LgwGg+nUqVP59nn8+HFTZGSkycfHx2Rra2sqX7686cknnzR99tlnhcaTe9/e7PTp06bevXubPD09TXZ2dqagoCDTwoULixT3zp07TXXr1jXZ2dmZqlSpYpo/f36ef/P+zjkEAKA4DCbTPfgqEgAAAADcICkpSSEhIfroo4/07LPPlnQ4uAU/Pz/VqlVL69atK+lQAAAA8P9RYx8AAADAXfXnn3/mWTdz5kzZ2NhYfAgVAAAAQNFQYx8AAADAXTV16lTt2bNHTzzxhEqXLq0NGzZow4YN6tevn3x9fUs6PAAAAMDqkNgHAAAAcFc1btxYW7Zs0YQJE5Senq6KFStq7Nixeu2110o6NAAAAMAqUWMfAAAAAAAAAAArQo19AAAAAAAAAACsCIl9AAAAAAAAAACsCDX2AaAE5eTk6LfffpOLi4sMBkNJhwMAAAAAAIASYjKZdPnyZZUrV042Nreek09iHwBK0G+//SZfX9+SDgMAAAAAAAD/EKdOnVKFChVu2YbEPgCUIBcXF0nX/8F2dXUt4WgAAAAAAABQUi5duiRfX19zvuhWSOwDQAnKLb/j6upKYh8AAAAAAABFKtfMx3MBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAipUs6AACAVCtmk2zsnUo6DAAAAAAAgH+85Nj2JR1CiWPGPgAAAAAAAAAAVoTEPgAAAAAAAAAAVoTEPgCrFhYWpujoaEmSn5+fZs6cWaLxAAAAAAAAAHcbiX0A943ExET169fvno2Xmpqqnj17KiAgQDY2NuYXDAAAAAAAAMDdRGIfwH3Dy8tLTk737gO0GRkZ8vLy0uuvv67g4OB7Ni4AAAAAAAAebCT2AViNK1euKDIyUkajUWXLltX06dMttt9cimfGjBkKCgqSs7OzfH19NXDgQKWnp1vss2DBAvn6+srJyUkdO3bUjBkz5O7uXqR4/Pz8NGvWLEVGRsrNze3vHh4AAAAAAABQJCT2AViNESNGaOfOnfriiy+0efNm7dixQz/88EOB7W1sbDR79mz9/PPPWrx4sbZt26aRI0eat8fFxWnAgAEaNmyYkpKS1KpVK02aNOleHAoAAAAAAABw20qXdAAAUBTp6en64IMP9NFHH6lFixaSpMWLF6tChQoF7nNjzXs/Pz9NnDhRAwYM0DvvvCNJmjNnjtq2bavhw4dLkgICArRr1y6tW7furh1HRkaGMjIyzMuXLl26a2MBAAAAAADg/sSMfQBW4fjx48rMzFTDhg3N6zw8PBQYGFjgPl9//bVatGih8uXLy8XFRb169dK5c+d09epVSdLhw4fVoEEDi31uXr7TpkyZIjc3N/PP19f3ro4HAAAAAACA+w+JfQD3peTkZD355JOqXbu2Vq1apT179mjevHmSpMzMzBKLa/To0bp48aL5d+rUqRKLBQAAAAAAANaJxD4Aq/DII4/I1tZW8fHx5nUXLlzQkSNH8m2/Z88e5eTkaPr06QoNDVVAQIB+++03izaBgYFKTEy0WHfz8p1mb28vV1dXix8AAAAAAABQHNTYB2AVjEaj+vTpoxEjRuihhx7Sww8/rNdee002Nvm/n6xataquXbumOXPmKCIiQnFxcZo/f75FmyFDhqhp06aaMWOGIiIitG3bNm3YsEEGg6HIcSUlJUm6/g2AP/74Q0lJSbKzs1ONGjVu+1gBAAAAAACAW2HGPgCr8dZbb+nxxx9XRESEWrZsqccee0x169bNt21wcLBmzJihN998U7Vq1dKyZcs0ZcoUizZNmjTR/PnzNWPGDAUHB2vjxo166aWX5ODgUOSYQkJCFBISoj179ujjjz9WSEiI2rVr97eOEwAAAAAAALgVg8lkMpV0EADwT9G3b18dOnRI33777T0Z79KlS9c/ohu9Qjb2TvdkTAAAAAAAAGuWHNu+pEO4K3LzRBcvXiy0fDOleAA80KZNm6ZWrVrJ2dlZGzZs0OLFi/XOO++UdFgAAAAAAABAgSjFA+CBlpCQoFatWikoKEjz58/X7Nmz9eKLL0qSatasKaPRmO9v2bJlJRw5AAAAAAAAHlTM2AfwQFuxYkWB27766itdu3Yt323e3t53KyQAAAAAAADglqixDwAlqDi10wAAAAAAAHD/Kk6eiFI8AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYERL7AAAAAAAAAABYkdIlHQAAQKoVs0k29k4lHQYAAAAAAMAdkRzbvqRDuK8xYx8AAAAAAAAAACtCYh8AAAAAAAAAACtCYh8AAAAAAAAAACtCYh+AVQsLC1N0dLQkyc/PTzNnzizReAAAAAAAAIC7jcQ+gPtGYmKi+vXrd8/G++6779SkSRM99NBDcnR0VLVq1fT222/fs/EBAAAAAADwYCpd0gEAwJ3i5eV1T8dzdnbW4MGDVbt2bTk7O+u7775T//795ezsfE9fMAAAAAAAAODBwox9AFbjypUrioyMlNFoVNmyZTV9+nSL7TeX4pkxY4aCgoLk7OwsX19fDRw4UOnp6Rb7LFiwQL6+vnJyclLHjh01Y8YMubu7FymekJAQ9ejRQzVr1pSfn5+ee+45hYeH69tvv/27hwoAAAAAAAAUiMQ+AKsxYsQI7dy5U1988YU2b96sHTt26IcffiiwvY2NjWbPnq2ff/5Zixcv1rZt2zRy5Ejz9ri4OA0YMEDDhg1TUlKSWrVqpUmTJt12fHv37tWuXbvUrFmz2+4DAAAAAAAAKAyleABYhfT0dH3wwQf66KOP1KJFC0nS4sWLVaFChQL3yf2ornR9Nv/EiRM1YMAAvfPOO5KkOXPmqG3btho+fLgkKSAgQLt27dK6deuKFVuFChX0xx9/KCsrS2PHjtWLL75YYNuMjAxlZGSYly9dulSssQAAAAAAAABm7AOwCsePH1dmZqYaNmxoXufh4aHAwMAC9/n666/VokULlS9fXi4uLurVq5fOnTunq1evSpIOHz6sBg0aWOxz83JRfPvtt9q9e7fmz5+vmTNn6pNPPimw7ZQpU+Tm5mb++fr6Fns8AAAAAAAAPNhI7AO4LyUnJ+vJJ59U7dq1tWrVKu3Zs0fz5s2TJGVmZt7RsSpXrqygoCD17dtXL730ksaOHVtg29GjR+vixYvm36lTp+5oLAAAAAAAALj/kdgHYBUeeeQR2draKj4+3rzuwoULOnLkSL7t9+zZo5ycHE2fPl2hoaEKCAjQb7/9ZtEmMDBQiYmJFutuXi6unJwci1I7N7O3t5erq6vFDwAAAAAAACgOauwDsApGo1F9+vTRiBEj9NBDD+nhhx/Wa6+9Jhub/N9PVq1aVdeuXdOcOXMUERGhuLg4zZ8/36LNkCFD1LRpU82YMUMRERHatm2bNmzYIIPBUKSY5s2bp4oVK6patWqSpG+++UbTpk3T0KFD/97BAgAAAAAAALfAjH0AVuOtt97S448/roiICLVs2VKPPfaY6tatm2/b4OBgzZgxQ2+++aZq1aqlZcuWacqUKRZtmjRpovnz52vGjBkKDg7Wxo0b9dJLL8nBwaFI8eTk5Gj06NGqU6eO6tWrp3nz5unNN9/U+PHj//axAgAAAAAAAAUxmEwmU0kHAQD/FH379tWhQ4f07bff3pPxLl26dP0jutErZGPvdE/GBAAAAAAAuNuSY9uXdAhWJzdPdPHixULLN1OKB8ADbdq0aWrVqpWcnZ21YcMGLV68WO+8805JhwUAAAAAAAAUiFI8AB5oCQkJatWqlYKCgjR//nzNnj1bL774oiSpZs2aMhqN+f6WLVtWwpEDAAAAAADgQcWMfQAPtBUrVhS47auvvtK1a9fy3ebt7X23QgIAAAAAAABuiRr7AFCCilM7DQAAAAAAAPev4uSJKMUDAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVKV3SAQAApFoxm2Rj71TSYQAAAAAAAEiSkmPbl3QIuAVm7AMAAAAAAAAAYEVI7AMAAAAAAAAAYEVI7AMAAAAAAAAAYEVI7AOwamFhYYqOjpYk+fn5aebMmSUaDwAAAAAAAHC3kdgHcN9ITExUv3797tl4q1evVqtWreTl5SVXV1c1atRImzZtumfjAwAAAAAA4MFEYh/AfcPLy0tOTk73bLxvvvlGrVq10ldffaU9e/boiSeeUEREhPbu3XvPYgAAAAAAAMCDh8Q+AKtx5coVRUZGymg0qmzZspo+fbrF9ptL8cyYMUNBQUFydnaWr6+vBg4cqPT0dIt9FixYIF9fXzk5Oaljx46aMWOG3N3dixTPzJkzNXLkSNWvX1/+/v6aPHmy/P399eWXX/7dQwUAAAAAAAAKRGIfgNUYMWKEdu7cqS+++EKbN2/Wjh079MMPPxTY3sbGRrNnz9bPP/+sxYsXa9u2bRo5cqR5e1xcnAYMGKBhw4YpKSlJrVq10qRJk247vpycHF2+fFkeHh633QcAAAAAAABQmNIlHQAAFEV6ero++OADffTRR2rRooUkafHixapQoUKB++R+VFe6Ppt/4sSJGjBggN555x1J0pw5c9S2bVsNHz5ckhQQEKBdu3Zp3bp1txXjtGnTlJ6erq5duxbYJiMjQxkZGeblS5cu3dZYAAAAAAAAeHAxYx+AVTh+/LgyMzPVsGFD8zoPDw8FBgYWuM/XX3+tFi1aqHz58nJxcVGvXr107tw5Xb16VZJ0+PBhNWjQwGKfm5eL6uOPP9a4ceO0YsUKPfzwwwW2mzJlitzc3Mw/X1/f2xoPAAAAAAAADy4S+wDuS8nJyXryySdVu3ZtrVq1Snv27NG8efMkSZmZmXd0rOXLl+vFF1/UihUr1LJly1u2HT16tC5evGj+nTp16o7GAgAAAAAAgPsfiX0AVuGRRx6Rra2t4uPjzesuXLigI0eO5Nt+z549ysnJ0fTp0xUaGqqAgAD99ttvFm0CAwOVmJhose7m5cJ88skn6t27tz755BO1b9++0Pb29vZydXW1+AEAAAAAAADFQY19AFbBaDSqT58+GjFihB566CE9/PDDeu2112Rjk//7yapVq+ratWuaM2eOIiIiFBcXp/nz51u0GTJkiJo2baoZM2YoIiJC27Zt04YNG2QwGIoU08cff6znn39es2bNUsOGDfX7779LkhwdHeXm5vb3DhgAAAAAAAAoADP2AViNt956S48//rgiIiLUsmVLPfbYY6pbt26+bYODgzVjxgy9+eabqlWrlpYtW6YpU6ZYtGnSpInmz5+vGTNmKDg4WBs3btRLL70kBweHIsXz3nvvKSsrS4MGDVLZsmXNv2HDhv3tYwUAAAAAAAAKYjCZTKaSDgIA/in69u2rQ4cO6dtvv70n4126dOn6R3SjV8jG3umejAkAAAAAAFCY5NjCSw7jzsrNE128eLHQ8s2U4gHwQJs2bZpatWolZ2dnbdiwQYsXL9Y777xT0mEBAAAAAAAABaIUD4AHWkJCglq1aqWgoCDNnz9fs2fP1osvvihJqlmzpoxGY76/ZcuWlXDkAAAAAAAAeFAxYx/AA23FihUFbvvqq6907dq1fLd5e3vfrZAAAAAAAACAW6LGPgCUoOLUTgMAAAAAAMD9qzh5IkrxAAAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUqXdAAAAKlWzCbZ2DuVdBgAAAAAcE8kx7Yv6RAAwKoxYx8AAAAAAAAAACtCYh8AAAAAAAAAACtCYh8AAAAAAAAAACtCYh+wQmFhYYqOji5y+x07dshgMCgtLe2uxfRPsmjRIrm7u5d0GAAAAAAAAMBdQWIfAAAAAAAAAAArQmIfwF2RmZlZ0iH8LdYePwAAAAAAAO5fJPaBQoSFhWno0KEaOXKkPDw85OPjo7Fjx0qSkpOTZTAYlJSUZG6flpYmg8GgHTt2SPpfGZxNmzYpJCREjo6Oat68uc6cOaMNGzaoevXqcnV1Vc+ePXX16tXbinHp0qWqV6+eXFxc5OPjo549e+rMmTN52sXFxal27dpycHBQaGio9u/fX6T+c0vbrFmzRv7+/nJwcFB4eLhOnTplbjN27FjVqVNH77//vipXriwHBwdJUkpKip5++mkZjUa5urqqa9euOn36tEX/X375perXry8HBwd5enqqY8eO5m0ZGRkaPny4ypcvL2dnZzVs2NB8bm+Mr2LFinJyclLHjh117tw5i+1RUVHq0KGDxbro6GiFhYWZl8PCwjR48GBFR0fL09NT4eHhkqT9+/erbdu2MhqN8vb2Vq9evXT27Fnzfp999pmCgoLk6Oiohx56SC1bttSVK1eKdF4BAAAAAACA20FiHyiCxYsXy9nZWfHx8Zo6darGjx+vLVu2FKuPsWPHau7cudq1a5dOnTqlrl27aubMmfr444+1fv16bd68WXPmzLmt+K5du6YJEyboxx9/1Jo1a5ScnKyoqKg87UaMGKHp06crMTFRXl5eioiI0LVr14o0xtWrVzVp0iQtWbJEcXFxSktLU/fu3S3aHDt2TKtWrdLq1auVlJSknJwcPf300zp//rx27typLVu26JdfflG3bt3M+6xfv14dO3ZUu3bttHfvXm3dulUNGjQwbx88eLC+//57LV++XD/99JO6dOmiNm3a6OjRo5Kk+Ph49enTR4MHD1ZSUpKeeOIJTZw48TbO4vXrbGdnp7i4OM2fP19paWlq3ry5QkJCtHv3bm3cuFGnT59W165dJUmpqanq0aOHXnjhBR08eFA7duxQp06dZDKZbmt8AAAAAAAAoChKl3QAgDWoXbu2YmJiJEn+/v6aO3eutm7dKn9//yL3MXHiRDVp0kSS1KdPH40ePVrHjx9XlSpVJEmdO3fW9u3bNWrUqGLH98ILL5j/u0qVKpo9e7bq16+v9PR0GY1G87aYmBi1atVK0vUkdoUKFfT555+bE9W3cu3aNc2dO1cNGzY071+9enUlJCSYE/GZmZlasmSJvLy8JElbtmzRvn37dOLECfn6+kqSlixZopo1ayoxMVH169fXpEmT1L17d40bN848VnBwsKTrs/0XLlyolJQUlStXTpI0fPhwbdy4UQsXLtTkyZM1a9YstWnTRiNHjpQkBQQEaNeuXdq4cWOxz6O/v7+mTp1qXp44caJCQkI0efJk87oPP/xQvr6+OnLkiNLT05WVlaVOnTqpUqVKkqSgoKBbjpGRkaGMjAzz8qVLl4odJwAAAAAAAB5szNgHiqB27doWy2XLls231E1R+/D29paTk5M5qZ+7rrh95tqzZ48iIiJUsWJFubi4qFmzZpKuJ8Zv1KhRI/N/e3h4KDAwUAcPHizSGKVLl1b9+vXNy9WqVZO7u7vF/pUqVTIn9SXp4MGD8vX1NSf1JalGjRoW+yUlJalFixb5jrlv3z5lZ2crICBARqPR/Nu5c6eOHz9uHiP3ZUN+x1kcdevWtVj+8ccftX37douxq1WrJkk6fvy4goOD1aJFCwUFBalLly5asGCBLly4cMsxpkyZIjc3N/PvxnMDAAAAAAAAFAUz9oEisLW1tVg2GAzKycmRjc31d2M3ll4pqLTNjX0YDIYC+yyuK1euKDw8XOHh4Vq2bJm8vLyUkpKi8PDwe/4BWGdn52Lv4+joWOC29PR0lSpVSnv27FGpUqUstt34lwiFsbGxyVMeJ7/rdHP86enpioiI0JtvvpmnbdmyZVWqVClt2bJFu3btMpdSeu211xQfH6/KlSvnG8vo0aP18ssvm5cvXbpEch8AAAAAAADFwox94G/InZ2emppqXnfjh3TvhUOHDuncuXOKjY3V448/rmrVqhU48/8///mP+b8vXLigI0eOqHr16kUaJysrS7t37zYvHz58WGlpabfcv3r16jp16pTFR3YPHDigtLQ01ahRQ9L1v2TYunVrvvuHhIQoOztbZ86cUdWqVS1+Pj4+5jHi4+MLPE7p+nW68RpJRbtOjz76qH7++Wf5+fnlGT/3JYDBYFCTJk00btw47d27V3Z2dvr8888L7NPe3l6urq4WPwAAAAAAAKA4SOwDf4Ojo6NCQ0MVGxurgwcPaufOnXr99dfvaQwVK1aUnZ2d5syZo19++UVr167VhAkT8m07fvx4bd26Vfv371dUVJQ8PT3VoUOHIo1ja2urIUOGKD4+Xnv27FFUVJRCQ0MtPnR7s5YtWyooKEjPPvusfvjhByUkJCgyMlLNmjVTvXr1JF2v+//JJ58oJiZGBw8e1L59+8wz5AMCAvTss88qMjJSq1ev1okTJ5SQkKApU6Zo/fr1kqShQ4dq48aNmjZtmo4ePaq5c+fmqa/fvHlz7d69W0uWLNHRo0cVExOj/fv3F3rMgwYN0vnz59WjRw8lJibq+PHj2rRpk3r37q3s7GzFx8dr8uTJ2r17t1JSUrR69Wr98ccfRX5ZAgAAAAAAANwOEvvA3/Thhx8qKytLdevWVXR0tCZOnHhPx/fy8tKiRYu0cuVK1ahRQ7GxsZo2bVq+bWNjYzVs2DDVrVtXv//+u7788kvZ2dkVaRwnJyeNGjVKPXv2VJMmTWQ0GvXpp5/ech+DwaAvvvhCZcqUUdOmTdWyZUtVqVLFYr+wsDCtXLlSa9euVZ06ddS8eXMlJCSYty9cuFCRkZF65ZVXFBgYqA4dOigxMVEVK1aUJIWGhmrBggWaNWuWgoODtXnz5jwvV8LDwzVmzBiNHDlS9evX1+XLlxUZGVnoMZcrV05xcXHKzs5W69atFRQUpOjoaLm7u8vGxkaurq765ptv1K5dOwUEBOj111/X9OnT1bZt2yKdUwAAAAAAAOB2GEw3F54GgJssWrRI0dHRSktLK+lQ7juXLl26/hHd6BWysXcq6XAAAAAA4J5Ijm1f0iEAwD9Obp7o4sWLhZZvZsY+AAAAAAAAAABWhMQ+8A+TkpIio9FY4C8lJeWOj9m2bdsCx5s8efIdHw8AAAAAAADA7Std0gEAsFSuXDklJSXdcvud9v777+vPP//Md5uHh4c8PDwUFRV1x8cFAAAAAAAAUHzU2AeAElSc2mkAAAAAAAC4f1FjHwAAAAAAAACA+xSJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArAiJfQAAAAAAAAAArEjpkg4AACDVitkkG3unkg4DAAAAJSg5tn1JhwAAAKwEM/YBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYB3HNhYWGKjo42L/v5+WnmzJl3dcwdO3bIYDAoLS3tro4DAAAAAAAA3G18PBdAiUtMTJSzs/Md6y8sLEx16tSxeFnQuHFjpaamys3N7Y6NAwAAAAAAAJQEEvsASpyXl9ddH8POzk4+Pj53fRwAAAAAAADgbqMUD1ACwsLCNHToUI0cOVIeHh7y8fHR2LFjJUnJyckyGAxKSkoyt09LS5PBYNCOHTsk/a+szKZNmxQSEiJHR0c1b95cZ86c0YYNG1S9enW5urqqZ8+eunr1apFjGjJkiKKjo1WmTBl5e3trwYIFunLlinr37i0XFxdVrVpVGzZssNhv//79atu2rYxGo7y9vdWrVy+dPXvWvP3KlSuKjIyU0WhU2bJlNX369Dxj31yKJy0tTf3795e3t7ccHBxUq1YtrVu3TpJ07tw59ejRQ+XLl5eTk5OCgoL0ySefmPeNiorSzp07NWvWLBkMBhkMBiUnJ+dbimfVqlWqWbOm7O3t5efnlyc2Pz8/TZ48WS+88IJcXFxUsWJFvffee+btmZmZGjx4sMqWLSsHBwdVqlRJU6ZMKdL5BgAAAAAAAG4XiX2ghCxevFjOzs6Kj4/X1KlTNX78eG3ZsqVYfYwdO1Zz587Vrl27dOrUKXXt2lUzZ87Uxx9/rPXr12vz5s2aM2dOsWLy9PRUQkKChgwZon/961/q0qWLGjdurB9++EGtW7dWr169zC8L0tLS1Lx5c4WEhGj37t3auHGjTp8+ra5du5r7HDFihHbu3KkvvvhCmzdv1o4dO/TDDz8UGENOTo7atm2ruLg4ffTRRzpw4IBiY2NVqlQpSdJff/2lunXrav369dq/f7/69eunXr16KSEhQZI0a9YsNWrUSH379lVqaqpSU1Pl6+ubZ5w9e/aoa9eu6t69u/bt26exY8dqzJgxWrRokUW76dOnq169etq7d68GDhyof/3rXzp8+LAkafbs2Vq7dq1WrFihw4cPa9myZfLz8yvy+QYAAAAAAABuB6V4gBJSu3ZtxcTESJL8/f01d+5cbd26Vf7+/kXuY+LEiWrSpIkkqU+fPho9erSOHz+uKlWqSJI6d+6s7du3a9SoUUXqLzg4WK+//rokafTo0YqNjZWnp6f69u0rSXrjjTf073//Wz/99JNCQ0M1d+5chYSEaPLkyeY+PvzwQ/n6+urIkSMqV66cPvjgA3300Udq0aKFpOsvDypUqFBgDF9//bUSEhJ08OBBBQQESJL5eCSpfPnyGj58uHl5yJAh2rRpk1asWKEGDRrIzc1NdnZ2cnJyumXpnRkzZqhFixYaM2aMJCkgIEAHDhzQW2+9paioKHO7du3aaeDAgZKkUaNG6e2339b27dsVGBiolJQU+fv767HHHpPBYFClSpUKPccZGRnKyMgwL1+6dKnQfQAAAAAAAIAbMWMfKCG1a9e2WC5btqzOnDlz2314e3vLycnJIgnu7e1drD5v7K9UqVJ66KGHFBQUZNGfJHOfP/74o7Zv3y6j0Wj+VatWTZJ0/PhxHT9+XJmZmWrYsKG5Dw8PDwUGBhYYQ1JSkipUqGBO6t8sOztbEyZMUFBQkDw8PGQ0GrVp0yalpKQU+Tgl6eDBg+aXIrmaNGmio0ePKjs727zuxnNiMBjk4+NjPv6oqCglJSUpMDBQQ4cO1ebNmwsdd8qUKXJzczP/8vtrAgAAAAAAAOBWSOwDJcTW1tZi2WAwKCcnRzY21x9Lk8lk3nbt2rVC+zAYDAX2+XdiunkMSeY+09PTFRERoaSkJIvf0aNH1bRp0yKPeyNHR8dbbn/rrbc0a9YsjRo1Stu3b1dSUpLCw8OVmZl5W+MV5lbn9NFHH9WJEyc0YcIE/fnnn+ratas6d+58y/5Gjx6tixcvmn+nTp26K3EDAAAAAADg/kUpHuAfxsvLS5KUmpqqkJAQSbL4kO4/yaOPPqpVq1bJz89PpUvn/efkkUceka2treLj41WxYkVJ0oULF3TkyBE1a9Ys3z5r166t//73vzpy5Ei+s/bj4uL09NNP67nnnpN0/SXDkSNHVKNGDXMbOzs7i1n3+alevbri4uLy9B0QEGCu518Urq6u6tatm7p166bOnTurTZs2On/+vDw8PPJtb29vL3t7+yL3DwAAAAAAANyMGfvAP4yjo6NCQ0MVGxurgwcPaufOnea69/80gwYN0vnz59WjRw8lJibq+PHj2rRpk3r37q3s7GwZjUb16dNHI0aM0LZt27R//35FRUWZ/yohP82aNVPTpk31zDPPaMuWLTpx4oQ2bNigjRs3Srr+PYItW7Zo165dOnjwoPr376/Tp09b9OHn56f4+HglJyfr7Nmz+f7VwiuvvKKtW7dqwoQJOnLkiBYvXqy5c+da1O8vzIwZM/TJJ5/o0KFDOnLkiFauXCkfHx+5u7sXuQ8AAAAAAACguEjsA/9AH374obKyslS3bl1FR0dr4sSJJR1SvsqVK6e4uDhlZ2erdevWCgoKUnR0tNzd3c3J+7feekuPP/64IiIi1LJlSz322GOqW7fuLftdtWqV6tevrx49eqhGjRoaOXKkeQb+66+/rkcffVTh4eEKCwuTj4+POnToYLH/8OHDVapUKdWoUUNeXl751t9/9NFHtWLFCi1fvly1atXSG2+8ofHjx1t8OLcwLi4umjp1qurVq6f69esrOTlZX3311S1fXAAAAAAAAAB/l8F0YyFvAMA9denSpesf0Y1eIRt7p5IOBwAAACUoObZ9SYcAAABKUG6e6OLFi3J1db1lW6aVAgAAAAAAAABgRUjsAw+AlJQUGY3GAn/5laoBAAAAAAAA8M9UuqQDAHD3lStXTklJSbfcDgAAAAAAAMA6UGMfAEpQcWqnAQAAAAAA4P5FjX0AAAAAAAAAAO5TJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAiJPYBAAAAAAAAALAipUs6AACAVCtmk2zsnUo6DAAAANwgObZ9SYcAAACQL2bsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjsAwAAAAAAAABgRUjs30NhYWGKjo4ucvsdO3bIYDAoLS3trsX0T7Jo0SK5u7uXdBhWxZrvkeTkZBkMBiUlJZV0KIUq7rMLAAAAAAAA3E0k9gHcdVFRUerQoYPFOl9fX6WmpqpWrVp3dCyDwaA1a9bc0T4BAAAAAACAfxIS+7CQmZlZ0iH8LdYe/4OkVKlS8vHxUenSpUs6lLuCexEAAAAAAAB3y32b2A8LC9PQoUM1cuRIeXh4yMfHR2PHjpWUfwmQtLQ0GQwG7dixQ9L/Spxs2rRJISEhcnR0VPPmzXXmzBlt2LBB1atXl6urq3r27KmrV6/eVoxLly5VvXr15OLiIh8fH/Xs2VNnzpzJ0y4uLk61a9eWg4ODQkNDtX///iL1n1vaZs2aNfL395eDg4PCw8N16tQpc5uxY8eqTp06ev/991W5cmU5ODhIklJSUvT000/LaDTK1dVVXbt21enTpy36//LLL1W/fn05ODjI09NTHTt2NG/LyMjQ8OHDVb58eTk7O6thw4bmc3tjfBUrVpSTk5M6duyoc+fOWWzPb5Z3dHS0wsLCzMthYWEaPHiwoqOj5enpqfDwcEnS/v371bZtWxmNRnl7e6tXr146e/aseb/PPvtMQUFBcnR01EMPPaSWLVvqypUrhZ7THTt2qEGDBnJ2dpa7u7uaNGmikydPFiveIUOGKDo6WmXKlJG3t7cWLFigK1euqHfv3nJxcVHVqlW1YcOGQmO5UUH3yJUrV+Tq6qrPPvvMov2aNWvk7Oysy5cv37Lf3Gdl+fLlaty4sRwcHFSrVi3t3LnT3CY7O1t9+vRR5cqV5ejoqMDAQM2aNcu8fezYsVq8eLG++OILGQwG83OW33NY2HW71XMtSX5+fpKkjh07ymAwmJdvJfcZWLp0qfz8/OTm5qbu3bvnOTdZWVkaPHiw3Nzc5OnpqTFjxshkMlmMPWHCBEVGRsrV1VX9+vUrdGwAAAAAAADgdty3iX1JWrx4sZydnRUfH6+pU6dq/Pjx2rJlS7H6GDt2rObOnatdu3bp1KlT6tq1q2bOnKmPP/5Y69ev1+bNmzVnzpzbiu/atWuaMGGCfvzxR61Zs0bJycmKiorK027EiBGaPn26EhMT5eXlpYiICF27dq1IY1y9elWTJk3SkiVLFBcXp7S0NHXv3t2izbFjx7Rq1SqtXr1aSUlJysnJ0dNPP63z589r586d2rJli3755Rd169bNvM/69evVsWNHtWvXTnv37tXWrVvVoEED8/bBgwfr+++/1/Lly/XTTz+pS5cuatOmjY4ePSpJio+PV58+fTR48GAlJSXpiSee0MSJE2/jLF6/znZ2doqLi9P8+fOVlpam5s2bKyQkRLt379bGjRt1+vRpde3aVZKUmpqqHj166IUXXtDBgwe1Y8cOderUySJJm5+srCx16NBBzZo1008//aTvv/9e/fr1k8FgKHa8np6eSkhI0JAhQ/Svf/1LXbp0UePGjfXDDz+odevW6tWrV7FeGBV0jzg7O6t79+5auHChRfuFCxeqc+fOcnFxKXL/r7zyivbu3atGjRopIiLC/CImJydHFSpU0MqVK3XgwAG98cYbevXVV7VixQpJ0vDhw9W1a1e1adNGqampSk1NVePGjfOMUdh1u/H8FfRcJyYmmo8vNTXVvFyY48ePa82aNVq3bp3WrVunnTt3KjY2Ns+4pUuXVkJCgmbNmqUZM2bo/ffft2gzbdo0BQcHa+/evRozZkyRxgYAAAAAAACK6/6sgfH/1a5dWzExMZIkf39/zZ07V1u3bpW/v3+R+5g4caKaNGkiSerTp49Gjx6t48ePq0qVKpKkzp07a/v27Ro1alSx43vhhRfM/12lShXNnj1b9evXV3p6uoxGo3lbTEyMWrVqJel6crFChQr6/PPP8yQ883Pt2jXNnTtXDRs2NO9fvXp1JSQkmBPxmZmZWrJkiby8vCRJW7Zs0b59+3TixAn5+vpKkpYsWaKaNWsqMTFR9evX16RJk9S9e3eNGzfOPFZwcLCk67P9Fy5cqJSUFJUrV07S9eTuxo0btXDhQk2ePFmzZs1SmzZtNHLkSElSQECAdu3apY0bNxb7PPr7+2vq1Knm5YkTJyokJESTJ082r/vwww/l6+urI0eOKD09XVlZWerUqZMqVaokSQoKCip0nEuXLunixYt68skn9cgjj0iSqlevXux4g4OD9frrr0uSRo8erdjYWHl6eqpv376SpDfeeEP//ve/9dNPPyk0NLRIfd7qHnnxxRfVuHFjpaamqmzZsjpz5oy++uorff3110WOefDgwXrmmWckSf/+97+1ceNGffDBBxo5cqRsbW0t7oPKlSvr+++/14oVK9S1a1cZjUY5OjoqIyNDPj4+BY4xd+7cW163gIAASQU/161atTLfw+7u7rcc62Y5OTlatGiR+UVHr169tHXrVk2aNMncxtfXV2+//bYMBoMCAwO1b98+vf322+brJknNmzfXK6+8csuxMjIylJGRYV6+dOlSkeMEAAAAAAAApPt8xn7t2rUtlnOTmrfbh7e3t5ycnMxJ/dx1xe0z1549exQREaGKFSvKxcVFzZo1k3Q9MX6jRo0amf/bw8NDgYGBOnjwYJHGKF26tOrXr29erlatmtzd3S32r1SpkjkhKkkHDx6Ur6+vOakvSTVq1LDYLykpSS1atMh3zH379ik7O1sBAQEyGo3m386dO3X8+HHzGLkvG/I7zuKoW7euxfKPP/6o7du3W4xdrVo1SddnZgcHB6tFixYKCgpSly5dtGDBAl24cKHQcTw8PBQVFaXw8HBFRERo1qxZSk1NLXa8N95TpUqV0kMPPWTxYsHb21uSinVf3eoeadCggWrWrKnFixdLkj766CNVqlRJTZs2va3+S5curXr16lncQ/PmzVPdunXl5eUlo9Go9957L899XJjCrluuO/Fc38zPz8/irxfy6zM0NNTirzMaNWqko0ePKjs727yuXr16hY41ZcoUubm5mX83PmcAAAAAAABAUdzXiX1bW1uLZYPBoJycHNnYXD/sG0uvFFTa5sY+DAZDgX0W15UrVxQeHi5XV1ctW7ZMiYmJ+vzzzyXd+49uOjs7F3sfR0fHArelp6erVKlS2rNnj5KSksy/gwcPWtReL4yNjU2e8jj5Xaeb409PT1dERITF2ElJSTp69KiaNm2qUqVKacuWLdqwYYNq1KihOXPmKDAwUCdOnCg0poULF+r7779X48aN9emnnyogIED/+c9/ihVvfvfQzfeZpNu6rwry4osvatGiReZj6N27d7FLCBVk+fLlGj58uPr06aPNmzcrKSlJvXv3LvZ9XNh1y3WnnsEb3ak+i/IsjR49WhcvXjT/bvzmBQAAAAAAAFAU93VivyC5s9NvnG194wc874VDhw7p3Llzio2N1eOPP65q1aoVOOs4N3EsSRcuXNCRI0eKXAImKytLu3fvNi8fPnxYaWlpt9y/evXqOnXqlEXC8cCBA0pLS1ONGjUkXZ81vXXr1nz3DwkJUXZ2ts6cOaOqVata/HLLo1SvXl3x8fEFHqd0/TrdPCO+KNfp0Ucf1c8//yw/P7884+cmXg0Gg5o0aaJx48Zp7969srOzM79YKUxISIhGjx6tXbt2qVatWvr444//Vrx3QmH3yHPPPaeTJ09q9uzZOnDggJ5//vnb7j8rK0t79uwx9x8XF6fGjRtr4MCBCgkJUdWqVS1m2EuSnZ2dxcz2/BTluhWFra1toWPdjvzuV39/f5UqVapY/djb28vV1dXiBwAAAAAAABTHA5nYd3R0VGhoqGJjY3Xw4EHt3LnTXPP8XqlYsaLs7Ow0Z84c/fLLL1q7dq0mTJiQb9vx48dr69at2r9/v6KiouTp6akOHToUaRxbW1sNGTJE8fHx2rNnj6KiohQaGmrxodubtWzZUkFBQXr22Wf1ww8/KCEhQZGRkWrWrJm51EhMTIw++eQTxcTE6ODBg9q3b5/efPNNSdfr5T/77LOKjIzU6tWrdeLECSUkJGjKlClav369JGno0KHauHGjpk2bpqNHj2ru3Ll56us3b95cu3fv1pIlS3T06FHFxMRo//79hR7zoEGDdP78efXo0UOJiYk6fvy4Nm3apN69eys7O1vx8fGaPHmydu/erZSUFK1evVp//PFHoS9LTpw4odGjR+v777/XyZMntXnzZh09etS83+3GeycUdo+UKVNGnTp10ogRI9S6dWtVqFChWP3PmzdPn3/+uQ4dOqRBgwbpwoUL5m9E+Pv7a/fu3dq0aZOOHDmiMWPG5PlorZ+fn3766ScdPnxYZ8+ezfcvGQq7bkXl5+enrVu36vfffy9SiaWiSklJ0csvv6zDhw/rk08+0Zw5czRs2LA71j8AAAAAAABQVA9kYl+6/lHOrKws1a1bV9HR0Zo4ceI9Hd/Ly0uLFi3SypUrVaNGDcXGxmratGn5to2NjdWwYcNUt25d/f777/ryyy9lZ2dXpHGcnJw0atQo9ezZU02aNJHRaNSnn356y30MBoO++OILlSlTRk2bNlXLli1VpUoVi/3CwsK0cuVKrV27VnXq1FHz5s2VkJBg3r5w4UJFRkbqlVdeUWBgoDp06KDExERVrFhR0vV65QsWLNCsWbMUHByszZs353m5Eh4erjFjxmjkyJGqX7++Ll++rMjIyEKPuVy5coqLi1N2drZat26toKAgRUdHy93dXTY2NnJ1ddU333yjdu3aKSAgQK+//rqmT5+utm3bFnouDx06pGeeeUYBAQHq16+fBg0apP79+/+teO+Eotwjffr0UWZmpsVHm4vTf2xsrIKDg/Xdd99p7dq18vT0lCT1799fnTp1Urdu3dSwYUOdO3dOAwcOtNi/b9++CgwMVL169eTl5aW4uLg8YxR23Ypq+vTp2rJli3x9fRUSElLsYy1IZGSk/vzzTzVo0ECDBg3SsGHD1K9fvzvWPwAAAAAAAFBUBtPNRcFx31i0aJGio6OVlpZW0qHgH2Dp0qV66aWX9NtvvxX5xVBycrIqV66svXv3qk6dOnc3wAfUpUuXrn9EN3qFbOydSjocAAAA3CA5tn1JhwAAAB4guXmiixcvFlq+ufQ9iglACbl69apSU1MVGxur/v37FzmpDwAAAAAAAOCf6YEtxXOnpaSkyGg0FvhLSUm542O2bdu2wPEmT558x8d7ENzqGn777bf3PJ4BAwYUGM+AAQOK1MfUqVNVrVo1+fj4aPTo0RbbJk+eXGD/hZUmshY1a9Ys8BiXLVtW0uEBAAAAAAAAxUYpnjskKytLycnJBW738/NT6dJ39g8kfv31V/3555/5bvPw8JCHh8cdHe9BcOzYsQK3lS9fXo6OjvcwGunMmTO6dOlSvttcXV318MMP/63+z58/r/Pnz+e7zdHRUeXLl/9b/f8TnDx5Mt+P9UqSt7e3XFxc7nFElijFAwAA8M9FKR4AAHAvFacUD4l9AChBxfkHGwAAAAAAAPev4uSJKMUDAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVIbEPAAAAAAAAAIAVKV3SAQAApFoxm2Rj71TSYQAAADwwkmPbl3QIAAAAt40Z+wAAAAAAAAAAWBES+wAAAAAAAAAAWBES+wAAAAAAAAAAWBES+3dAWFiYoqOji9x+x44dMhgMSktLu2sx/ZMsWrRI7u7uJR3Gfcma76Xk5GQZDAYlJSWVdCiFKu4zDgAAAAAAANxNJPYB3HVRUVHq0KGDxTpfX1+lpqaqVq1ad3Qsg8GgNWvW3NE+AQAAAAAAgH8SEvsPiMzMzJIO4W+x9viRV6lSpeTj46PSpUuXdCh3BfcsAAAAAAAA7harS+yHhYVp6NChGjlypDw8POTj46OxY8dKyr+0R1pamgwGg3bs2CHpf6VLNm3apJCQEDk6Oqp58+Y6c+aMNmzYoOrVq8vV1VU9e/bU1atXbyvGpUuXql69enJxcZGPj4969uypM2fO5GkXFxen2rVry8HBQaGhodq/f3+R+s8tbbNmzRr5+/vLwcFB4eHhOnXqlLnN2LFjVadOHb3//vuqXLmyHBwcJEkpKSl6+umnZTQa5erqqq5du+r06dMW/X/55ZeqX7++HBwc5OnpqY4dO5q3ZWRkaPjw4SpfvrycnZ3VsGFD87m9Mb6KFSvKyclJHTt21Llz5yy25zd7Ozo6WmFhYeblsLAwDR48WNHR0fL09FR4eLgkaf/+/Wrbtq2MRqO8vb3Vq1cvnT171rzfZ599pqCgIDk6Ouqhhx5Sy5YtdeXKlULPaW5MkydPlre3t9zd3TV+/HhlZWVpxIgR8vDwUIUKFbRw4UKL/U6dOqWuXbvK3d1dHh4eevrpp5WcnGzenpiYqFatWsnT01Nubm5q1qyZfvjhB4s+DAaD3n//fXXs2FFOTk7y9/fX2rVrC435RgXdS1euXJGrq6s+++wzi/Zr1qyRs7OzLl++fMt+c5+p5cuXq3HjxnJwcFCtWrW0c+dOc5vs7Gz16dNHlStXlqOjowIDAzVr1izz9rFjx2rx4sX64osvZDAYzM9jfs9rYdf3Vs+/JPn5+UmSOnbsKIPBYF6+ldxnZenSpfLz85Obm5u6d++e59xkZWVp8ODBcnNzk6enp8aMGSOTyWQx9oQJExQZGSlXV1f169ev0LEBAAAAAACA22F1iX1JWrx4sZydnRUfH6+pU6dq/Pjx2rJlS7H6GDt2rObOnatdu3aZk7MzZ87Uxx9/rPXr12vz5s2aM2fObcV37do1TZgwQT/++KPWrFmj5ORkRUVF5Wk3YsQITZ8+XYmJifLy8lJERISuXbtWpDGuXr2qSZMmacmSJYqLi1NaWpq6d+9u0ebYsWNatWqVVq9eraSkJOXk5Ojpp5/W+fPntXPnTm3ZskW//PKLunXrZt5n/fr16tixo9q1a6e9e/dq69atatCggXn74MGD9f3332v58uX66aef1KVLF7Vp00ZHjx6VJMXHx6tPnz4aPHiwkpKS9MQTT2jixIm3cRavX2c7OzvFxcVp/vz5SktLU/PmzRUSEqLdu3dr48aNOn36tLp27SpJSk1NVY8ePfTCCy/o4MGD2rFjhzp16mSRfL2Vbdu26bffftM333yjGTNmKCYmRk8++aTKlCmj+Ph4DRgwQP3799d///tfSdevc3h4uFxcXPTtt98qLi5ORqNRbdq0Mc/Wvnz5sp5//nl99913+s9//iN/f3+1a9cuT9J43Lhx6tq1q3766Se1a9dOzz77rM6fP1/kc1XQveTs7Kzu3bvneSGxcOFCde7cWS4uLkXu/5VXXtHevXvVqFEjRUREmF/Y5OTkqEKFClq5cqUOHDigN954Q6+++qpWrFghSRo+fLi6du2qNm3aKDU1VampqWrcuHGeMQq7vrlu9fwnJiaajy81NdW8XJjjx49rzZo1WrdundatW6edO3cqNjY2z7ilS5dWQkKCZs2apRkzZuj999+3aDNt2jQFBwdr7969GjNmTJHGBgAAAAAAAIrLKmtg1K5dWzExMZIkf39/zZ07V1u3bpW/v3+R+5g4caKaNGkiSerTp49Gjx6t48ePq0qVKpKkzp07a/v27Ro1alSx43vhhRfM/12lShXNnj1b9evXV3p6uoxGo3lbTEyMWrVqJel60rBChQr6/PPP8yQy83Pt2jXNnTtXDRs2NO9fvXp1JSQkmBPxmZmZWrJkiby8vCRJW7Zs0b59+3TixAn5+vpKkpYsWaKaNWsqMTFR9evX16RJk9S9e3eNGzfOPFZwcLCk67P9Fy5cqJSUFJUrV07S9aTtxo0btXDhQk2ePFmzZs1SmzZtNHLkSElSQECAdu3apY0bNxb7PPr7+2vq1Knm5YkTJyokJESTJ082r/vwww/l6+urI0eOKD09XVlZWerUqZMqVaokSQoKCiryeB4eHpo9e7ZsbGwUGBioqVOn6urVq3r11VclSaNHj1ZsbKy+++47de/eXZ9++qlycnL0/vvvy2AwSLqeUHZ3d9eOHTvUunVrNW/e3GKM9957T+7u7tq5c6eefPJJ8/qoqCj16NFDkjR58mTNnj1bCQkJatOmTZFiv9W99OKLL6px48ZKTU1V2bJldebMGX311Vf6+uuvi3xuBg8erGeeeUaS9O9//1sbN27UBx98oJEjR8rW1tbifqlcubK+//57rVixQl27dpXRaJSjo6MyMjLk4+NT4Bhz58695fUNCAiQVPDz36pVK/O97u7ufsuxbpaTk6NFixaZX3T06tVLW7du1aRJk8xtfH199fbbb8tgMCgwMFD79u3T22+/rb59+5rbNG/eXK+88sotx8rIyFBGRoZ5+dKlS0WOEwAAAAAAAJCsdMZ+7dq1LZZzk5W324e3t7ecnJzMSf3cdcXtM9eePXsUERGhihUrysXFRc2aNZN0PTF+o0aNGpn/28PDQ4GBgTp48GCRxihdurTq169vXq5WrZrc3d0t9q9UqZI50SlJBw8elK+vrzmpL0k1atSw2C8pKUktWrTId8x9+/YpOztbAQEBMhqN5t/OnTt1/Phx8xi5LxvyO87iqFu3rsXyjz/+qO3bt1uMXa1aNUnXZ1wHBwerRYsWCgoKUpcuXbRgwQJduHChyOPVrFlTNjb/eyS8vb0tXgyUKlVKDz30kPm++PHHH3Xs2DG5uLiY4/Hw8NBff/1lPh+nT59W37595e/vLzc3N7m6uio9PT3PvXDj/ejs7CxXV9di3X+3upcaNGigmjVravHixZKkjz76SJUqVVLTpk1vq//SpUurXr16FvfavHnzVLduXXl5ecloNOq9997Lc4yFKez65roTz//N/Pz8LP56Ib8+Q0NDzS9wpOvn5OjRo8rOzjavq1evXqFjTZkyRW5ububfjc8jAAAAAAAAUBRWOWPf1tbWYtlgMCgnJ8eclL2x9EpBpW1u7MNgMBTYZ3FduXJF4eHhCg8P17Jly+Tl5aWUlBSFh4ff849pOjs7F3sfR0fHArelp6erVKlS2rNnj0qVKmWx7ca/RCiMjY1NnvI4+V2nm+NPT09XRESE3nzzzTxty5Ytq1KlSmnLli3atWuXuZTSa6+9pvj4eFWuXLnQuPK7B251X6Snp6tu3bpatmxZnr5yX6g8//zzOnfunGbNmqVKlSrJ3t5ejRo1ynMv3Kn7ryAvvvii5s2bp//7v//TwoUL1bt3b4sk9d+xfPlyDR8+XNOnT1ejRo3k4uKit956S/Hx8cXqp7Drm+tunKs71WdRnrnRo0fr5ZdfNi9funSJ5D4AAAAAAACKxSpn7BckN5mamppqXnfjhznvhUOHDuncuXOKjY3V448/rmrVqhU4m/g///mP+b8vXLigI0eOqHr16kUaJysrS7t37zYvHz58WGlpabfcv3r16jp16pTFR3YPHDigtLQ01ahRQ9L12dBbt27Nd/+QkBBlZ2frzJkzqlq1qsUvt+xJ9erV8yR0bzxO6fp1uvEaSUW7To8++qh+/vln+fn55Rk/N6FqMBjUpEkTjRs3Tnv37pWdnZ0+//zzQvu+HY8++qiOHj2qhx9+OE88bm5ukq5/1Hbo0KFq166datasKXt7e4uPwd4phd1Lzz33nE6ePKnZs2frwIEDev7552+7/6ysLO3Zs8fcf1xcnBo3bqyBAwcqJCREVatWtZhhL0l2dnYWM9vzU5TrWxS2traFjnU78ruv/f3987zkKoy9vb1cXV0tfgAAAAAAAEBx3FeJfUdHR4WGhio2NlYHDx7Uzp079frrr9/TGCpWrCg7OzvNmTNHv/zyi9auXasJEybk23b8+PHaunWr9u/fr6ioKHl6eqpDhw5FGsfW1lZDhgxRfHy89uzZo6ioKIWGhlp86PZmLVu2VFBQkJ599ln98MMPSkhIUGRkpJo1a2YuIRITE6NPPvlEMTExOnjwoPbt22eeQR0QEKBnn31WkZGRWr16tU6cOKGEhARNmTJF69evlyQNHTpUGzdu1LRp03T06FHNnTs3T3395s2ba/fu3VqyZImOHj2qmJgY7d+/v9BjHjRokM6fP68ePXooMTFRx48f16ZNm9S7d29lZ2crPj5ekydP1u7du5WSkqLVq1frjz/+KPLLkuJ69tln5enpqaefflrffvutTpw4oR07dmjo0KHmD+z6+/tr6dKlOnjwoOLj4/Xss8/e8q8ibldh91KZMmXUqVMnjRgxQq1bt1aFChWK1f+8efP0+eef69ChQxo0aJAuXLhg/paEv7+/du/erU2bNunIkSMaM2ZMno/W+vn56aefftLhw4d19uzZfP9Co7DrW1R+fn7aunWrfv/992KVYipMSkqKXn75ZR0+fFiffPKJ5syZo2HDht2x/gEAAAAAAICiuq8S+9L1j21mZWWpbt26io6O1sSJE+/p+F5eXlq0aJFWrlypGjVqKDY2VtOmTcu3bWxsrIYNG6a6devq999/15dffik7O7sijePk5KRRo0apZ8+eatKkiYxGoz799NNb7mMwGPTFF1+oTJkyatq0qVq2bKkqVapY7BcWFqaVK1dq7dq1qlOnjpo3b66EhATz9oULFyoyMlKvvPKKAgMD1aFDByUmJqpixYqSrtchX7BggWbNmqXg4GBt3rw5z8uV8PBwjRkzRiNHjlT9+vV1+fJlRUZGFnrM5cqVU1xcnLKzs9W6dWsFBQUpOjpa7u7usrGxkaurq7755hu1a9dOAQEBev311zV9+nS1bdu2SOe0uJycnPTNN9+oYsWK6tSpk6pXr64+ffror7/+Ms/C/uCDD3ThwgU9+uij6tWrl4YOHaqHH374jsdSlHupT58+yszMtPi4c3H6j42NVXBwsL777jutXbtWnp6ekqT+/furU6dO6tatmxo2bKhz585p4MCBFvv37dtXgYGBqlevnry8vBQXF5dnjMKub1FNnz5dW7Zska+vr0JCQop9rAWJjIzUn3/+qQYNGmjQoEEaNmyY+vXrd8f6BwAAAAAAAIrKYLq52Dn+8RYtWqTo6GilpaWVdCiwIkuXLtVLL72k3377rcgvkJKTk1W5cmXt3btXderUubsBPqAuXbp0/SO60StkY+9U0uEAAAA8MJJj25d0CAAAABZy80QXL14stHyzVX48F0DRXb16VampqYqNjVX//v2LnNQHAAAAAAAA8M9035XiudNSUlJkNBoL/KWkpNzxMdu2bVvgeJMnT77j4z0IbnUNv/3225IOr0ADBgwoMO4BAwYUqY+pU6eqWrVq8vHx0ejRoy22TZ48ucD+71YJo3utZs2aBR7jsmXLSjo8AAAAAAAAoNgoxVOIrKwsJScnF7jdz89PpUvf2T98+PXXX/Xnn3/mu83Dw0MeHh53dLwHwbFjxwrcVr58+bvyQds74cyZM7p06VK+21xdXf92vf7z58/r/Pnz+W5zdHRU+fLl/1b//wQnT57M92O9kuTt7S0XF5d7HJElSvEAAACUDErxAACAf5rilOIhsQ8AJag4/2ADAAAAAADg/lWcPBGleAAAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCIk9gEAAAAAAAAAsCKlSzoAAIBUK2aTbOydSjoMAADwAEmObV/SIQAAAOA2MWMfAAAAAAAAAAArQmIfAAAAAAAAAAArQmIfAAAAAAAAAAArQmL/HgkLC1N0dHSR2+/YsUMGg0FpaWl3LaZ/kkWLFsnd3b2kw7A61nyfJCcny2AwKCkpqaRDKVRxn18AAAAAAADgbiKxD+Cui4qKUocOHSzW+fr6KjU1VbVq1bqjYxkMBq1Zs+aO9gkAAAAAAAD8k5DYh1lmZmZJh/C3WHv8D5pSpUrJx8dHpUuXLulQ7gruRwAAAAAAANwt92ViPywsTEOHDtXIkSPl4eEhHx8fjR07VlL+5T/S0tJkMBi0Y8cOSf8rb7Jp0yaFhITI0dFRzZs315kzZ7RhwwZVr15drq6u6tmzp65evXpbMS5dulT16tWTi4uLfHx81LNnT505cyZPu7i4ONWuXVsODg4KDQ3V/v37i9R/bmmbNWvWyN/fXw4ODgoPD9epU6fMbcaOHas6dero/fffV+XKleXg4CBJSklJ0dNPPy2j0ShXV1d17dpVp0+ftuj/yy+/VP369eXg4CBPT0917NjRvC0jI0PDhw9X+fLl5ezsrIYNG5rP7Y3xVaxYUU5OTurYsaPOnTtnsT2/Gd7R0dEKCwszL4eFhWnw4MGKjo6Wp6enwsPDJUn79+9X27ZtZTQa5e3trV69euns2bPm/T777DMFBQXJ0dFRDz30kFq2bKkrV64Uek5zY5o8ebK8vb3l7u6u8ePHKysrSyNGjJCHh4cqVKighQsXWuw3atQoBQQEyMnJSVWqVNGYMWN07do1SZLJZFLLli0VHh4uk8kkSTp//rwqVKigN954o9CYchV0n1y5ckWurq767LPPLNqvWbNGzs7Ounz58i37zX1eli9frsaNG8vBwUG1atXSzp07zW2ys7PVp08fVa5cWY6OjgoMDNSsWbPM28eOHavFixfriy++kMFgMD9r+T2LhV27Wz3bkuTn5ydJ6tixowwGg3n5VnKfg6VLl8rPz09ubm7q3r17nnOTlZWlwYMHy83NTZ6enhozZoz5muWOPWHCBEVGRsrV1VX9+vUrdGwAAAAAAADgdtyXiX1JWrx4sZydnRUfH6+pU6dq/Pjx2rJlS7H6GDt2rObOnatdu3bp1KlT6tq1q2bOnKmPP/5Y69ev1+bNmzVnzpzbiu/atWuaMGGCfvzxR61Zs0bJycmKiorK027EiBGaPn26EhMT5eXlpYiICHNSuDBXr17VpEmTtGTJEsXFxSktLU3du3e3aHPs2DGtWrVKq1evVlJSknJycvT000/r/Pnz2rlzp7Zs2aJffvlF3bp1M++zfv16dezYUe3atdPevXu1detWNWjQwLx98ODB+v7777V8+XL99NNP6tKli9q0aaOjR49KkuLj49WnTx8NHjxYSUlJeuKJJzRx4sTbOIvXr7OdnZ3i4uI0f/58paWlqXnz5goJCdHu3bu1ceNGnT59Wl27dpUkpaamqkePHnrhhRd08OBB7dixQ506dbJI0N7Ktm3b9Ntvv+mbb77RjBkzFBMToyeffFJlypRRfHy8BgwYoP79++u///2veR8XFxctWrRIBw4c0KxZs7RgwQK9/fbbkq6XjVm8eLESExM1e/ZsSdKAAQNUvnz5YiX2C7pPnJ2d1b179zwvGxYuXKjOnTvLxcWlyP2/8sor2rt3rxo1aqSIiAjzy5icnBxVqFBBK1eu1IEDB/TGG2/o1Vdf1YoVKyRJw4cPV9euXdWmTRulpqYqNTVVjRs3zjNGYdcu162e7cTERPPxpaammpcLc/z4ca1Zs0br1q3TunXrtHPnTsXGxuYZt3Tp0kpISNCsWbM0Y8YMvf/++xZtpk2bpuDgYO3du1djxozJd6yMjAxdunTJ4gcAAAAAAAAUx/1ZA0NS7dq1FRMTI0ny9/fX3LlztXXrVvn7+xe5j4kTJ6pJkyaSpD59+mj06NE6fvy4qlSpIknq3Lmztm/frlGjRhU7vhdeeMH831WqVNHs2bNVv359paeny2g0mrfFxMSoVatWkq4nFitUqKDPP/88T7IzP9euXdPcuXPVsGFD8/7Vq1dXQkKCORGfmZmpJUuWyMvLS5K0ZcsW7du3TydOnJCvr68kacmSJapZs6YSExNVv359TZo0Sd27d9e4cePMYwUHB0u6Ptt/4cKFSklJUbly5SRdT+xu3LhRCxcu1OTJkzVr1iy1adNGI0eOlCQFBARo165d2rhxY7HPo7+/v6ZOnWpenjhxokJCQjR58mTzug8//FC+vr46cuSI0tPTlZWVpU6dOqlSpUqSpKCgoCKP5+HhodmzZ8vGxkaBgYGaOnWqrl69qldffVWSNHr0aMXGxuq7774zv0R5/fXXzfv7+flp+PDhWr58ufn4y5cvr3fffVeRkZH6/fff9dVXX2nv3r3FKlFzq/vkxRdfVOPGjZWamqqyZcvqzJkz+uqrr/T1118Xuf/BgwfrmWeekST9+9//1saNG/XBBx9o5MiRsrW1tbgXKleurO+//14rVqxQ165dZTQa5ejoqIyMDPn4+BQ4xty5c2957QICAiQV/Gy3atXKfB+7u7vfcqyb5eTkaNGiReYXHb169dLWrVs1adIkcxtfX1+9/fbbMhgMCgwM1L59+/T222+rb9++5jbNmzfXK6+8csuxpkyZYnG+AAAAAAAAgOK6b2fs165d22I5N6F5u314e3ubS6ncuK64febas2ePIiIiVLFiRbm4uKhZs2aSrifGb9SoUSPzf3t4eCgwMFAHDx4s0hilS5dW/fr1zcvVqlWTu7u7xf6VKlUyJ0Ml6eDBg/L19TUn9SWpRo0aFvslJSWpRYsW+Y65b98+ZWdnKyAgQEaj0fzbuXOnjh8/bh4j92VDfsdZHHXr1rVY/vHHH7V9+3aLsatVqybp+qzs4OBgtWjRQkFBQerSpYsWLFigCxcuFHm8mjVrysbmf4+Nt7e3xYuBUqVK6aGHHrK4Lz799FM1adJEPj4+MhqNev311/Nc5y5duqhjx46KjY3VtGnTivUCSrr1fdKgQQPVrFlTixcvliR99NFHqlSpkpo2bXpb/ZcuXVr16tWzuI/mzZununXrysvLS0ajUe+9916eYyxMYdcu1514tm/m5+dn8dcL+fUZGhoqg8FgXm7UqJGOHj2q7Oxs87p69eoVOtbo0aN18eJF8+/G8lgAAAAAAABAUdy3M/ZtbW0tlg0Gg3JycsxJ2RtLrxRU2ubGPgwGQ4F9FteVK1cUHh6u8PBwLVu2TF5eXkpJSVF4ePg9/+Cms7NzsfdxdHQscFt6erpKlSqlPXv2qFSpUhbbbvxLhMLY2NjkKY+T33W6Of709HRFRETozTffzNO2bNmyKlWqlLZs2aJdu3aZSym99tprio+PV+XKlQuNK7974Fb3xffff69nn31W48aNU3h4uNzc3LR8+XJNnz7dYp+rV6+az1luyaI76cUXX9S8efP0f//3f1q4cKF69+5tkaT+O5YvX67hw4dr+vTpatSokVxcXPTWW28pPj6+WP0Udu1y3ann8EZ3qs+iPE/29vayt7cvdt8AAAAAAABArvt2xn5Bcmenp6ammtfd+PHOe+HQoUM6d+6cYmNj9fjjj6tatWoFzjj+z3/+Y/7vCxcu6MiRI6pevXqRxsnKytLu3bvNy4cPH1ZaWtot969evbpOnTplMYv4wIEDSktLU40aNSRdnzG9devWfPcPCQlRdna2zpw5o6pVq1r8ckujVK9ePU/S98bjlK5fpxuvkVS06/Too4/q559/lp+fX57xc5OuBoNBTZo00bhx47R3717Z2dnp888/L7Tv27Fr1y5VqlRJr732murVqyd/f3+dPHkyT7tXXnlFNjY22rBhg2bPnq1t27YVa5zC7pPnnntOJ0+e1OzZs3XgwAE9//zzt91/VlaW9uzZY+4/Li5OjRs31sCBAxUSEqKqVatazLCXJDs7O4uZ7fkpyrUrCltb20LHuh353bP+/v55XmABAAAAAAAAd9sDl9h3dHRUaGioYmNjdfDgQe3cudOiBvq9ULFiRdnZ2WnOnDn65ZdftHbtWk2YMCHftuPHj9fWrVu1f/9+RUVFydPTUx06dCjSOLa2thoyZIji4+O1Z88eRUVFKTQ01OJDtzdr2bKlgoKC9Oyzz+qHH35QQkKCIiMj1axZM3OZkZiYGH3yySeKiYnRwYMHtW/fPvMs64CAAD377LOKjIzU6tWrdeLECSUkJGjKlClav369JGno0KHauHGjpk2bpqNHj2ru3Ll56us3b95cu3fv1pIlS3T06FHFxMRo//79hR7zoEGDdP78efXo0UOJiYk6fvy4Nm3apN69eys7O1vx8fGaPHmydu/erZSUFK1evVp//PFHkV+WFJe/v79SUlK0fPlyHT9+XLNnz87zEmH9+vX68MMPtWzZMrVq1UojRozQ888/X6wSQYXdJ2XKlFGnTp00YsQItW7dWhUqVCjWccybN0+ff/65Dh06pEGDBunChQvm70T4+/tr9+7d2rRpk44cOaIxY8bk+Witn5+ffvrpJx0+fFhnz57N968vCrt2ReXn56etW7fq999/L9Y5LExKSopefvllHT58WJ988onmzJmjYcOG3bH+AQAAAAAAgKJ64BL70vUPcmZlZalu3bqKjo7WxIkT7+n4Xl5eWrRokVauXKkaNWqY66rnJzY2VsOGDVPdunX1+++/68svv5SdnV2RxnFyctKoUaPUs2dPNWnSREajUZ9++ukt9zEYDPriiy9UpkwZNW3aVC1btlSVKlUs9gsLC9PKlSu1du1a1alTR82bN1dCQoJ5+8KFCxUZGalXXnlFgYGB6tChgxITE1WxYkVJ12uVL1iwQLNmzVJwcLA2b96c5+VKeHi4xowZo5EjR6p+/fq6fPmyIiMjCz3mcuXKKS4uTtnZ2WrdurWCgoIUHR0td3d32djYyNXVVd98843atWungIAAvf7665o+fbratm1bpHNaXE899ZReeuklDR48WHXq1NGuXbs0ZswY8/Y//vhDffr00dixY/Xoo49KksaNGydvb28NGDCgyOMU5T7p06ePMjMzLT7cXJz+Y2NjFRwcrO+++05r166Vp6enJKl///7q1KmTunXrpoYNG+rcuXMaOHCgxf59+/ZVYGCg6tWrJy8vL8XFxeUZo7BrV1TTp0/Xli1b5Ovrq5CQkGIfa0EiIyP1559/qkGDBho0aJCGDRumfv363bH+AQAAAAAAgKIymG4uZI77wqJFixQdHa20tLSSDgX/EEuXLtVLL72k3377rcgvh5KTk1W5cmXt3btXderUubsBPqAuXbokNzc3+UavkI29U0mHAwAAHiDJse1LOgQAAADcIDdPdPHiRbm6ut6y7X378VwA1129elWpqamKjY1V//79i5zUBwAAAAAAAPDP9ECW4rnTUlJSZDQaC/ylpKTc8THbtm1b4HiTJ0++4+M9CG51Db/99tsSiWnAgAEFxlTUUj1Tp05VtWrV5OPjo9GjR1tsmzx5coH9363yRPdazZo1CzzGZcuWlXR4AAAAAAAAQLFRiucOyMrKUnJycoHb/fz8VLr0nf3jiF9//VV//vlnvts8PDzk4eFxR8d7EBw7dqzAbeXLl5ejo+M9jOa6M2fO6NKlS/luc3V11cMPP/y3+j9//rzOnz+f7zZHR0eVL1/+b/X/T3Dy5Ml8P9YrSd7e3nJxcbnHEVmiFA8AACgplOIBAAD4ZylOKR4S+wBQgorzDzYAAAAAAADuX8XJE1GKBwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK0JiHwAAAAAAAAAAK1K6pAMAAEi1YjbJxt6ppMMAAABWKDm2fUmHAAAAgHuMGfsAAAAAAAAAAFgREvsAAAAAAAAAAFgREvsAAAAAAAAAAFgREvsosrCwMEVHR5uX/fz8NHPmzLs65o4dO2QwGJSWlnZXx7FWUVFR6tChQ0mHcVvGjh2rOnXqlHQYhUpOTpbBYFBSUlJJhwIAAAAAAABIIrGPvyExMVH9+vW7Y/3d/OJAkho3bqzU1FS5ubndsXFw7xkMBq1Zs8Zi3fDhw7V169Y7Os6iRYvk7u5+R/sEAAAAAAAA/mlKl3QAsF5eXl53fQw7Ozv5+Pjc9XFw7xmNRhmNxpIO464wmUzKzs5W6dL8EwsAAAAAAIA7jxn7xRAWFqahQ4dq5MiR8vDwkI+Pj8aOHSsp/3IdaWlpMhgM2rFjh6T/lZXZtGmTQkJC5OjoqObNm+vMmTPasGGDqlevLldXV/Xs2VNXr14tckxDhgxRdHS0ypQpI29vby1YsEBXrlxR79695eLioqpVq2rDhg0W++3fv19t27aV0WiUt7e3evXqpbNnz5q3X7lyRZGRkTIajSpbtqymT5+eZ+ybS/GkpaWpf//+8vb2loODg2rVqqV169ZJks6dO6cePXqofPnycnJyUlBQkD755BPzvlFRUdq5c6dmzZolg8Egg8Gg5OTkfEvxrFq1SjVr1pS9vb38/PzyxObn56fJkyfrhRdekIuLiypWrKj33nvPvD0zM1ODBw9W2bJl5eDgoEqVKmnKlCmFnmuTyaSxY8eqYsWKsre3V7ly5TR06FDz9vxmpbu7u2vRokWS/nePrFixQo8//rgcHR1Vv359HTlyRImJiapXr56MRqPatm2rP/74o9B4bjRu3Dh5eXnJ1dVVAwYMUGZmpiRpyZIleuihh5SRkWHRvkOHDurVq1eh/eaWy3n33Xfl6+srJycnde3aVRcvXjS3SUxMVKtWreTp6Sk3Nzc1a9ZMP/zwg3m7n5+fJKljx44yGP4fe3ceV1W1/3/8fQRB8DCIGqiBaIKiIYlaojc15yGvQ4mpV8XUMnOgRM2bA85kYU43M1NwKrMcssyRK6aoOJsDThRhRXpTUXEG/P3hj/31COLBMMRez8fjPB6cs9de67OHwx+fvc5nmYz3OZXi+fTTT+Xn56dixYqpSpUq+uijj4xtWedv+fLleuGFF+To6KiAgABt375d0u3vV8+ePXXhwgXjHsr6fubmfvdLlqNHj6pu3brGvb1582ZjW9Z9umbNGtWsWVP29vbaunXrfccGAAAAAAAAHgSJ/TyaP3++ihcvrvj4eE2ePFljx47Vhg0b8tRHeHi4Zs6cqW3btunUqVMKDg7W1KlT9dlnn2n16tVav369ZsyYkaeYSpUqpZ07d2rAgAF644031LFjR9WtW1d79+5Vs2bN1K1bN+NhQWpqqho1aqQaNWpo9+7dWrt2rU6fPq3g4GCjzyFDhmjz5s36+uuvtX79esXGxloka++WmZmpli1bKi4uTosWLdKRI0cUEREhGxsbSdK1a9dUs2ZNrV69WocOHdJrr72mbt26aefOnZKkadOmKSgoSH369FFKSopSUlLk6emZbZw9e/YoODhYr7zyig4ePKjw8HCNHDnSSJ5niYyMVK1atbRv3z7169dPb7zxho4dOyZJmj59ulatWqWlS5fq2LFjWrx4sZFszs2yZcv04Ycfavbs2Tpx4oRWrlwpf3//++53t9GjR2vEiBHau3evbG1t1aVLFw0dOlTTpk3Tli1bdPLkSY0aNcrq/mJiYpSQkKDY2Fh9/vnnWr58ucaMGSNJ6tixozIyMrRq1Sqj/ZkzZ7R69Wq9+uqrVvV/8uRJLV26VN98843Wrl1rnNMsly5dUo8ePbR161bt2LFDPj4+atWqlS5duiTpduJfkqKiopSSkmK8v9vixYs1atQoTZgwQQkJCZo4caJGjhyp+fPnW7R79913FRYWpv3798vX11edO3dWenq66tatq6lTp8rZ2dm4h8LCwqw6xtzulyxDhgzR4MGDtW/fPgUFBalNmzY6e/asRZt33nlHERERSkhIUPXq1XMc6/r167p48aLFCwAAAAAAAMgL6kTkUfXq1TV69GhJko+Pj2bOnKmYmBj5+PhY3cf48eNVr149SVKvXr00fPhwJSYmqmLFipKkl19+WZs2bdKwYcOs6i8gIEAjRoyQJA0fPlwREREqVaqU+vTpI0kaNWqUZs2apR9++EF16tTRzJkzVaNGDU2cONHoY968efL09NTx48dVtmxZzZ07V4sWLVLjxo0l3X548OSTT94zho0bN2rnzp1KSEiQr6+vJBnHI0nlypWzSLIOGDBA69at09KlS/Xss8/KxcVFdnZ2cnR0zLX0zpQpU9S4cWONHDlSkuTr66sjR47o/fffV0hIiNGuVatWRvJ52LBh+vDDD7Vp0yZVrlxZycnJ8vHx0T/+8Q+ZTCaVL1/eqvOcnJwsDw8PNWnSREWLFpWXl5eeffZZq/a9U1hYmJo3by5JGjRokDp37qyYmBiLe+LuBxW5sbOz07x58+To6Khq1app7NixGjJkiMaNGycHBwd16dJFUVFR6tixoyRp0aJF8vLyUsOGDa3q/9q1a1qwYIHKlSsnSZoxY4Zat26tyMhIeXh4qFGjRhbtP/nkE7m6umrz5s168cUXjZJNrq6uuV7b0aNHKzIyUh06dJAkVahQQUeOHNHs2bPVo0cPo11YWJhat24t6fYvFapVq6aTJ0+qSpUqcnFxkclkynP5ptzulyz9+/fXSy+9JEmaNWuW1q5dq7lz52ro0KFGm7Fjx6pp06a5jjVp0iTjwQsAAAAAAADwIJixn0d3z8ItU6aMzpw588B9uLu7y9HR0SIJ7u7unqc+7+zPxsZGJUuWtJhJ7u7uLklGnwcOHNCmTZuMGudms1lVqlSRJCUmJioxMVE3btzQc889Z/Th5uZmkeS82/79+/Xkk08aSf27ZWRkaNy4cfL395ebm5vMZrPWrVun5ORkq49TkhISEowEeJZ69erpxIkTysjIMD6785xkJXqzjj8kJET79+9X5cqVNXDgQK1fv96qsTt27KirV6+qYsWK6tOnj1asWKH09PQ8xX93bFnX5u7rlZfrHxAQIEdHR+N9UFCQ0tLSdOrUKUlSnz59tH79ev3666+Sbi8wGxISIpPJZFX/Xl5eRlI/q//MzExjRvvp06fVp08f+fj4yMXFRc7OzkpLS8vTtb18+bISExPVq1cvi/ty/PjxSkxMtGh75/krU6aMJOX5O3i33O6XLEFBQcbftra2qlWrlhISEiza1KpV675jDR8+XBcuXDBeWdcJAAAAAAAAsBYz9vOoaNGiFu9NJpMyMzNVpMjtZyS3bt0ytt28efO+fZhMpnv2+WdiunsMSUafaWlpatOmjd57771sfZUpU0YnT560euwsDg4OuW5///33NW3aNE2dOlX+/v4qXry4QkNDjVrw+S23cxoYGKiffvpJa9as0caNGxUcHKwmTZroq6++yrVPT09PHTt2TBs3btSGDRvUr18/vf/++9q8ebOKFi0qk8lkcf2lnO+BnK7N3Z/l5frfT40aNRQQEKAFCxaoWbNmOnz4sFavXp1v/ffo0UNnz57VtGnTVL58ednb2ysoKChP1zYtLU2SNGfOHIsHSpKMck5Zcru3H9Sf/Q5mKV68+H3b2Nvby97ePs99AwAAAAAAAFmYsZ9PssqNpKSkGJ/duZDuoyQwMFCHDx+Wt7e3KlWqZPEqXry4nnrqKRUtWlTx8fHGPufPn9fx48fv2Wf16tX1yy+/3LNNXFyc2rZtq3/9618KCAhQxYoVs7W1s7OzmHWfEz8/P8XFxWXr29fXN1sCODfOzs7q1KmT5syZoy+++ELLli3TuXPn7rufg4OD2rRpo+nTpys2Nlbbt2/XwYMHJd2+B+68/idOnLB6EeQ/48CBA7p69arxfseOHTKbzRZrFPTu3VvR0dGKiopSkyZNcly/4F6Sk5P122+/WfRfpEgR4xcccXFxGjhwoFq1amUsanznQszS7cR5btfW3d1dZcuW1Y8//pjtnqxQoYLVsVpzDz2oHTt2GH+np6drz5498vPzeyhjAQAAAAAAALlhxn4+cXBwUJ06dRQREaEKFSrozJkzRt37R82bb76pOXPmqHPnzho6dKjc3Nx08uRJLVmyRJ9++qnMZrN69eqlIUOGqGTJknriiSf07rvvGr9KyEmDBg1Uv359vfTSS5oyZYoqVaqko0ePymQyqUWLFvLx8dFXX32lbdu2qUSJEpoyZYpOnz6tqlWrGn14e3srPj5eSUlJMpvNcnNzyzbO4MGDVbt2bY0bN06dOnXS9u3bNXPmTH300UdWH/+UKVNUpkwZ1ahRQ0WKFNGXX34pDw8Pubq65rpfdHS0MjIy9Nxzz8nR0VGLFi2Sg4ODUaO/UaNGmjlzpoKCgpSRkaFhw4Zlmwn+MNy4cUO9evXSiBEjlJSUpNGjR6t///4W16tLly4KCwvTnDlztGDBgjz1X6xYMfXo0UMffPCBLl68qIEDByo4ONioY+/j46OFCxeqVq1aunjxooYMGZLtFxze3t7GOgL29vYqUaJEtnHGjBmjgQMHysXFRS1atND169e1e/dunT9/Xm+//bZVsXp7eystLU0xMTFGiaI7yxT9Gf/5z3/k4+MjPz8/ffjhhzp//rzVCxADAAAAAAAA+YkZ+/lo3rx5Sk9PV82aNRUaGqrx48cXdEg5Klu2rOLi4pSRkaFmzZrJ399foaGhcnV1NZLB77//vp5//nm1adNGTZo00T/+8Q/VrFkz136XLVum2rVrq3PnzqpataqGDh1qzJ4eMWKEAgMD1bx5czVs2FAeHh5q166dxf5hYWGysbFR1apVVbp06RxrtAcGBmrp0qVasmSJnn76aY0aNUpjx461WDj3fpycnDR58mTVqlVLtWvXVlJSkr777rtcH1xItxd/nTNnjurVq6fq1atr48aN+uabb1SyZElJUmRkpDw9PfX8888bifT8SirnpnHjxvLx8VH9+vXVqVMn/fOf/1R4eLhFGxcXF7300ksym83Zzvv9VKpUSR06dFCrVq3UrFkzVa9e3eJByty5c3X+/HkFBgaqW7duGjhwoJ544gmLPiIjI7VhwwZ5enqqRo0aOY7Tu3dvffrpp4qKipK/v78aNGig6OjoPM3Yr1u3rvr27atOnTqpdOnSmjx5cp6ONTcRERGKiIhQQECAtm7dqlWrVqlUqVL51j8AAAAAAABgLdOtu4uCA3gsNW7cWNWqVdP06dOt3ic8PFwrV658ZMtKPQ4uXrwoFxcXeYYuVRH7h/8gCAAAPH6SIloXdAgAAADIB1l5ogsXLsjZ2TnXtpTiAR5z58+fV2xsrGJjY/NUsggAAAAAAADAo4nE/iMsOTnZogb93Y4cOSIvL6+/MKLH2+LFi/X666/nuK18+fI6fPjwXxyRZDab77ltzZo1ev755+/bR40aNXT+/Hm99957xoK3WapVq6aff/45x/1mz56dt2AfQVu2bFHLli3vuT0tLe0vjAYAAAAAAADIH5TieYSlp6crKSnpntu9vb1la8uzmfxy6dIlnT59OsdtRYsWNRbJ/SudPHnyntvKlSuXbZHavPr555918+bNHLe5u7vLycnpT/Vf0K5evapff/31ntsrVar0F0aTM0rxAACAP4tSPAAAAI+HvJTiIbEPAAUoL/+wAQAAAAAA8PjKS56oyF8UEwAAAAAAAAAAyAck9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8AAAAAAAAAgEKExD4AAAAAAAAAAIUIiX0AAAAAAAAAAAoREvsAAAAAAAAAABQiJPYBAAAAAAAAAChESOwDAAAAAAAAAFCIkNgHAAAAAAAAAKAQIbEPAAAAAAAAAEAhQmIfAAAAAAAAAIBChMQ+AAAAAAAAAACFCIl9AAAAAAAAAAAKERL7AAAAAAAAAAAUIrYFHQAAQHp69DoVsXcs6DAAAEABSYpoXdAhAAAAoBBhxj4AAAAAAAAAAIUIiX0AAAAAAAAAAAoREvsAAAAAAAAAABQiJPahhg0bKjQ01Hjv7e2tqVOnPtQxY2NjZTKZlJqa+lDHedyFhISoXbt2BR3GAwkPD9czzzxT0GHcV1JSkkwmk/bv31/QoQAAAAAAAACSSOwjB7t27dJrr72Wb/3d/eBAkurWrauUlBS5uLjk2zh4dJlMJq1cudLis7CwMMXExOTrONHR0XJ1dc3XPgEAAAAAAIBHjW1BB4BHT+nSpR/6GHZ2dvLw8Hjo4+DRZTabZTabCzqMh+LWrVvKyMiQrS3/YgEAAAAAAJD/mLGv2zPKBw4cqKFDh8rNzU0eHh4KDw+XlHMZjtTUVJlMJsXGxkr6v7Iy69atU40aNeTg4KBGjRrpzJkzWrNmjfz8/OTs7KwuXbroypUrVsc0YMAAhYaGqkSJEnJ3d9ecOXN0+fJl9ezZU05OTqpUqZLWrFljsd+hQ4fUsmVLmc1mubu7q1u3bvrjjz+M7ZcvX1b37t1lNptVpkwZRUZGZhv77lI8qampev311+Xu7q5ixYrp6aef1rfffitJOnv2rDp37qxy5crJ0dFR/v7++vzzz419Q0JCtHnzZk2bNk0mk0kmk0lJSUk5luJZtmyZqlWrJnt7e3l7e2eLzdvbWxMnTtSrr74qJycneXl56ZNPPjG237hxQ/3791eZMmVUrFgxlS9fXpMmTbLqfJtMJs2ePVsvvviiHB0d5efnp+3bt+vkyZNq2LChihcvrrp16yoxMdFiv6+//lqBgYEqVqyYKlasqDFjxig9Pd3YPmXKFPn7+6t48eLy9PRUv379lJaWZmzPmmG+bt06+fn5yWw2q0WLFkpJSbEq7ixjxoxR6dKl5ezsrL59++rGjRuSpAULFqhkyZK6fv26Rft27dqpW7du9+03q1zO7Nmz5enpKUdHRwUHB+vChQtGm127dqlp06YqVaqUXFxc1KBBA+3du9fY7u3tLUlq3769TCaT8T6nUjyffvqp/Pz8VKxYMVWpUkUfffSRsS3ru7h8+XK98MILcnR0VEBAgLZv3y7p9vewZ8+eunDhgnGvZX2Pc3O/+yrL0aNHVbduXeM7sHnzZmNb1v28Zs0a1axZU/b29tq6det9xwYAAAAAAAAeBIn9/2/+/PkqXry44uPjNXnyZI0dO1YbNmzIUx/h4eGaOXOmtm3bplOnTik4OFhTp07VZ599ptWrV2v9+vWaMWNGnmIqVaqUdu7cqQEDBuiNN95Qx44dVbduXe3du1fNmjVTt27djIcFqampatSokWrUqKHdu3dr7dq1On36tIKDg40+hwwZos2bN+vrr7/W+vXrFRsba5GEvVtmZqZatmypuLg4LVq0SEeOHFFERIRsbGwkSdeuXVPNmjW1evVqHTp0SK+99pq6deumnTt3SpKmTZumoKAg9enTRykpKUpJSZGnp2e2cfbs2aPg4GC98sorOnjwoMLDwzVy5EhFR0dbtIuMjFStWrW0b98+9evXT2+88YaOHTsmSZo+fbpWrVqlpUuX6tixY1q8eLGRRLbGuHHj1L17d+3fv19VqlRRly5d9Prrr2v48OHavXu3bt26pf79+xvtt2zZou7du2vQoEE6cuSIZs+erejoaE2YMMFoU6RIEU2fPl2HDx/W/Pnz9d///ldDhw61GPfKlSv64IMPtHDhQn3//fdKTk5WWFiY1XHHxMQoISFBsbGx+vzzz7V8+XKNGTNGktSxY0dlZGRo1apVRvszZ85o9erVevXVV63q/+TJk1q6dKm++eYbrV271jj3WS5duqQePXpo69at2rFjh3x8fNSqVStdunRJ0u3EvyRFRUUpJSXFeH+3xYsXa9SoUZowYYISEhI0ceJEjRw5UvPnz7do9+677yosLEz79++Xr6+vOnfurPT0dNWtW1dTp06Vs7Ozca9Zex5zu6+yDBkyRIMHD9a+ffsUFBSkNm3a6OzZsxZt3nnnHUVERCghIUHVq1fPcazr16/r4sWLFi8AAAAAAAAgL6gT8f9Vr15do0ePliT5+Pho5syZiomJkY+Pj9V9jB8/XvXq1ZMk9erVS8OHD1diYqIqVqwoSXr55Ze1adMmDRs2zKr+AgICNGLECEnS8OHDFRERoVKlSqlPnz6SpFGjRmnWrFn64YcfVKdOHc2cOVM1atTQxIkTjT7mzZsnT09PHT9+XGXLltXcuXO1aNEiNW7cWNLthwdPPvnkPWPYuHGjdu7cqYSEBPn6+kqScTySVK5cOYvk6YABA7Ru3TotXbpUzz77rFxcXGRnZydHR8dcS+9MmTJFjRs31siRIyVJvr6+OnLkiN5//32FhIQY7Vq1amUklYcNG6YPP/xQmzZtUuXKlZWcnCwfHx/94x//kMlkUvny5a06z1l69uxpPAQZNmyYgoKCNHLkSDVv3lySNGjQIPXs2dNoP2bMGL3zzjvq0aOHcV7GjRunoUOHGvfS3YsSjx8/Xn379rWYiX7z5k19/PHHeuqppyRJ/fv319ixY62O287OTvPmzZOjo6OqVaumsWPHasiQIRo3bpwcHBzUpUsXRUVFqWPHjpKkRYsWycvLSw0bNrSq/2vXrmnBggUqV66cJGnGjBlq3bq1IiMj5eHhoUaNGlm0/+STT+Tq6qrNmzfrxRdfNEo7ubq65noPjB49WpGRkerQoYMkqUKFCsYDk6xzLN2uzd+6dWtJt69BtWrVdPLkSVWpUkUuLi4ymUx5LvOU232VpX///nrppZckSbNmzdLatWs1d+5ciwc1Y8eOVdOmTXMda9KkScaDFwAAAAAAAOBBMGP//7t7dm2ZMmV05syZB+7D3d1djo6OFklwd3f3PPV5Z382NjYqWbKk/P39LfqTZPR54MABbdq0yahdbjabVaVKFUlSYmKiEhMTdePGDT333HNGH25ubhbJy7vt379fTz75pJHUv1tGRobGjRsnf39/ubm5yWw2a926dUpOTrb6OCUpISHBeCiSpV69ejpx4oQyMjKMz+48J1kJ3KzjDwkJ0f79+1W5cmUNHDhQ69evz1MMd18/SdnO97Vr14wZ1gcOHNDYsWMtznfWLxOyfkWxceNGNW7cWOXKlZOTk5O6deums2fPWpRkcnR0NJL6Ut7vvYCAADk6Ohrvg4KClJaWplOnTkmS+vTpo/Xr1+vXX3+VdLv8T0hIiEwmk1X9e3l5GUn9rP4zMzONGe2nT59Wnz595OPjIxcXFzk7OystLS1P98Dly5eVmJioXr16WZzP8ePHZyt/dOd1KlOmjCTl+bt6t9zuqyxBQUHG37a2tqpVq5YSEhIs2tSqVeu+Yw0fPlwXLlwwXlnXCQAAAAAAALAWM/b/v6JFi1q8N5lMyszMVJEit5993Lp1y9h28+bN+/ZhMpnu2eefienuMSQZfaalpalNmzZ67733svVVpkwZnTx50uqxszg4OOS6/f3339e0adM0depUo5Z8aGioUeM9v+V2TgMDA/XTTz9pzZo12rhxo4KDg9WkSRN99dVXee4769ze73yPGTPGmGF+p2LFiikpKUkvvvii3njjDU2YMEFubm7aunWrevXqpRs3bhjJ+JyO6c777c+qUaOGAgICtGDBAjVr1kyHDx/W6tWr863/Hj166OzZs5o2bZrKly8ve3t7BQUF5ekeyFp3YM6cORYPniQZZZ+y5HZNHtSf/a5mKV68+H3b2Nvby97ePs99AwAAAAAAAFlI7N9HVhmRlJQU1ahRQ5IsFtJ9lAQGBmrZsmXy9vaWrW32S/vUU0+paNGiio+Pl5eXlyTp/PnzOn78uBo0aJBjn9WrV9cvv/yi48eP5zhrPy4uTm3bttW//vUvSbcTrMePH1fVqlWNNnZ2dhaz7nPi5+enuLi4bH37+vpmS+zmxtnZWZ06dVKnTp308ssvq0WLFjp37pzc3Nys7sNagYGBOnbsmCpVqpTj9j179igzM1ORkZHGA6KlS5fmexwHDhzQ1atXjYcwO3bskNlstljLoHfv3po6dap+/fVXNWnSJMd1Du4lOTlZv/32m8qWLWv0X6RIEeOXHnFxcfroo4/UqlUrSdKpU6csFmyWbifOc7sH3N3dVbZsWf3444/q2rWr1bHdzZp77UHt2LFD9evXlySlp6drz549FmsuAAAAAAAAAH8VSvHch4ODg+rUqWMsiLl582aj7v2j5s0339S5c+fUuXNn7dq1S4mJiVq3bp169uypjIwMmc1m9erVS0OGDNF///tfHTp0SCEhIUbSOScNGjRQ/fr19dJLL2nDhg3GjPi1a9dKur0ewYYNG7Rt2zYlJCTo9ddf1+nTpy368Pb2Vnx8vJKSkvTHH3/kOBN68ODBiomJ0bhx43T8+HHNnz9fM2fOzNMislOmTNHnn3+uo0eP6vjx4/ryyy/l4eEhV1dXq/vIi1GjRmnBggUaM2aMDh8+rISEBC1ZssS4PypVqqSbN29qxowZ+vHHH7Vw4UJ9/PHH+R7HjRs31KtXLx05ckTfffedRo8erf79+1tc1y5duuiXX37RnDlzrF40N0uxYsXUo0cPHThwQFu2bNHAgQMVHBxs1LH38fHRwoULlZCQoPj4eHXt2jXbLz28vb0VExOj33//XefPn89xnDFjxmjSpEmaPn26jh8/roMHDyoqKkpTpkyxOlZvb2+lpaUpJiZGf/zxh0XJoz/rP//5j1asWKGjR4/qzTff1Pnz5/N8LgEAAAAAAID8QGLfCvPmzVN6erpq1qyp0NBQjR8/vqBDylHZsmUVFxenjIwMNWvWTP7+/goNDZWrq6uR5H3//ff1/PPPq02bNmrSpIn+8Y9/qGbNmrn2u2zZMtWuXVudO3dW1apVNXToUGNW9IgRIxQYGKjmzZurYcOG8vDwULt27Sz2DwsLk42NjapWrarSpUvnWHs9MDBQS5cu1ZIlS/T0009r1KhRGjt2rMXCuffj5OSkyZMnq1atWqpdu7aSkpL03Xff5frg4s9o3ry5vv32W61fv161a9dWnTp19OGHHxqL9gYEBGjKlCl677339PTTT2vx4sWaNGlSvsfRuHFj+fj4qH79+urUqZP++c9/Kjw83KKNi4uLXnrpJZnN5mzX534qVaqkDh06qFWrVmrWrJmqV69usfjv3Llzdf78eQUGBqpbt24aOHCgnnjiCYs+IiMjtWHDBnl6ehq/fLlb79699emnnyoqKkr+/v5q0KCBoqOjVaFCBatjrVu3rvr27atOnTqpdOnSmjx5cp6ONTcRERGKiIhQQECAtm7dqlWrVqlUqVL51j8AAAAAAABgLdOt/CzmDeCR1bhxY1WrVk3Tp0+3ep/w8HCtXLnykS0/9Ti4ePGiXFxc5Bm6VEXsHe+/AwAAeCwlRbQu6BAAAABQwLLyRBcuXJCzs3OubamxDzzmzp8/r9jYWMXGxlrMtAcAAAAAAABQOJHYLwDJyckWi8ve7ciRI8bitvjzFi9erNdffz3HbeXLl9fhw4f/4oisZzab77ltzZo1ev755+/bR40aNXT+/Hm99957xoK3WapVq6aff/45x/1mz56dt2AfQVu2bFHLli3vuT0tLe0vjAYAAAAAAADIH5TiKQDp6elKSkq653Zvb2/Z2vLMJb9cunQp24K+WYoWLWrUxH8UnTx58p7bypUrl22R2rz6+eefdfPmzRy3ubu7y8nJ6U/1X9CuXr2qX3/99Z7bK1Wq9BdGkzNK8QAAAIlSPAAAAMhbKR4S+wBQgPLyDxsAAAAAAACPr7zkiYr8RTEBAAAAAAAAAIB8QGIfAAAAAAAAAIBChMQ+AAAAAAAAAACFCIl9AAAAAAAAAAAKERL7AAAAAAAAAAAUIiT2AQAAAAAAAAAoREjsAwAAAAAAAABQiJDYBwAAAAAAAACgECGxDwAAAAAAAABAIUJiHwAAAAAAAACAQoTEPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIk9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFiW9ABAACkp0evUxF7x4IOAwAAWCEponVBhwAAAIC/OWbsAwAAAAAAAABQiJDYBwAAAAAAAACgECGxDwAAAAAAAABAIUJi/y4NGzZUaGio1e1jY2NlMpmUmpr60GJ6lERHR8vV1bWgw3hkhISEqF27dsb7vN4/f1Z4eLieeeaZv2y8/FSY7iWTyaSVK1cWdBgAAAAAAACAJBL7QL5avny5xo0bV9BhPHK8vb01depUi886deqk48eP5+s4f7cHbQAAAAAAAPh7si3oAJB3N27ckJ2dXUGH8cAKe/y5cXNzK+gQCg0HBwc5ODgUdBgPzc2bN1W0aNGCDgMAAAAAAACPoQKdsd+wYUMNHDhQQ4cOlZubmzw8PBQeHi5JSkpKkslk0v79+432qampMplMio2NlfR/s3PXrVunGjVqyMHBQY0aNdKZM2e0Zs0a+fn5ydnZWV26dNGVK1ceKMaFCxeqVq1acnJykoeHh7p06aIzZ85kaxcXF6fq1aurWLFiqlOnjg4dOmRV/1nlSFauXCkfHx8VK1ZMzZs316lTp4w2WeVWPv30U1WoUEHFihWTJCUnJ6tt27Yym81ydnZWcHCwTp8+bdH/N998o9q1a6tYsWIqVaqU2rdvb2y7fv26wsLCVK5cORUvXlzPPfeccW7vjM/Ly0uOjo5q3769zp49a7H97lI0khQaGqqGDRsa7xs2bKj+/fsrNDRUpUqVUvPmzSVJhw4dUsuWLWU2m+Xu7q5u3brpjz/+MPb76quv5O/vLwcHB5UsWVJNmjTR5cuX73tOs2KaOHGi3N3d5erqqrFjxyo9PV1DhgyRm5ubnnzySUVFRVnsd+rUKQUHB8vV1VVubm5q27atkpKSjO0ZGRl6++235erqqpIlS2ro0KG6deuWRR93l+K53/2TdQ/HxMSoVq1acnR0VN26dXXs2LH7HuedZs+eLU9PTzk6Oio4OFgXLlyQJH3//fcqWrSofv/9d4v2oaGhev755+/brzX3Z2Jiotq2bSt3d3eZzWbVrl1bGzdutDgnP//8s9566y2ZTCaZTCaLvu/09ddfKzAwUMWKFVPFihU1ZswYpaenG9tNJpM+/fRTtW/fXo6OjvLx8dGqVask3f6f8cILL0iSSpQoIZPJpJCQkPseY27/h+6UkpKili1bysHBQRUrVtRXX31lbMv6f/XFF1+oQYMGKlasmBYvXnzfsQEAAAAAAIAHUeCleObPn6/ixYsrPj5ekydP1tixY7Vhw4Y89REeHq6ZM2dq27ZtRnJ26tSp+uyzz7R69WqtX79eM2bMeKD4bt68qXHjxunAgQNauXKlkpKSckwWDhkyRJGRkdq1a5dKly6tNm3a6ObNm1aNceXKFU2YMEELFixQXFycUlNT9corr1i0OXnypJYtW6bly5dr//79yszMVNu2bXXu3Dlt3rxZGzZs0I8//qhOnToZ+6xevVrt27dXq1attG/fPsXExOjZZ581tvfv31/bt2/XkiVL9MMPP6hjx45q0aKFTpw4IUmKj49Xr1691L9/f+3fv18vvPCCxo8f/wBn8fZ1trOzU1xcnD7++GOlpqaqUaNGqlGjhnbv3q21a9fq9OnTCg4OlnQ7idq5c2e9+uqrSkhIUGxsrDp06JAtkX4v//3vf/Xbb7/p+++/15QpUzR69Gi9+OKLKlGihOLj49W3b1+9/vrr+uWXXyTdvs7NmzeXk5OTtmzZori4OJnNZrVo0UI3btyQJEVGRio6Olrz5s3T1q1bde7cOa1YsSLXOKy9f959911FRkZq9+7dsrW11auvvmr1uT158qSWLl2qb775RmvXrtW+ffvUr18/SVL9+vVVsWJFLVy40CKmxYsXWz3G/e7PtLQ0tWrVSjExMdq3b59atGihNm3aKDk5WdLt8kRPPvmkxo4dq5SUFKWkpOQ4zpYtW9S9e3cNGjRIR44c0ezZsxUdHa0JEyZYtBszZoyCg4P1ww8/qFWrVuratavOnTsnT09PLVu2TJJ07NgxpaSkaNq0aVYdozX/h0aOHKmXXnpJBw4cUNeuXfXKK68oISHBos0777yjQYMGKSEhwXiAdbfr16/r4sWLFi8AAAAAAAAgLwq8FE/16tU1evRoSZKPj49mzpypmJgY+fj4WN3H+PHjVa9ePUlSr169NHz4cCUmJqpixYqSpJdfflmbNm3SsGHD8hzfncnPihUravr06apdu7bS0tJkNpuNbaNHj1bTpk0l3U4SPvnkk1qxYoWRqM7NzZs3NXPmTD333HPG/n5+ftq5c6eRiL9x44YWLFig0qVLS5I2bNiggwcP6qeffpKnp6ckacGCBapWrZp27dql2rVra8KECXrllVc0ZswYY6yAgABJt2f7R0VFKTk5WWXLlpUkhYWFae3atYqKitLEiRM1bdo0tWjRQkOHDpUk+fr6atu2bVq7dm2ez6OPj48mT55svB8/frxq1KihiRMnGp/NmzdPnp6eOn78uNLS0pSenq4OHTqofPnykiR/f3+rx3Nzc9P06dNVpEgRVa5cWZMnT9aVK1f073//W5I0fPhwRUREaOvWrXrllVf0xRdfKDMzU59++qkxozwqKkqurq6KjY1Vs2bNNHXqVA0fPlwdOnSQJH388cdat25drnFYe/9MmDBBDRo0kHQ7Ody6dWtdu3bN+HVGbq5du6YFCxaoXLlykqQZM2aodevWioyMlIeHh3r16qWoqCgNGTJE0u1fcVy7ds2qe1O6//0ZEBBg3FeSNG7cOK1YsUKrVq1S//795ebmJhsbG+NXC/cyZswYvfPOO+rRo4dxvsaNG6ehQ4ca/yOk27/I6Ny5syRp4sSJmj59unbu3KkWLVoYpZCeeOKJPC3Me6//Q1nfaUnq2LGjevfubRzjhg0bNGPGDH300UdGm9DQUOP+uJdJkyZZfCcBAAAAAACAvCrwGfvVq1e3eF+mTJkcS91Y24e7u7scHR2NpH7WZ3ntM8uePXvUpk0beXl5ycnJyUi+Zs1GzhIUFGT87ebmpsqVK2ebzXsvtra2ql27tvG+SpUqcnV1tdi/fPnyRlJfkhISEuTp6Wkk9SWpatWqFvvt379fjRs3znHMgwcPKiMjQ76+vjKbzcZr8+bNSkxMNMbISubmdJx5UbNmTYv3Bw4c0KZNmyzGrlKliqTbpV0CAgLUuHFj+fv7q2PHjpozZ47Onz9v9XjVqlVTkSL/d3u7u7tbPBiwsbFRyZIljfviwIEDOnnypJycnIx43NzcdO3aNSUmJurChQtKSUmxOB+2traqVatWrnFYe//ceQ+XKVNGkqy+Z728vIykvnT7GmVmZhrlfEJCQnTy5Ent2LFD0u0SOMHBwSpevLhV/d/v/kxLS1NYWJj8/Pzk6uoqs9mshISEbMd4PwcOHNDYsWMt7ok+ffooJSXFopTWneeqePHicnZ2fuDvd059Sjn/H7r73g8KCsr2Hb/f/SDdfqh04cIF43VnWSMAAAAAAADAGgU+Y//uxSVNJpMyMzONpOydpVfuVdrmzj5MJtM9+8yry5cvq3nz5mrevLkWL16s0qVLKzk5Wc2bNzfKs/xVrE3C3im3hUnT0tJkY2OjPXv2yMbGxmLbnTPJ76dIkSLZyuPkdJ3ujj8tLU1t2rTRe++9l61tmTJlZGNjow0bNmjbtm1GKaV3331X8fHxqlChwn3jyukeyO2+SEtLU82aNXOsi37nA5W8yMv9c/c9LOmB7tmcPPHEE2rTpo2ioqJUoUIFrVmzJttaCn9GWFiYNmzYoA8++ECVKlWSg4ODXn755Tx/R9LS0jRmzJgcZ7zf+cuF/Pp+3ym/+rTme2pvby97e/s89w0AAAAAAABkKfAZ+/eSlUy9sx73nQvp/hWOHj2qs2fPKiIiQs8//7yqVKlyz5nBWbOhJen8+fM6fvy4/Pz8rBonPT1du3fvNt4fO3ZMqampue7v5+enU6dOWcz2PXLkiFJTU1W1alVJt2chx8TE5Lh/jRo1lJGRoTNnzqhSpUoWr6xyKX5+foqPj7/ncUq3r9PdNdOtuU6BgYE6fPiwvL29s42flRw1mUyqV6+exowZo3379snOzu6+Ne0fVGBgoE6cOKEnnngiWzwuLi5ycXFRmTJlLM5Henq69uzZc88+83L//BnJycn67bffjPc7duwwShBl6d27t7744gt98skneuqpp4zSVda43/0ZFxenkJAQtW/fXv7+/vLw8LBYdFiS7OzslJGRkes4gYGBOnbsWLbzX6lSJYtfX+TGzs5Oku471oO4+97fsWOH1d9xAAAAAAAAID89sol9BwcH1alTRxEREUpISNDmzZs1YsSIvzQGLy8v2dnZacaMGfrxxx+1atUqjRs3Lse2Y8eOVUxMjA4dOqSQkBCVKlVK7dq1s2qcokWLasCAAYqPj9eePXsUEhKiOnXqWCx0e7cmTZrI399fXbt21d69e7Vz5051795dDRo0MMqBjB49Wp9//rlGjx6thIQEHTx40Jgh7+vrq65du6p79+5avny5fvrpJ+3cuVOTJk3S6tWrJUkDBw7U2rVr9cEHH+jEiROaOXNmtvr6jRo10u7du7VgwQKdOHFCo0eP1qFDh+57zG+++abOnTunzp07a9euXUpMTNS6devUs2dPZWRkKD4+XhMnTtTu3buVnJys5cuX63//+99DS6R27dpVpUqVUtu2bbVlyxb99NNPio2N1cCBA40FdgcNGqSIiAitXLlSR48eVb9+/ZSamnrPPvNy//wZxYoVU48ePXTgwAFt2bJFAwcOVHBwsEU9++bNm8vZ2Vnjx49Xz54989T//e5PHx8fY1HnAwcOqEuXLtlmu3t7e+v777/Xr7/+qj/++CPHcUaNGqUFCxZozJgxOnz4sBISErRkyZI8fe/Lly8vk8mkb7/9Vv/73/+UlpaWp2PNzZdffql58+bp+PHjGj16tHbu3Kn+/fvnW/8AAAAAAACAtR7ZxL50ezHV9PR01axZU6GhoRo/fvxfOn7p0qUVHR2tL7/8UlWrVlVERIQ++OCDHNtGRERo0KBBqlmzpn7//Xd98803xuzh+3F0dNSwYcPUpUsX1atXT2azWV988UWu+5hMJn399dcqUaKE6tevryZNmqhixYoW+zVs2FBffvmlVq1apWeeeUaNGjXSzp07je1RUVHq3r27Bg8erMqVK6tdu3batWuXvLy8JEl16tTRnDlzNG3aNAUEBGj9+vXZkqzNmzfXyJEjNXToUNWuXVuXLl1S9+7d73vMZcuWVVxcnDIyMtSsWTP5+/srNDRUrq6uKlKkiJydnfX999+rVatW8vX11YgRIxQZGamWLVtadU7zytHRUd9//728vLzUoUMH+fn5qVevXrp27ZqcnZ0lSYMHD1a3bt3Uo0cPBQUFycnJSe3bt79nn3m5f/6MSpUqqUOHDmrVqpWaNWum6tWrWyzoKt0umRQSEqKMjAyrrs+d7nd/TpkyRSVKlFDdunXVpk0bNW/eXIGBgRZ9jB07VklJSXrqqafuWdqoefPm+vbbb7V+/XrVrl1bderU0YcffmgsnmyNcuXKGYvwuru752vifcyYMVqyZImqV6+uBQsW6PPPPzd+HQMAAAAAAAD8lUy37i6Qjr9UdHS0QkNDc535DeSHXr166X//+59WrVpl9T7cnw/fxYsX5eLiIs/QpSpi71jQ4QAAACskRbQu6BAAAADwGMrKE124cMGYbHwvBb54LoCH68KFCzp48KA+++yzPCX1AQAAAAAAADyaHulSPPktOTlZZrP5nq/k5OR8H7Nly5b3HG/ixIn5Pt7fQW7XcMuWLQUdXr6qVq3aPY918eLFVvXRtm1bNWvWTH379lXTpk0ttj3u92dBfOcBAAAAAACAh+1vVYonPT1dSUlJ99zu7e0tW9v8/RHDr7/+qqtXr+a4zc3NTW5ubvk63t/ByZMn77mtXLlycnBw+Aujebh+/vln3bx5M8dt7u7ucnJy+lP9P+73Z0F85/OKUjwAABQ+lOIBAADAw5CXUjx/q8Q+ADxq8vIPGwAAAAAAAI+vvOSJ/laleAAAAAAAAAAAKOxI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8AAAAAAAAAgEKExD4AAAAAAAAAAIUIiX0AAAAAAAAAAAoREvsAAAAAAAAAABQiJPYBAAAAAAAAAChESOwDAAAAAAAAAFCIkNgHAAAAAAAAAKAQIbEPAAAAAAAAAEAhQmIfAAAAAAAAAIBChMQ+AAAAAAAAAACFCIl9AAAAAAAAAAAKERL7AAAAAAAAAAAUIiT2AQAAAAAAAAAoRGwLOgAAgPT06HUqYu9Y0GEAAPC3lxTRuqBDAAAAAO6LGfsAAAAAAAAAABQiJPYBAAAAAAAAAChESOwDAAAAAAAAAFCIkNjHY6dhw4YKDQ2VJHl7e2vq1Kl/us/Y2FiZTCalpqb+6b4eFSaTSStXrpQkJSUlyWQyaf/+/QUaU5aQkBC1a9cu1zZ/9TWx5hw9jvcJAAAAAAAAHj0snovH2q5du1S8ePGCDuOR5+npqZSUFJUqVaqgQ5EkTZs2Tbdu3TLeN2zYUM8884zFQ5q6desqJSVFLi4uf0lMj9o5AgAAAAAAwN8XiX081kqXLl3QIeTqxo0bsrOzK+gwZGNjIw8Pj4IOw2BNst7Ozu4vjflRO0cAAAAAAAD4+6IUDwq1y5cvq3v37jKbzSpTpowiIyMttt9ZiufWrVsKDw+Xl5eX7O3tVbZsWQ0cONBoe/36dQ0bNkyenp6yt7dXpUqVNHfuXIv+9uzZo1q1asnR0VF169bVsWPHjG2JiYlq27at3N3dZTabVbt2bW3cuDFbPOPGjVP37t3l7Oys1157TZI0Z84ceXp6ytHRUe3bt9eUKVPk6upqse/XX3+twMBAFStWTBUrVtSYMWOUnp5u1Xk6ceKE6tevr2LFiqlq1arasGGDxfa7y8ycP39eXbt2VenSpeXg4CAfHx9FRUVZtF2yZInq1q2rYsWK6emnn9bmzZst+ty8ebOeffZZ2dvbq0yZMnrnnXcs4v3qq6/k7+8vBwcHlSxZUk2aNNHly5clWZbiCQkJ0ebNmzVt2jSZTCaZTCYlJSXlWPZm2bJlqlatmuzt7eXt7Z3j/TBx4kS9+uqrcnJykpeXlz755BOrzmFOpXi+++47+fr6ysHBQS+88IKSkpKs6gsAAAAAAAD4M0jso1AbMmSINm/erK+//lrr169XbGys9u7dm2PbZcuW6cMPP9Ts2bN14sQJrVy5Uv7+/sb27t276/PPP9f06dOVkJCg2bNny2w2W/Tx7rvvKjIyUrt375atra1effVVY1taWppatWqlmJgY7du3Ty1atFCbNm2UnJxs0ccHH3yggIAA7du3TyNHjlRcXJz69u2rQYMGaf/+/WratKkmTJhgsc+WLVvUvXt3DRo0SEeOHNHs2bMVHR2drV1OMjMz1aFDB9nZ2Sk+Pl4ff/yxhg0blus+I0eO1JEjR7RmzRolJCRo1qxZ2UrQDBkyRIMHD9a+ffsUFBSkNm3a6OzZs5KkX3/9Va1atVLt2rV14MABzZo1S3PnztX48eMlSSkpKercubNeffVVJSQkKDY2Vh06dLAov5Nl2rRpCgoKUp8+fZSSkqKUlBR5enpma7dnzx4FBwfrlVde0cGDBxUeHq6RI0cqOjraol1kZKRq1aqlffv2qV+/fnrjjTcsHtBY69SpU+rQoYPatGmj/fv3q3fv3nrnnXfuu9/169d18eJFixcAAAAAAACQF5TiQaGVlpamuXPnatGiRWrcuLEkaf78+XryySdzbJ+cnCwPDw81adJERYsWlZeXl5599llJ0vHjx7V06VJt2LBBTZo0kSRVrFgxWx8TJkxQgwYNJEnvvPOOWrdurWvXrqlYsWIKCAhQQECA0XbcuHFasWKFVq1apf79+xufN2rUSIMHDzbev/vuu2rZsqXCwsIkSb6+vtq2bZu+/fZbo82YMWP0zjvvqEePHkZs48aN09ChQzV69Ohcz9PGjRt19OhRrVu3TmXLlpUkTZw4US1btrznPsnJyapRo4Zq1aol6fZM97v1799fL730kiRp1qxZWrt2rebOnauhQ4fqo48+kqenp2bOnCmTyaQqVarot99+07BhwzRq1CilpKQoPT1dHTp0UPny5SXJ4iHLnVxcXGRnZydHR8dcS+FMmTJFjRs31siRIyXdPo9HjhzR+++/r5CQEKNdq1at1K9fP0nSsGHD9OGHH2rTpk2qXLnyPfvOyaxZs/TUU08ZvwqoXLmyDh48qPfeey/X/SZNmqQxY8bkaSwAAAAAAADgTszYR6GVmJioGzdu6LnnnjM+c3Nzu2eCtmPHjrp69aoqVqyoPn36aMWKFUZpmP3798vGxsZI2t9L9erVjb/LlCkjSTpz5oyk2w8awsLC5OfnJ1dXV5nNZiUkJGSbsZ+VLM9y7Ngx4wFDlrvfHzhwQGPHjpXZbDZeWTPYr1y5kmvMCQkJ8vT0NJL6khQUFJTrPm+88YaWLFmiZ555RkOHDtW2bduytbmzD1tbW9WqVUsJCQnGmEFBQTKZTEabevXqKS0tTb/88osCAgLUuHFj+fv7q2PHjpozZ47Onz+fa0z3k5CQoHr16ll8Vq9ePZ04cUIZGRnGZ3deQ5PJJA8PD+Ma5nW8O+896f7nVZKGDx+uCxcuGK9Tp07leWwAAAAAAAD8vZHYx9+Gp6enjh07po8++kgODg7q16+f6tevr5s3b8rBwcGqPooWLWr8nZW0zszMlCSFhYVpxYoVmjhxorZs2aL9+/fL399fN27csOijePHieY49LS1NY8aM0f79+43XwYMHdeLECRUrVizP/d1Py5Yt9fPPP+utt97Sb7/9psaNGxu/KMgPNjY22rBhg9asWaOqVatqxowZqly5sn766ad8G+Ne7ryG0u3rmHUN/wr29vZydna2eAEAAAAAAAB5QWIfhdZTTz2lokWLKj4+3vjs/PnzOn78+D33cXBwUJs2bTR9+nTFxsZq+/btOnjwoPz9/ZWZmZltAdi8iIuLU0hIiNq3by9/f395eHhYtZhq5cqVtWvXLovP7n4fGBioY8eOqVKlStleRYrk/jX28/PTqVOnlJKSYny2Y8eO+8ZVunRp9ejRQ4sWLdLUqVOzLTJ7Zx/p6enas2eP/Pz8jDG3b99uUTM/Li5OTk5ORqkkk8mkevXqacyYMdq3b5/s7Oy0YsWKHGOxs7OzmHV/r+OMi4uz+CwuLk6+vr6ysbG57/HmlZ+fn3bu3GnxmTXnFQAAAAAAAPizqLGPQstsNqtXr14aMmSISpYsqSeeeELvvvvuPRPd0dHRysjI0HPPPSdHR0ctWrRIDg4OKl++vEqWLKkePXro1Vdf1fTp0xUQEKCff/5ZZ86cUXBwsFXx+Pj4aPny5WrTpo1MJpNGjhxp1UzwAQMGqH79+poyZYratGmj//73v1qzZo1FGZtRo0bpxRdflJeXl15++WUVKVJEBw4c0KFDh4wFae+lSZMm8vX1VY8ePfT+++/r4sWLevfdd3PdZ9SoUapZs6aqVaum69ev69tvvzWS9ln+85//yMfHR35+fvrwww91/vx5YzHhfv36aerUqRowYID69++vY8eOafTo0Xr77bdVpEgRxcfHKyYmRs2aNdMTTzyh+Ph4/e9//8s2RhZvb2/Fx8crKSlJZrNZbm5u2doMHjxYtWvX1rhx49SpUydt375dM2fO1EcffZTrsT6ovn37KjIyUkOGDFHv3r21Z8+ebAv1AgAAAAAAAA8DM/ZRqL3//vt6/vnn1aZNGzVp0kT/+Mc/VLNmzRzburq6as6cOapXr56qV6+ujRs36ptvvlHJkiUl3V4M9eWXX1a/fv1UpUoV9enTR5cvX7Y6lilTpqhEiRKqW7eu2rRpo+bNmyswMPC++9WrV08ff/yxpkyZooCAAK1du1ZvvfWWRYmd5s2b69tvv9X69etVu3Zt1alTRx9++KGx8GxuihQpohUrVujq1at69tln1bt3b02YMCHXfezs7DR8+HBVr15d9evXl42NjZYsWWLRJiIiQhEREQoICNDWrVu1atUqlSpVSpJUrlw5fffdd9q5c6cCAgLUt29f9erVSyNGjJAkOTs76/vvv1erVq3k6+urESNGKDIy8p4L+oaFhcnGxkZVq1ZV6dKls61bIN3+VcPSpUu1ZMkSPf300xo1apTGjh1rsXBufvLy8tKyZcu0cuVKBQQE6OOPP9bEiRMfylgAAAAAAADAnUy37qyVAeCR0KdPHx09elRbtmwp6FCySUpKUoUKFbRv3z4988wzBR1OoXfx4kW5uLjIM3Spitg7FnQ4AAD87SVFtC7oEAAAAPA3lZUnunDhwn3XZaQUD/AI+OCDD9S0aVMVL15ca9as0fz58x9aCRkAAAAAAAAAhRuleIBHwM6dO9W0aVP5+/vr448/1vTp09W7d2+r9l28eLHMZnOOr2rVqj3kyB8fEydOvOd5vFeJIAAAAAAAAKAgUIoHKOQuXbqk06dP57itaNGiVtXhh3Tu3DmdO3cux20ODg4qV67cQxmXUjwAADxaKMUDAACAgpKXUjwk9gGgAOXlHzYAAAAAAAAeX3nJE1GKBwAAAAAAAACAQoTEPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIPlNhPTEzUiBEj1LlzZ505c0aStGbNGh0+fDhfgwMAAAAAAAAAAJbynNjfvHmz/P39FR8fr+XLlystLU2SdODAAY0ePTrfAwQAAAAAAAAAAP8nz4n9d955R+PHj9eGDRtkZ2dnfN6oUSPt2LEjX4MDAAAAAAAAAACW8pzYP3jwoNq3b5/t8yeeeEJ//PFHvgQFAAAAAAAAAABylufEvqurq1JSUrJ9vm/fPpUrVy5fggIAAAAAAAAAADnLc2L/lVde0bBhw/T777/LZDIpMzNTcXFxCgsLU/fu3R9GjAAAAAAAAAAA4P/Lc2J/4sSJqlKlijw9PZWWlqaqVauqfv36qlu3rkaMGPEwYgQAAAAAAAAAAP+f6datW7esbXzr1i2dOnVKpUuX1h9//KGDBw8qLS1NNWrUkI+Pz8OMEwAeSxcvXpSLi4suXLggZ2fngg4HAAAAAAAABSQveSLbvHR869YtVapUSYcPH5aPj488PT3/VKAAAAAAAAAAACBv8lSKp0iRIvLx8dHZs2cfVjwAAAAAAAAAACAXea6xHxERoSFDhujQoUMPIx4AAAAAAAAAAJCLPNXYl6QSJUroypUrSk9Pl52dnRwcHCy2nzt3Ll8DBIDHGTX2AQAAAAAAID3EGvuSNHXq1AeNCwAAAAAAAAAA/El5nrEPAMg/WU9iPUOXqoi9Y0GHAwBAoZMU0bqgQwAAAADyxUOdsZ+cnJzrdi8vr7x2CQAAAAAAAAAArJTnxL63t7dMJtM9t2dkZPypgAAAAAAAAAAAwL3lObG/b98+i/c3b97Uvn37NGXKFE2YMCHfAgMAAAAAAAAAANkVyesOAQEBFq9atWqpT58++uCDDzR9+vSHEeMjKzY2ViaTSampqQUWQ3R0tFxdXfOtv4YNGyo0NDTf+nsQ4eHheuaZZx6Zfh5lj8I9+KCSkpJkMpm0f//+gg7lvh6F7wUAAAAAAACQJc+J/XupXLmydu3alV/dPZLuTu7VrVtXKSkpcnFxKbCYOnXqpOPHjxfY+A9DWFiYYmJijPchISFq165dwQWEPy2na+jp6amUlBQ9/fTT+TqWyWTSypUr87VPAAAAAAAA4FGS51I8Fy9etHh/69YtpaSkKDw8XD4+PvkWWGFgZ2cnDw+PAo3BwcFBDg4OBRpDfjObzTKbzQUdBh4yGxubAv/+PEw3btyQnZ1dQYcBAAAAAACAx1CeZ+y7urqqRIkSxsvNzU1Vq1bV9u3bNWvWrIcR4yMhJCREmzdv1rRp02QymWQymRQdHW1RBiWrLM63336rypUry9HRUS+//LKuXLmi+fPny9vbWyVKlNDAgQMtFhm+fv26wsLCVK5cORUvXlzPPfecYmNjrYrr7lI8WeVnFi5cKG9vb7m4uOiVV17RpUuXrD7WzMxMDR06VG5ubvLw8FB4eLjF9uTkZLVt21Zms1nOzs4KDg7W6dOnje0HDhzQCy+8ICcnJzk7O6tmzZravXu3RbwrV66Uj4+PihUrpubNm+vUqVPZjiHr7/nz5+vrr782znvWuRk2bJh8fX3l6OioihUrauTIkbp586bVx3mnrBnlEydOlLu7u1xdXTV27Filp6dryJAhcnNz05NPPqmoqCiL/U6dOqXg4GC5urrKzc1Nbdu2VVJSkrF9165datq0qUqVKiUXFxc1aNBAe/futejDZDLp008/Vfv27eXo6CgfHx+tWrUqT/HHxcWpevXqKlasmOrUqaNDhw5Jki5fvixnZ2d99dVXFu1Xrlyp4sWL3/e+yCqXs2TJEtWtW1fFihXT008/rc2bNxttMjIy1KtXL1WoUEEODg6qXLmypk2bZmy/1zXMqRTPoUOH1LJlS5nNZrm7u6tbt276448/jO0NGzbUwIED73l/ent7S5Lat28vk8lkvM+Ntd+Z9PR09e/fXy4uLipVqpRGjhypW7duWYw9btw4de/eXc7OznrttdfuOzYAAAAAAADwIPKc2N+0aZP++9//Gq/Y2FgdOXJEiYmJCgoKehgxPhKmTZumoKAg9enTRykpKUpJSZGnp2e2dleuXNH06dO1ZMkSrV27VrGxsWrfvr2+++47fffdd1q4cKFmz55tkWjt37+/tm/friVLluiHH35Qx44d1aJFC504ceKBYk1MTNTKlSv17bff6ttvv9XmzZsVERFh9f7z589X8eLFFR8fr8mTJ2vs2LHasGGDpNtJ/7Zt2+rcuXPavHmzNmzYoB9//FGdOnUy9u/atauefPJJ7dq1S3v27NE777yjokWLWpyjCRMmaMGCBYqLi1NqaqpeeeWVHGMJCwtTcHCwWrRoYZz3unXrSpKcnJwUHR2tI0eOaNq0aZozZ44+/PDDBzllkqT//ve/+u233/T9999rypQpGj16tF588UWVKFFC8fHx6tu3r15//XX98ssvkm4vHN28eXM5OTlpy5YtiouLk9lsVosWLXTjxg1J0qVLl9SjRw9t3bpVO3bskI+Pj1q1apUtaTxmzBgFBwfrhx9+UKtWrdS1a1edO3fO6tiHDBmiyMhI7dq1S6VLl1abNm108+ZNFS9eXK+88kq2BxJRUVF6+eWX5eTkZHX/gwcP1r59+xQUFKQ2bdro7Nmzkm7fE08++aS+/PJLHTlyRKNGjdK///1vLV26VFLu1/BOqampatSokWrUqKHdu3dr7dq1On36tIKDgy3a5XZ/ZpUDi4qKUkpKitXlwaz5zsyfP1+2trbauXOnpk2bpilTpujTTz+1aPPBBx8oICBA+/bt08iRI3Mc6/r167p48aLFCwAAAAAAAMiLPJfiMZlMqlu3rmxtLXdNT0/X999/r/r16+dbcI8SFxcX2dnZydHR0SgfcvTo0Wztbt68qVmzZumpp56SJL388stauHChTp8+LbPZrKpVq+qFF17Qpk2b1KlTJyUnJysqKkrJyckqW7aspNuJ0LVr1yoqKkoTJ07Mc6yZmZmKjo42krbdunVTTEyMJkyYYNX+1atX1+jRoyVJPj4+mjlzpmJiYtS0aVPFxMTo4MGD+umnn4wHGwsWLFC1atW0a9cu1a5dW8nJyRoyZIiqVKli9HH3OZo5c6aee+45SbcTpn5+ftq5c6eeffZZi7Zms1kODg66fv16trItI0aMMP729vZWWFiYlixZoqFDh1p7qiy4ublp+vTpKlKkiCpXrqzJkyfrypUr+ve//y1JGj58uCIiIrR161a98sor+uKLL5SZmalPP/1UJpNJ0u2Esqurq2JjY9WsWTM1atTIYoxPPvlErq6u2rx5s1588UXj85CQEHXu3FmSNHHiRE2fPl07d+5UixYtrIp99OjRatq0qaTb5/PJJ5/UihUrFBwcrN69exvrQZQpU0ZnzpzRd999p40bN1p9bvr376+XXnpJkjRr1iytXbtWc+fO1dChQ1W0aFGNGTPGaFuhQgVt375dS5cuVXBwcK7X8E4zZ85UjRo1LO75efPmydPTU8ePH5evr6+k3O/P0qVLS7r9y6K8lPmx5jvj6empDz/8UCaTSZUrV9bBgwf14Ycfqk+fPkabRo0aafDgwbmONWnSJIvzBQAAAAAAAORVnmfsv/DCCznOJL5w4YJeeOGFfAmqMHN0dDSS+pLk7u4ub29vi5rx7u7uOnPmjCTp4MGDysjIkK+vr1Fb3mw2a/PmzUpMTHygGLy9vS1mYmclc61VvXp1i/d37p+QkCBPT0+LXytUrVpVrq6uSkhIkCS9/fbb6t27t5o0aaKIiIhsx2Fra6vatWsb76tUqWKxv7W++OIL1atXTx4eHjKbzRoxYoSSk5Pz1MedqlWrpiJF/u8r4e7uLn9/f+O9jY2NSpYsaZyLAwcO6OTJk3JycjKum5ubm65du2Yc8+nTp9WnTx/5+PjIxcVFzs7OSktLyxbnnee8ePHicnZ2ztM1u/PXMm5ubqpcubJxPp999llVq1ZN8+fPlyQtWrRI5cuXz9NDuDv7t7W1Va1atSyu13/+8x/VrFlTpUuXltls1ieffJLna3HgwAFt2rTJ4nuQ9XDoznsot/vzQVnznalTp47xAEe6fU5OnDhhUVarVq1a9x1r+PDhunDhgvG6swwVAAAAAAAAYI08z9i/deuWRXIry9mzZ1W8ePF8Caowu7PkjHT7Fw45fZaZmSlJSktLk42Njfbs2SMbGxuLdg+6gGxu4/0V+4eHh6tLly5avXq11qxZo9GjR2vJkiVq37691X3cz/bt29W1a1eNGTNGzZs3l4uLi5YsWaLIyMgH7vNBrl3NmjW1ePHibH1lzRzv0aOHzp49q2nTpql8+fKyt7dXUFCQUaont7Hzcs7vp3fv3vrPf/6jd955R1FRUerZs2eO3+MHsWTJEoWFhSkyMlJBQUFycnLS+++/r/j4+Dz1k5aWpjZt2ui9997Ltq1MmTLG3w/jXOVXn9b8D7S3t5e9vX2e+wYAAAAAAACyWJ3Y79Chg6TbCa+QkBCLxFRGRoZ++OGHHOtmP07s7OwsZufmhxo1aigjI0NnzpzR888/n699Pwx+fn46deqUTp06ZczaP3LkiFJTU1W1alWjna+vr3x9ffXWW2+pc+fOioqKMhL76enp2r17t1F259ixY0pNTZWfn1+OY+Z03rdt26by5cvr3XffNT77+eef8/VY7ycwMFBffPGFnnjiCTk7O+fYJi4uTh999JFatWol6fZiu3cuBptfduzYIS8vL0nS+fPndfz4cYvz+a9//UtDhw7V9OnTdeTIEfXo0SPP/WfN8E9PT9eePXvUv39/SbePsW7duurXr5/R/u5faVjz3QkMDNSyZcvk7e2drdRXXhQtWjTfv6eSsj2oyFoz4e4HcgAAAAAAAMDDZnUpHhcXF7m4uOjWrVtycnIy3ru4uMjDw0OvvfaaFi1a9DBjLXDe3t6Kj49XUlKS/vjjj3yZUe3r66uuXbuqe/fuWr58uX766Sft3LlTkyZN0urVq/Mh6vzVpEkT+fv7q2vXrtq7d6927typ7t27q0GDBqpVq5auXr2q/v37KzY2Vj///LPi4uK0a9cuiyRz0aJFNWDAAMXHx2vPnj0KCQlRnTp1stXXz+Lt7a0ffvhBx44d0x9//KGbN2/Kx8dHycnJWrJkiRITEzV9+nStWLHirzoNkm4vElyqVCm1bdtWW7Zs0U8//aTY2FgNHDjQWGDXx8dHCxcuVEJCguLj49W1a1c5ODjkeyxjx45VTEyMDh06pJCQEJUqVUrt2rUztpcoUUIdOnTQkCFD1KxZMz355JN56v8///mPVqxYoaNHj+rNN9/U+fPn9eqrr0q6fYy7d+/WunXrdPz4cY0cOTLborU5XcO7vfnmmzp37pw6d+6sXbt2KTExUevWrVPPnj3zlKj39vZWTEyMfv/9d50/fz5Px5mb5ORkvf322zp27Jg+//xzzZgxQ4MGDcq3/gEAAAAAAABrWZ3Yj4qKUlRUlEaPHq25c+ca76OiojR79mwNHz5cpUqVepixFriwsDDZ2NioatWqKl269J+q536nqKgode/eXYMHD1blypXVrl077dq1y5iB/SgxmUz6+uuvVaJECdWvX19NmjRRxYoV9cUXX0i6XYf+7Nmz6t69u3x9fRUcHKyWLVtaLBbq6OioYcOGqUuXLqpXr57MZrOxf0769OmjypUrq1atWipdurTi4uL0z3/+U2+99Zb69++vZ555Rtu2bdPIkSMf+vHfydHRUd9//728vLzUoUMH+fn5qVevXrp27Zoxg3/u3Lk6f/68AgMD1a1bNw0cOFBPPPFEvscSERGhQYMGqWbNmvr999/1zTffyM7OzqJNr169dOPGDSMhn9f+IyIiFBAQoK1bt2rVqlXG9/31119Xhw4d1KlTJz333HM6e/asxex9KedreLeyZcsqLi5OGRkZatasmfz9/RUaGipXV1eLtQ/uJzIyUhs2bJCnp6dq1KiR52O9l+7du+vq1at69tln9eabb2rQoEF67bXX8q1/AAAAAAAAwFqmW7du3SroIPD3ER0drdDQUKWmphZ0KH87Cxcu1FtvvaXffvstW9L/XpKSklShQgXt27dPzzzzzMMN8G/q4sWLcnFxkWfoUhWxdyzocAAAKHSSIloXdAgAAABAvsjKE124cOGepb+zPFAh66+++kpLly5VcnJytkVA9+7d+yBdAnhIrly5opSUFEVEROj111+3OqkPAAAAAAAA4NFkfX2L/2/69Onq2bOn3N3dtW/fPj377LMqWbKkfvzxR7Vs2fJhxPi31rJlS5nN5hxfEydOzFNfycnJ9+zLbDbnW2mhR1Fux71ly5aCDu+e+vbte8+4+/bta1UfkydPVpUqVeTh4aHhw4dbbJs4ceI9+39cvs/VqlW75zEuXry4oMMDAAAAAAAA8izPpXiqVKmi0aNHq3PnznJyctKBAwdUsWJFjRo1SufOndPMmTMfVqx/S7/++quuXr2a4zY3Nze5ublZ3Vd6erqSkpLuud3b21u2tg/0I45H3smTJ++5rVy5cg9lQdv8cObMGV28eDHHbc7Ozn+6Xv+5c+d07ty5HLc5ODioXLlyf6r/R8HPP/+c42K9kuTu7i4nJ6e/OCJLlOIBAODPoRQPAAAAHhd5KcWT58S+o6OjEhISVL58eT3xxBPasGGDAgICdOLECdWpU0dnz579U8EDwN9JXv5hAwAAAAAA4PGVlzxRnkvxeHh4GDN8vby8tGPHDknSTz/9JNbhBQAAAAAAAADg4cpzYr9Ro0ZatWqVJKlnz55666231LRpU3Xq1Ent27fP9wABAAAAAAAAAMD/yXMpnszMTGVmZhq12JcsWaJt27bJx8dHr7/+uuzs7B5KoADwOKIUDwAAAAAAAKSHXGMfAJB/SOwDAAAAAABAesg19iVpy5Yt+te//qWgoCD9+uuvkqSFCxdq69atD9IdAAAAAAAAAACwUp4T+8uWLVPz5s3l4OCgffv26fr165KkCxcuaOLEifkeIAAAAAAAAAAA+D95TuyPHz9eH3/8sebMmaOiRYsan9erV0979+7N1+AAAAAAAAAAAIClPCf2jx07pvr162f73MXFRampqfkREwAAAAAAAAAAuIc8J/Y9PDx08uTJbJ9v3bpVFStWzJegAAAAAAAAAABAzvKc2O/Tp48GDRqk+Ph4mUwm/fbbb1q8eLHCwsL0xhtvPIwYAQAAAAAAAADA/2drTaMffvhBTz/9tIoUKaLhw4crMzNTjRs31pUrV1S/fn3Z29srLCxMAwYMeNjxAgAAAAAAAADwt2a6devWrfs1srGxUUpKip544glVrFhRu3btkpOTk06ePKm0tDRVrVpVZrP5r4gXAB4rFy9elIuLiy5cuCBnZ+eCDgcAAAAAAAAFJC95Iqtm7Lu6uuqnn37SE088oaSkJGVmZsrOzk5Vq1bNl4ABAAAAAAAAAIB1rErsv/TSS2rQoIHKlCkjk8mkWrVqycbGJse2P/74Y74GCAAAAAAAAAAA/o9Vif1PPvlEHTp00MmTJzVw4ED16dNHTk5ODzs2AAAAAAAAAABwF6sS+5LUokULSdKePXs0aNAgEvsAAAAAAAAAABQAqxP7WaKioh5GHAAAAAAAAAAAwAp5TuwDAPLf06PXqYi9Y0GHAQAopJIiWhd0CAAAAAD+QkUKOgAAAAAAAAAAAGA9EvsAAAAAAAAAABQiJPYBAAAAAAAAAChESOwDhUhsbKxMJpNSU1MLLIbo6Gi5urrmW38NGzZUaGhovvX3IMLDw/XMM888Mv0AAAAAAAAAuSGxDzzC7k56161bVykpKXJxcSmwmDp16qTjx48X2PgPQ1hYmGJiYoz3ISEhateuXcEFBAAAAAAAAOTCtqADAGA9Ozs7eXh4FGgMDg4OcnBwKNAY8pvZbJbZbC7oMAAAAAAAAACrMGMfeESFhIRo8+bNmjZtmkwmk0wmk6Kjoy1K8WSVxfn2229VuXJlOTo66uWXX9aVK1c0f/58eXt7q0SJEho4cKAyMjKMvq9fv66wsDCVK1dOxYsX13PPPafY2Fir4rq7FE9W+ZmFCxfK29tbLi4ueuWVV3Tp0iWrjzUzM1NDhw6Vm5ubPDw8FB4ebrE9OTlZbdu2ldlslrOzs4KDg3X69Glj+4EDB/TCCy/IyclJzs7Oqlmzpnbv3m0R78qVK+Xj46NixYqpefPmOnXqVLZjyPp7/vz5+vrrr43znnVuhg0bJl9fXzk6OqpixYoaOXKkbt68afVxAgAAAAAAAPmBGfvAI2ratGk6fvy4nn76aY0dO1aSdPjw4Wztrly5ounTp2vJkiW6dOmSOnTooPbt28vV1VXfffedfvzxR7300kuqV6+eOnXqJEnq37+/jhw5oiVLlqhs2bJasWKFWrRooYMHD8rHxyfPsSYmJmrlypX69ttvdf78eQUHBysiIkITJkywav/58+fr7bffVnx8vLZv366QkBDVq1dPTZs2VWZmppHU37x5s9LT0/Xmm2+qU6dORsK9a9euqlGjhmbNmiUbGxvt379fRYsWtThHEyZM0IIFC2RnZ6d+/frplVdeUVxcXLZYwsLClJCQoIsXLyoqKkqS5ObmJklycnJSdHS0ypYtq4MHD6pPnz5ycnLS0KFDrT5X169f1/Xr1433Fy9etHpfAAAAAAAAQCKxDzyyXFxcZGdnJ0dHR6P8ztGjR7O1u3nzpmbNmqWnnnpKkvTyyy9r4cKFOn36tMxms6pWraoXXnhBmzZtUqdOnZScnKyoqCglJyerbNmykm4ns9euXauoqChNnDgxz7FmZmYqOjpaTk5OkqRu3bopJibG6sR+9erVNXr0aEmSj4+PZs6cqZiYGDVt2lQxMTE6ePCgfvrpJ3l6ekqSFixYoGrVqmnXrl2qXbu2kpOTNWTIEFWpUsXo4+5zNHPmTD333HOSbj9I8PPz086dO/Xss89atDWbzXJwcND169ezlT0aMWKE8be3t7fCwsK0ZMmSPCX2J02apDFjxljdHgAAAAAAALgbpXiAQs7R0dFI6kuSu7u7vL29LWrGu7u768yZM5KkgwcPKiMjQ76+vkZt+azZ8ImJiQ8Ug7e3t5HUl6QyZcoY41mjevXqFu/v3D8hIUGenp5GUl+SqlatKldXVyUkJEiS3n77bfXu3VtNmjRRREREtuOwtbVV7dq1jfdVqlSx2N9aX3zxherVqycPDw+ZzWaNGDFCycnJeepj+PDhunDhgvG6syQQAAAAAAAAYA1m7AOF3J0lZyTJZDLl+FlmZqYkKS0tTTY2NtqzZ49sbGws2j3oArK5jfdX7B8eHq4uXbpo9erVWrNmjUaPHq0lS5aoffv2VvdxP9u3b1fXrl01ZswYNW/eXC4uLlqyZIkiIyPz1I+9vb3s7e3zLS4AAAAAAAD8/ZDYBx5hdnZ2Fove5ocaNWooIyNDZ86c0fPPP5+vfT8Mfn5+OnXqlE6dOmXM2j9y5IhSU1NVtWpVo52vr698fX311ltvqXPnzoqKijIS++np6dq9e7dRdufYsWNKTU2Vn59fjmPmdN63bdum8uXL69133zU++/nnn/P1WAEAAAAAAABrUIoHeIR5e3srPj5eSUlJ+uOPP/I0i/1efH191bVrV3Xv3l3Lly/XTz/9pJ07d2rSpElavXp1PkSdv5o0aSJ/f3917dpVe/fu1c6dO9W9e3c1aNBAtWrV0tWrV9W/f3/Fxsbq559/VlxcnHbt2mWRtC9atKgGDBig+Ph47dmzRyEhIapTp062+vpZvL299cMPP+jYsWP6448/dPPmTfn4+Cg5OVlLlixRYmKipk+frhUrVvxVpwEAAAAAAAAwkNgHHmFhYWGysbFR1apVVbp06TzXc7+XqKgode/eXYMHD1blypXVrl077dq1S15eXvnSf34ymUz6+uuvVaJECdWvX19NmjRRxYoV9cUXX0iSbGxsdPbsWXXv3l2+vr4KDg5Wy5YtLRaodXR01LBhw9SlSxfVq1dPZrPZ2D8nffr0UeXKlVWrVi2VLl1acXFx+uc//6m33npL/fv31zPPPKNt27Zp5MiRD/34AQAAAAAAgLuZbt26dauggwCAhyU6OlqhoaFKTU0t6FBydPHiRbm4uMgzdKmK2DsWdDgAgEIqKaJ1QYcAAAAA4E/KyhNduHBBzs7OubZlxj4AAAAAAAAAAIUIiX0AFlq2bCmz2Zzja+LEiXnqKzk5+Z59mc3mfCstBAAAAAAAAPydUIoHgIVff/1VV69ezXGbm5ub3NzcrO4rPT1dSUlJ99zu7e0tW1vbvIb4WMnLT6wAAAAAAADw+MpLnujvnVEDkE25cuXyrS9bW1tVqlQp3/oDAAAAAAAAQCkeAAAAAAAAAAAKFRL7AAAAAAAAAAAUIiT2AQAAAAAAAAAoREjsAwAAAAAAAABQiJDYBwAAAAAAAACgECGxDwAAAAAAAABAIUJiHwAAAAAAAACAQoTEPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIk9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8AAAAAAAAAgEKExD4AAAAAAAAAAIUIiX0AAAAAAAAAAAoR24IOAAAgPT16nYrYOxZ0GACAR1RSROuCDgEAAADAI4QZ+wAAAAAAAAAAFCIk9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2IdVGjZsqNDQUOO9t7e3pk6d+lDHjI2NlclkUmpq6kMdpzALCQlRu3btCjqMBxIeHq5nnnmmoMO4r6SkJJlMJu3fv7+gQwEAAAAAAAAkkdjHA9q1a5dee+21fOvv7gcHklS3bl2lpKTIxcUl38ZBwTCZTFq5cqXFZ2FhYYqJicnXcaKjo+Xq6pqvfQIAAAAAAACPGtuCDgCFU+nSpR/6GHZ2dvLw8Hjo46BgmM1mmc3mgg7jobh165YyMjJka8u/WAAAAAAAAOQ/ZuxbqWHDhho4cKCGDh0qNzc3eXh4KDw8XFLOpTpSU1NlMpkUGxsr6f/Kyqxbt041atSQg4ODGjVqpDNnzmjNmjXy8/OTs7OzunTpoitXrlgd04ABAxQaGqoSJUrI3d1dc+bM0eXLl9WzZ085OTmpUqVKWrNmjcV+hw4dUsuWLWU2m+Xu7q5u3brpjz/+MLZfvnxZ3bt3l9lsVpkyZRQZGZlt7LtL8aSmpur111+Xu7u7ihUrpqefflrffvutJOns2bPq3LmzypUrJ0dHR/n7++vzzz839g0JCdHmzZs1bdo0mUwmmUwmJSUl5ViKZ9myZapWrZrs7e3l7e2dLTZvb29NnDhRr776qpycnOTl5aVPPvnE2H7jxg31799fZcqUUbFixVS+fHlNmjTJqvNtMpk0e/Zsvfjii3J0dJSfn5+2b9+ukydPqmHDhipevLjq1q2rxMREY5/ExES1bdtW7u7uMpvNql27tjZu3GhsP3r0qBwdHfXZZ58Zny1dulQODg46cuSIVXFJ0pgxY1S6dGk5Ozurb9++unHjhiRpwYIFKlmypK5fv27Rvl27durWrdt9+80qlzN79mx5enrK0dFRwcHBunDhgtFm165datq0qUqVKiUXFxc1aNBAe/fuNbZ7e3tLktq3by+TyWS8z6kUz6effio/Pz8VK1ZMVapU0UcffWRsy/qeLV++XC+88IIcHR0VEBCg7du3S7r9HevZs6cuXLhg3EdZ39Hc3O+eyXL06FHVrVvXuL83b95sbMu6V9esWaOaNWvK3t5eW7duve/YAAAAAAAAwIMgsZ8H8+fPV/HixRUfH6/Jkydr7Nix2rBhQ576CA8P18yZM7Vt2zadOnVKwcHBmjp1qj777DOtXr1a69ev14wZM/IUU6lSpbRz504NGDBAb7zxhjp27Ki6detq7969atasmbp162Y8LEhNTVWjRo1Uo0YN7d69W2vXrtXp06cVHBxs9DlkyBBt3rxZX3/9tdavX6/Y2FiLRO3dMjMz1bJlS8XFxWnRokU6cuSIIiIiZGNjI0m6du2aatasqdWrV+vQoUN67bXX1K1bN+3cuVOSNG3aNAUFBalPnz5KSUlRSkqKPD09s42zZ88eBQcH65VXXtHBgwcVHh6ukSNHKjo62qJdZGSkatWqpX379qlfv3564403dOzYMUnS9OnTtWrVKi1dulTHjh3T4sWLjUSzNcaNG6fu3btr//79qlKlirp06aLXX39dw4cP1+7du3Xr1i3179/faJ+WlqZWrVopJiZG+/btU4sWLdSmTRslJydLkqpUqaIPPvhA/fr1U3Jysn755Rf17dtX7733nqpWrWpVTDExMUpISFBsbKw+//xzLV++XGPGjJEkdezYURkZGVq1apXR/syZM1q9erVeffVVq/o/efKkli5dqm+++UZr1641zmuWS5cuqUePHtq6dat27NghHx8ftWrVSpcuXZJ0O/EvSVFRUUpJSTHe323x4sUaNWqUJkyYoISEBE2cOFEjR47U/PnzLdq9++67CgsL0/79++Xr66vOnTsrPT1ddevW1dSpU+Xs7GzcR2FhYVYdY273TJYhQ4Zo8ODB2rdvn4KCgtSmTRudPXvWos0777yjiIgIJSQkqHr16jmOdf36dV28eNHiBQAAAAAAAOQFdSLyoHr16ho9erQkycfHRzNnzlRMTIx8fHys7mP8+PGqV6+eJKlXr14aPny4EhMTVbFiRUnSyy+/rE2bNmnYsGFW9RcQEKARI0ZIkoYPH66IiAiVKlVKffr0kSSNGjVKs2bN0g8//KA6depo5syZqlGjhiZOnGj0MW/ePHl6eur48eMqW7as5s6dq0WLFqlx48aSbj88ePLJJ+8Zw8aNG7Vz504lJCTI19dXkozjkaRy5cpZJFgHDBigdevWaenSpXr22Wfl4uIiOzs7OTo65lp6Z8qUKWrcuLFGjhwpSfL19dWRI0f0/vvvKyQkxGjXqlUrI/E8bNgwffjhh9q0aZMqV66s5ORk+fj46B//+IdMJpPKly9v1XnO0rNnT+MhyLBhwxQUFKSRI0eqefPmkqRBgwapZ8+eRvuAgAAFBAQY78eNG6cVK1Zo1apVxgOAfv366bvvvtO//vUv2dnZqXbt2howYIDVMdnZ2WnevHlydHRUtWrVNHbsWA0ZMkTjxo2Tg4ODunTpoqioKHXs2FGStGjRInl5ealhw4ZW9X/t2jUtWLBA5cqVkyTNmDFDrVu3VmRkpDw8PNSoUSOL9p988olcXV21efNmvfjii0bZJldX11yv7+jRoxUZGakOHTpIkipUqKAjR45o9uzZ6tGjh9EuLCxMrVu3lnT7lwrVqlXTyZMnVaVKFbm4uMhkMuW5hFNu90yW/v3766WXXpIkzZo1S2vXrtXcuXM1dOhQo83YsWPVtGnTXMeaNGmS8eAFAAAAAAAAeBDM2M+Du2fglilTRmfOnHngPtzd3eXo6GiRBHd3d89Tn3f2Z2Njo5IlS8rf39+iP0lGnwcOHNCmTZuM+uZms1lVqlSRdLtsTGJiom7cuKHnnnvO6MPNzc0iwXm3/fv368knnzSS+nfLyMjQuHHj5O/vLzc3N5nNZq1bt86YtW6thIQE46FIlnr16unEiRPKyMgwPrvznGQlebOOPyQkRPv371flypU1cOBArV+/Pk8x3H39JGU739euXTNmYaelpSksLEx+fn5ydXWV2WxWQkJCtmOfN2+efvjhB+3du1fR0dEymUxWxxQQECBHR0fjfVBQkNLS0nTq1ClJUp8+fbR+/Xr9+uuvkm4vMBsSEmL1GF5eXkZSP6v/zMxMY0b76dOn1adPH/n4+MjFxUXOzs5KS0vL0/W9fPmyEhMT1atXL4t7c/z48RaljSTLa1CmTBlJyvP38G653TNZgoKCjL9tbW1Vq1YtJSQkWLSpVavWfccaPny4Lly4YLyyrhMAAAAAAABgLWbs50HRokUt3ptMJmVmZqpIkdvPR27dumVsu3nz5n37MJlM9+zzz8R09xiSjD7T0tLUpk0bvffee9n6KlOmjE6ePGn12FkcHBxy3f7+++9r2rRpmjp1qvz9/VW8eHGFhoYadeDzW27nNDAwUD/99JPWrFmjjRs3Kjg4WE2aNNFXX32V576zzm1u5zssLEwbNmzQBx98oEqVKsnBwUEvv/xytmM/cOCALl++rCJFiiglJcVIWOeHGjVqKCAgQAsWLFCzZs10+PBhrV69Ot/679Gjh86ePatp06apfPnysre3V1BQUJ6ub1pamiRpzpw5Fg+VJBklnbLkdr4f1J/9HmYpXrz4fdvY29vL3t4+z30DAAAAAAAAWUjs54OsUiMpKSmqUaOGJFkspPsoCQwM1LJly+Tt7S1b2+yX/6mnnlLRokUVHx8vLy8vSdL58+d1/PhxNWjQIMc+q1evrl9++UXHjx/PcdZ+XFyc2rZtq3/961+Sbidhjx8/blFD3s7OzmLWfU78/PwUFxeXrW9fX99syd/cODs7q1OnTurUqZNefvlltWjRQufOnZObm5vVfVgrLi5OISEhat++vaTbCeykpCSLNufOnVNISIjeffddpaSkqGvXrtq7d+99H5hkOXDggK5evWq037Fjh8xms8U6Bb1799bUqVP166+/qkmTJjmuYXAvycnJ+u2331S2bFmj/yJFihi/4oiLi9NHH32kVq1aSZJOnTplsRizdDtxntv1dXd3V9myZfXjjz+qa9euVsd2N2vuowe1Y8cO1a9fX5KUnp6uPXv2WKynAAAAAAAAAPxVKMWTDxwcHFSnTh1j0czNmzcbde8fNW+++abOnTunzp07a9euXUpMTNS6devUs2dPZWRkyGw2q1evXhoyZIj++9//6tChQwoJCTF+lZCTBg0aqH79+nrppZe0YcMGY0b82rVrJd1ej2DDhg3atm2bEhIS9Prrr+v06dMWfXh7eys+Pl5JSUn6448/cpwtPXjwYMXExGjcuHE6fvy45s+fr5kzZ1q9QKp0u07/559/rqNHj+r48eP68ssv5eHhIVdXV6v7yAsfHx8tX75c+/fv14EDB9SlS5dsx9a3b195enpqxIgRmjJlijIyMvJ0TDdu3FCvXr105MgRfffddxo9erT69+9vcc26dOmiX375RXPmzLF60dwsxYoVU48ePXTgwAFt2bJFAwcOVHBwsFHH3sfHRwsXLlRCQoLi4+PVtWvXbA8lvL29FRMTo99//13nz5/PcZwxY8Zo0qRJmj59uo4fP66DBw8qKipKU6ZMsTpWb29vpaWlKSYmRn/88YexaHR++M9//qMVK1bo6NGjevPNN3X+/Pk8n0sAAAAAAAAgP5DYzyfz5s1Tenq6atasqdDQUI0fP76gQ8pR2bJlFRcXp4yMDDVr1kz+/v4KDQ2Vq6urkQh+//339fzzz6tNmzZq0qSJ/vGPf6hmzZq59rts2TLVrl1bnTt3VtWqVTV06FBj5vSIESMUGBio5s2bq2HDhvLw8FC7du0s9g8LC5ONjY2qVq2q0qVL51ifPTAwUEuXLtWSJUv09NNPa9SoURo7dqzFwrn34+TkpMmTJ6tWrVqqXbu2kpKS9N133+X64OLPmDJlikqUKKG6deuqTZs2at68uQIDA43tCxYs0HfffaeFCxfK1tZWxYsX16JFizRnzhytWbPGqjEaN24sHx8f1a9fX506ddI///lPhYeHW7RxcXHRSy+9JLPZnO3c30+lSpXUoUMHtWrVSs2aNVP16tX10UcfGdvnzp2r8+fPKzAwUN26ddPAgQP1xBNPWPQRGRmpDRs2yNPT0/hVy9169+6tTz/9VFFRUfL391eDBg0UHR2tChUqWB1r3bp11bdvX3Xq1EmlS5fW5MmT83SsuYmIiFBERIQCAgK0detWrVq1SqVKlcq3/gEAAAAAAABrmW7dWRgewGOrcePGqlatmqZPn271PuHh4Vq5cuUjW1rqcXDx4kW5uLjIM3Spitg73n8HAMDfUlJE64IOAQAAAMBDlpUnunDhgpydnXNtS4194DF3/vx5xcbGKjY21mKmPQAAAAAAAIDCicT+Iyo5Odlicdm7HTlyxFjcFn/e4sWL9frrr+e4rXz58jp8+PBfHNFtZrP5ntvWrFmj559//r591KhRQ+fPn9d7771nLHibpVq1avr5559z3G/27Nl5C/YRtGXLFrVs2fKe29PS0v7CaAAAAAAAAID8QSmeR1R6erqSkpLuud3b21u2tjyXyS+XLl3KtqBvlqJFi6p8+fJ/cUS3nTx58p7bypUrl22R2rz6+eefdfPmzRy3ubu7y8nJ6U/1X9CuXr2qX3/99Z7bK1Wq9BdGk7O8/MQKAAAAAAAAj6+85IlI7ANAASKxDwAAAAAAAClveaIif1FMAAAAAAAAAAAgH5DYBwAAAAAAAACgECGxDwAAAAAAAABAIUJiHwAAAAAAAACAQoTEPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIk9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8AAAAAAAAAgEKExD4AAAAAAAAAAIUIiX0AAAAAAAAAAAoREvsAAAAAAAAAABQiJPYBAAAAAAAAAChESOwDAAAAAAAAAFCI2BZ0AAAA6enR61TE3rGgwwAA/IWSIloXdAgAAAAACilm7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8ArBQSEqJ27doVdBgAAAAAAAD4myOxDwAAAAAAAABAIUJiH0Chc+PGjYIOAQAAAAAAACgwJPYB5Kphw4bq37+/+vfvLxcXF5UqVUojR47UrVu3JEkLFy5UrVq15OTkJA8PD3Xp0kVnzpyRJN26dUuVKlXSBx98YNHn/v37ZTKZdPLkSUlSamqqevfurdKlS8vZ2VmNGjXSgQMHjPbh4eF65pln9Omnn6pChQoqVqzYfePOzMzU5MmTValSJdnb28vLy0sTJkwwth88eFCNGjWSg4ODSpYsqddee01paWnG9oyMDL399ttydXVVyZIlNXToUOOY7xxj0qRJqlChghwcHBQQEKCvvvoqj2cYAAAAAAAAyBsS+wDua/78+bK1tdXOnTs1bdo0TZkyRZ9++qkk6ebNmxo3bpwOHDiglStXKikpSSEhIZIkk8mkV199VVFRURb9RUVFqX79+qpUqZIkqWPHjjpz5ozWrFmjPXv2KDAwUI0bN9a5c+eMfU6ePKlly5Zp+fLl2r9//31jHj58uCIiIjRy5EgdOXJEn332mdzd3SVJly9fVvPmzVWiRAnt2rVLX375pTZu3Kj+/fsb+0dGRio6Olrz5s3T1q1bde7cOa1YscJijEmTJmnBggX6+OOPdfjwYb311lv617/+pc2bN98zruvXr+vixYsWLwAAAAAAACAvTLfunoIKAHdo2LChzpw5o8OHD8tkMkmS3nnnHa1atUpHjhzJ1n737t2qXbu2Ll26JLPZrN9++01eXl7atm2bnn32Wd28eVNly5bVBx98oB49emjr1q1q3bq1zpw5I3t7e6OfSpUqaejQoXrttdcUHh6uiRMn6tdff1Xp0qXvG/OlS5dUunRpzZw5U7179862fc6cORo2bJhOnTql4sWLS5K+++47tWnTRr/99pvc3d1VtmxZvfXWWxoyZIgkKT09XRUqVFDNmjW1cuVKXb9+XW5ubtq4caOCgoKMvnv37q0rV67os88+yzG28PBwjRkzJtvnnqFLVcTe8b7HBgB4fCRFtC7oEAAAAAA8Qi5evCgXFxdduHBBzs7OubZlxj6A+6pTp46R1JekoKAgnThxQhkZGdqzZ4/atGkjLy8vOTk5qUGDBpKk5ORkSVLZsmXVunVrzZs3T5L0zTff6Pr16+rYsaMk6cCBA0pLS1PJkiVlNpuN108//aTExERjzPLly1uV1JekhIQEXb9+XY0bN77n9oCAACOpL0n16tVTZmamjh07pgsXLiglJUXPPfecsd3W1la1atUy3p88eVJXrlxR06ZNLeJesGCBRdx3Gz58uC5cuGC8Tp06ZdUxAQAAAAAAAFlsCzoAAIXXtWvX1Lx5czVv3lyLFy9W6dKllZycrObNm1sscNu7d29169ZNH374oaKiotSpUyc5Ot6enZ6WlqYyZcooNjY2W/+urq7G33cm4e/HwcHhgY/JWln1+FevXq1y5cpZbLvzlwd3s7e3z3U7AAAAAAAAcD8k9gHcV3x8vMX7HTt2yMfHR0ePHtXZs2cVEREhT09PSbdL8dytVatWKl68uGbNmqW1a9fq+++/N7YFBgbq999/l62trby9vfMlXh8fHzk4OCgmJibHUjx+fn6Kjo7W5cuXjQcGcXFxKlKkiCpXriwXFxeVKVNG8fHxql+/vqTbpXiy6v9LUtWqVWVvb6/k5GTjVwoAAAAAAADAX4FSPADuKzk5WW+//baOHTumzz//XDNmzNCgQYPk5eUlOzs7zZgxQz/++KNWrVqlcePGZdvfxsZGISEhGj58uHx8fCxq0jdp0kRBQUFq166d1q9fr6SkJG3btk3vvvtujg8JrFGsWDENGzZMQ4cONUrj7NixQ3PnzpUkde3aVcWKFVOPHj106NAhbdq0SQMGDFC3bt2MBXYHDRqkiIgIrVy5UkePHlW/fv2UmppqjOHk5KSwsDC99dZbmj9/vhITE7V3717NmDFD8+fPf6C4AQAAAAAAAGswYx/AfXXv3l1Xr17Vs88+KxsbGw0aNEivvfaaTCaToqOj9e9//1vTp09XYGCgPvjgA/3zn//M1kevXr00ceJE9ezZ0+Jzk8mk7777Tu+++6569uyp//3vf/Lw8FD9+vWNJPuDGDlypGxtbTVq1Cj99ttvKlOmjPr27StJcnR01Lp16zRo0CDVrl1bjo6OeumllzRlyhRj/8GDByslJUU9evRQkSJF9Oqrr6p9+/a6cOGC0WbcuHEqXbq0Jk2apB9//FGurq4KDAzUv//97weOGwAAAAAAALgf061bt24VdBAAHl0NGzbUM888o6lTp/6pfrZs2aLGjRvr1KlTfyph/7jJWu3cM3Spitg7FnQ4AIC/UFJE64IOAQAAAMAjJCtPdOHCBTk7O+falhn7AB6q69ev63//+5/Cw8PVsWNHkvoAAAAAAADAn0SNfQAP1eeff67y5csrNTVVkydPzpc+k5OTZTab7/lKTk7Ol3EAAAAAAACARxGleAAUOunp6UpKSrrndm9vb9naFo4fJOXlJ1YAAAAAAAB4fFGKB8BjzdbWVpUqVSroMAAAAAAAAIACQSkeAAAAAAAAAAAKERL7AAAAAAAAAAAUIiT2AQAAAAAAAAAoREjsAwAAAAAAAABQiJDYBwAAAAAAAACgECGxDwAAAAAAAABAIUJiHwAAAAAAAACAQoTEPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIk9gEAAAAAAAAAKERI7AMAAAAAAAAAUIiQ2AcAAAAAAAAAoBAhsQ8AAAAAAAAAQCFCYh8AAAAAAAAAgEKExD4AAAAAAAAAAIUIiX0AAAAAAAAAAAoR24IOAAAgPT16nYrYOxZ0GACAfJIU0bqgQwAAAADwGGPGPgAAAAAAAAAAhQiJfQAAAAAAAAAAChES+wAAAAAAAAAAFCIk9h8zDRs2VGhoqPHe29tbU6dOfahjxsbGymQyKTU19aGO8ygymUxauXKlJCkpKUkmk0n79+//y8b/K67vw3L3vfqoio6Olqura0GHAQAAAAAAABhYPPcxt2vXLhUvXjzf+mvYsKGeeeYZi2Ry3bp1lZKSIhcXl3wbpzDy9PRUSkqKSpUqVdChPFJiY2P1wgsv6Pz58xYJ8uXLl6to0f/H3p3H13Tt/x9/HYmQWUNIRDhUEqGGmMNtm6o2VAdVYrpSilJSUlLDRcUcQ8y0vVVJqKG0qq5Zc1FiVkKVIFfEbdPmooaUEuH3h1/21xGJE1Jp9P18PM7j4WSvvdZnr7WPPz57788uXqBjde3alQsXLhgXW0RERERERERERB5HSuw/5tzd3f/wMezs7PDw8PjDx/mzs7Gx0Tzkg5ubW2GH8Ie5fv06dnZ2hR2GiIiIiIiIiIg8ph67UjxBQUH069ePQYMG4ebmhoeHB5GRkcC9S6VcuHABk8nEli1bgP8rK7NhwwYCAgKwt7enWbNmpKens27dOvz9/XFxcaFTp05cuXLF6pjeffddwsPDeeKJJyhXrhyffPIJv/32G926dcPZ2ZmqVauybt06i/2+//57WrZsiZOTE+XKlaNLly6cPXvW2P7bb78RGhqKk5MTnp6eREdH5xj77lItFy5coFevXpQrV46SJUvy1FNPsXr1agDOnTtHx44d8fLywsHBgZo1a7JkyRJj365du7J161ZmzJiByWTCZDKRkpJyz1I8X375JTVq1KBEiRKYzeYcsZnNZsaPH89bb72Fs7MzFStW5J///Kex/fr164SFheHp6UnJkiWpVKkSEyZMsGq+TSYTH3/8MS+//DIODg74+/uzc+dOTp48SVBQEI6OjjRp0oTk5GSL/b7++mvq1q1LyZIlqVKlCqNGjeLGjRvG9hMnTvDMM89QsmRJqlevzqZNmyz2v/v8ysrKonv37lSuXBl7e3v8/PyYMWOGxT5du3aldevWTJkyBU9PT0qXLk3fvn3JzMy06lgBLl++TMeOHXF0dMTLy4s5c+YY29566y1efvlli/aZmZmULVuWTz/99L59BwUFERYWRlhYGK6urpQpU4YRI0Zw69Yto83ChQupX78+zs7OeHh40KlTJ9LT0405ee655wB44oknMJlMdO3a1ej7zlI8165dIyIiAi8vLxwdHWnUqJHxu4T/K4mzYcMG/P39cXJyokWLFqSlpQEQGRlJXFwcX3/9tXF+3rn/vWSv2YoVK3juuedwcHCgdu3a7Ny5M0fblStX4uPjQ8mSJQkODubMmTPGtsjISOrUqcO8efOoXLkyJUuWvO/cioiIiIiIiIiIPKjHLrEPEBcXh6OjI7t372bSpEmMHj06RxL2fiIjI5k9ezY7duzgzJkzhISEMH36dBYvXsyaNWvYuHEjs2bNyldMZcqUYc+ePbz77ru88847tGvXjiZNmvDdd9/x4osv0qVLF+NiwYULF2jWrBkBAQHs27eP9evX88svvxASEmL0+f7777N161a+/vprNm7cyJYtW/juu+9yjeHmzZu0bNmShIQEPvvsM3744QeioqKwsbEB4Pfff6devXqsWbOG77//nrfffpsuXbqwZ88eAGbMmEFgYCA9e/YkLS2NtLQ0vL29c4yzf/9+QkJC6NChA4cPHyYyMpIRI0YQGxtr0S46Opr69etz4MAB+vTpwzvvvENSUhIAM2fOZNWqVSxbtoykpCQWLVqE2Wy2er7HjBlDaGgoBw8epFq1anTq1IlevXoxdOhQ9u3bx61btwgLCzPab9u2jdDQUPr3788PP/zAxx9/TGxsLOPGjTPmrk2bNtjZ2bF7924++ugjBg8enGcMN2/epEKFCixfvpwffviBDz74gH/84x8sW7bMot3mzZtJTk5m8+bNxMXFERsbm2Ou8jJ58mRq167NgQMHGDJkCP379zfO9x49erB+/Xoj+Q2wevVqrly5Qvv27a3qPy4uDltbW/bs2cOMGTOYOnUq8+bNM7ZnZmYyZswYEhMTWblyJSkpKUby3tvbmy+//BKApKQk0tLSclzcyBYWFsbOnTtZunQphw4dol27drRo0YITJ04Yba5cucKUKVNYuHAh3377LampqURERAAQERFBSEiIkexPS0ujSZMmVh3jsGHDiIiI4ODBg/j6+tKxY0eLizpXrlxh3LhxLFiwgISEBC5cuECHDh0s+jh58iRffvklK1asyPM9C9euXePSpUsWHxERERERERERkfx4LEvx1KpVi5EjRwLg4+PD7NmziY+Px8fHx+o+xo4dS9OmTQHo3r07Q4cOJTk5mSpVqgDQtm1bNm/efN/kbrbatWszfPhwAIYOHUpUVBRlypShZ8+eAHzwwQd8+OGHHDp0iMaNGzN79mwCAgIYP3680cf8+fPx9vbm+PHjlC9fnk8//ZTPPvuM559/HridgK1QoUKuMXzzzTfs2bOHo0eP4uvrC2AcD4CXl5eRJAV499132bBhA8uWLaNhw4a4urpiZ2eHg4NDniVnpk6dyvPPP8+IESMA8PX15YcffmDy5MlGwhfgpZdeok+fPgAMHjyYadOmsXnzZvz8/EhNTcXHx4e//e1vmEwmKlWqZNU8Z+vWrZtxEWTw4MEEBgYyYsQIgoODAejfvz/dunUz2o8aNYohQ4bw5ptvGvMyZswYBg0axMiRI/nmm284duwYGzZsoHz58gCMHz+eli1b5hpD8eLFGTVqlPG9cuXK7Ny5k2XLlllcoHniiSeYPXs2NjY2VKtWjVatWhEfH2+cG/fTtGlThgwZAtye64SEBKZNm8YLL7xAkyZN8PPzY+HChQwaNAiAmJgY2rVrh5OTk1X9e3t7M23aNEwmE35+fhw+fJhp06YZ8b311ltG2ypVqjBz5kwaNGhARkYGTk5ORsmdsmXL5voS2tTUVGJiYkhNTTXmNyIigvXr1xMTE2P8DjIzM/noo4948skngdsXA0aPHg2Ak5MT9vb2XLt2Ld8lkSIiImjVqhVw+1yoUaMGJ0+epFq1asa4s2fPplGjRsDt35q/vz979uyhYcOGwO2nTBYsWHDf8lcTJkywOC9ERERERERERETy67G8Y79WrVoW3z09PY3SIA/SR7ly5XBwcLBIgpcrVy5ffd7Zn42NDaVLl6ZmzZoW/QFGn4mJiWzevBknJyfjk51kTE5OJjk5mevXrxuJRrhds9zPzy/XGA4ePEiFChWMpP7dsrKyGDNmDDVr1sTNzQ0nJyc2bNhAamqq1ccJcPToUeOiSLamTZty4sQJsrKyjL/dOScmkwkPDw/j+Lt27crBgwfx8/OjX79+bNy4MV8x3L1+QI75/v333427pRMTExk9erTFfGc/mXDlyhWOHj2Kt7e3kXQGCAwMvG8cc+bMoV69eri7u+Pk5MQ///nPHPNZo0YN46kJyP/5enccgYGBHD161Pjeo0cPYmJiAPjll19Yt26dRTL+fho3bozJZLLo/8613L9/P6+88goVK1bE2dmZZ599FiBf583hw4fJysrC19fXYg22bt1qUTLJwcHBSOrDg/227+XO88XT0xPAol9bW1saNGhgfK9WrRqlSpWymOdKlSpZ9U6LoUOHcvHiReNzZ0kfERERERERERERazyWd+wXL17c4rvJZOLmzZsUK3b7Osad9cFzq2V+Zx8mkynXPh8mprvHAIw+MzIyeOWVV5g4cWKOvjw9PTl58qTVY2ezt7fPc/vkyZOZMWMG06dPp2bNmjg6OhIeHs7169fzPZY18prTunXrcurUKdatW8c333xDSEgIzZs354svvsh339lze7/5HjVqFG3atMnR14PWS1+6dCkRERFER0cTGBiIs7MzkydPZvfu3bnGmh1bfs6t+wkNDWXIkCHs3LmTHTt2ULlyZZ5++ukC6fu3334jODiY4OBgFi1ahLu7O6mpqQQHB+frvMnIyMDGxob9+/dbXOQALJ4suNdc3fl7flB5nRvWcnR0tKpdiRIlKFGiRL76FhERERERERERudNjmdjPTfbdtGlpaQQEBADkWQu7MNWtW5cvv/wSs9mMrW3OZXryyScpXrw4u3fvpmLFigD8+uuvHD9+3Lhj+m61atXiv//9L8ePH7/nXfsJCQm89tpr/P3vfwduJzaPHz9O9erVjTZ2dnYWd93fi7+/PwkJCTn69vX1zZG0zYuLiwvt27enffv2tG3blhYtWnD+/HmjtEtBqlu3LklJSVStWvWe2/39/Tlz5gxpaWnGHd27du3Ks8+EhASaNGlilBsCcrywtyDcHceuXbvw9/c3vpcuXZrWrVsTExPDzp07LUoQWePuCxG7du3Cx8cHGxsbjh07xrlz54iKijLet7Bv3z6L9nZ2dgB5njcBAQFkZWWRnp7+UBcdrDk/H8SNGzfYt2+fUXYnKSmJCxcuWMyziIiIiIiIiIjIo/JYluLJjb29PY0bNyYqKoqjR4+ydetWo+79n03fvn05f/48HTt2ZO/evSQnJ7Nhwwa6detGVlYWTk5OdO/enffff59///vffP/993Tt2tV4KuFenn32WZ555hneeOMNNm3aZNwRv379euD2+wg2bdrEjh07OHr0KL169eKXX36x6MNsNrN7925SUlI4e/bsPe9qHjhwIPHx8YwZM4bjx48TFxfH7NmzLer338/UqVNZsmQJx44d4/jx4yxfvhwPD49ca7Q/rA8++IAFCxYwatQojhw5wtGjR1m6dKlxfjRv3hxfX1/efPNNEhMT2bZtG8OGDcuzTx8fH/bt28eGDRs4fvw4I0aMYO/evQUee0JCApMmTeL48ePMmTOH5cuX079/f4s2PXr0IC4ujqNHjxrvEbBWamoqAwYMICkpiYh/ZAAAi+lJREFUiSVLljBr1iyj/4oVK2JnZ8esWbP4z3/+w6pVqxgzZozF/pUqVcJkMrF69Wr+97//kZGRkWMMX19fOnfuTGhoKCtWrODUqVPs2bOHCRMmsGbNGqtjNZvNHDp0iKSkJM6ePZvrEzn5Vbx4cd599112797N/v376dq1K40bNzYS/SIiIiIiIiIiIo/SXyqxD7dfQHvjxg3q1atHeHg4Y8eOLeyQ7ql8+fIkJCSQlZXFiy++SM2aNQkPD6dUqVJG8n7y5Mk8/fTTvPLKKzRv3py//e1v1KtXL89+v/zySxo0aEDHjh2pXr06gwYNMu5wHj58OHXr1iU4OJigoCA8PDxo3bq1xf4RERHY2NhQvXp1o+zK3erWrcuyZctYunQpTz31FB988AGjR4+2eHHu/Tg7OzNp0iTq169PgwYNSElJYe3atXleuHgYwcHBrF69mo0bN9KgQQMaN27MtGnTjJf2FitWjK+++oqrV6/SsGFDevTowbhx4/Lss1evXrRp04b27dvTqFEjzp07Z3H3fkEZOHAg+/btIyAggLFjxzJ16lTjJcHZmjdvjqenJ8HBwRbvCbBGaGiocdx9+/alf//+vP3228Dtp2BiY2NZvnw51atXJyoqiilTpljs7+XlZbycuFy5coSFhd1znJiYGEJDQxk4cCB+fn60bt2avXv3Gk+kWKNnz574+flRv3593N3dczw58qAcHBwYPHgwnTp1omnTpjg5OfH5558XSN8iIiIiIiIiIiL5ZbpVEAWqReRPLSMjAy8vL2JiYu75HoHcBAUFUadOHaZPn/7HBfcXd+nSJVxdXfEOX0axEg6FHY6IiBSQlKhWhR2CiIiIiIgUMdl5oosXL+Li4pJn279UjX2Rv5qbN29y9uxZoqOjKVWqFK+++mphhyQiIiIiIiIiIiIP6S9Xiqegpaam4uTklOvnXqVq5MEtWrQo17muUaNGYYdXoLZt25bnuWWN1NRUypUrx+LFi5k/f77Fi5j/Cufu+PHjcz2+li1bFnZ4IiIiIiIiIiIiD0SleB7SjRs3SElJyXW72Wy2SKbKw7l8+XKOF/pmK168uFET/3Fw9epVfvzxx1y3V61a9aH6/yucu+fPn+f8+fP33GZvb4+Xl9cjjiin/DxiJSIiIiIiIiIij6/85ImU2BcRKURK7IuIiIiIiIiICOQvT6RSPCIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYhtYQcgIiLw1MgNFCvhUNhhiIjIHVKiWhV2CCIiIiIiIvekO/ZFRERERERERERERIoQJfZFRERERERERERERIoQJfZFRERERERERERERIoQJfblDxcUFER4eHhhh/FY6tq1K61bty7sMB5IZGQkderUKeww7islJQWTycTBgwcLOxQRERERERERERFAiX0ReQRMJhMrV660+FtERATx8fEFOk5sbCylSpUq0D5FRERERERERET+bJTY/4u4fv16YYfwUDIzMws7BClgTk5OlC5durDD+EPcunWLGzduFHYYIiIiIiIiIiLymFJi/z6CgoLo168fgwYNws3NDQ8PDyIjI4F7l+i4cOECJpOJLVu2ALBlyxZMJhMbNmwgICAAe3t7mjVrRnp6OuvWrcPf3x8XFxc6derElStXrI4pLCyMsLAwXF1dKVOmDCNGjODWrVtGG7PZzJgxYwgNDcXFxYW3334bgC+//JIaNWpQokQJzGYz0dHRFn1fu3aNwYMH4+3tTYkSJahatSqffvqpsf3777+nZcuWODk5Ua5cObp06cLZs2eN7b/99huhoaE4OTnh6emZo3+4993bpUqVIjY21mJeP//8c5599llKlizJokWLAJg3bx7+/v6ULFmSatWqMXfuXKOP69evExYWhqenJyVLlqRSpUpMmDDBqjk1mUx8/PHHvPzyyzg4OODv78/OnTs5efIkQUFBODo60qRJE5KTky32+/rrr6lbty4lS5akSpUqjBo1yiKhO3XqVGrWrImjoyPe3t706dOHjIwMY3v2HeYbNmzA398fJycnWrRoQVpamlVxZxs1ahTu7u64uLjQu3dv40LOggULKF26NNeuXbNo37p1a7p06XLffrPL5Xz88cd4e3vj4OBASEgIFy9eNNrs3buXF154gTJlyuDq6sqzzz7Ld999Z2w3m80AvP7665hMJuP7vUrx5LW+2efFihUreO6553BwcKB27drs3LkTuP1b69atGxcvXsRkMmEymYzfal7MZjPjx4/nrbfewtnZmYoVK/LPf/4zR7tjx47RpEkTSpYsyVNPPcXWrVuNbdm/83Xr1lGvXj1KlCjB9u3b7zu2iIiIiIiIiIjIg1Bi3wpxcXE4Ojqye/duJk2axOjRo9m0aVO++oiMjGT27Nns2LGDM2fOEBISwvTp01m8eDFr1qxh48aNzJo1K18x2drasmfPHmbMmMHUqVOZN2+eRZspU6ZQu3ZtDhw4wIgRI9i/fz8hISF06NCBw4cPExkZyYgRI4yEOkBoaChLlixh5syZHD16lI8//hgnJyfg9kWLZs2aERAQwL59+1i/fj2//PILISEhxv7vv/8+W7du5euvv2bjxo1s2bLFIsmbH0OGDKF///4cPXqU4OBgFi1axAcffMC4ceM4evQo48ePZ8SIEcTFxQEwc+ZMVq1axbJly0hKSmLRokVGEtka2RdCDh48SLVq1ejUqRO9evVi6NCh7Nu3j1u3bhEWFma037ZtG6GhofTv358ffviBjz/+mNjYWMaNG2e0KVasGDNnzuTIkSPExcXx73//m0GDBlmMe+XKFaZMmcLChQv59ttvSU1NJSIiwuq44+PjOXr0KFu2bGHJkiWsWLGCUaNGAdCuXTuysrJYtWqV0T49PZ01a9bw1ltvWdX/yZMnWbZsGf/6179Yv349Bw4coE+fPsb2y5cv8+abb7J9+3Z27dqFj48PL730EpcvXwZuJ/4BYmJiSEtLM77f7X7rm23YsGFERERw8OBBfH196dixIzdu3KBJkyZMnz4dFxcX0tLSSEtLs3oeo6OjqV+/vnFs77zzDklJSRZt3n//fQYOHMiBAwcIDAzklVde4dy5cxZthgwZQlRUFEePHqVWrVr3HOvatWtcunTJ4iMiIiIiIiIiIpIftoUdQFFQq1YtRo4cCYCPjw+zZ88mPj4eHx8fq/sYO3YsTZs2BaB79+4MHTqU5ORkqlSpAkDbtm3ZvHkzgwcPtqo/b29vpk2bhslkws/Pj8OHDzNt2jR69uxptGnWrBkDBw40vnfu3Jnnn3+eESNGAODr68sPP/zA5MmT6dq1K8ePH2fZsmVs2rSJ5s2bAxjxAcyePZuAgADGjx9v/G3+/Pl4e3tz/Phxypcvz6effspnn33G888/D9y+AFGhQgWr5+lO4eHhtGnTxvg+cuRIoqOjjb9VrlzZSKi/+eabpKam4uPjw9/+9jdMJhOVKlXK13jdunUzLlIMHjyYwMBARowYQXBwMAD9+/enW7duRvtRo0YxZMgQ3nzzTeD2XI0ZM4ZBgwYZ58udLw02m82MHTuW3r17W9yJnpmZyUcffcSTTz4JQFhYGKNHj7Y6bjs7O+bPn4+DgwM1atRg9OjRvP/++4wZMwZ7e3s6depETEwM7dq1A+Czzz6jYsWKBAUFWdX/77//zoIFC/Dy8gJg1qxZtGrViujoaDw8PGjWrJlF+3/+85+UKlWKrVu38vLLL+Pu7g7cfirDw8Mj13Hut77ZIiIiaNWqFXB7DWrUqMHJkyepVq0arq6umEymPMe5l5deesm4WDF48GCmTZvG5s2b8fPzM9qEhYXxxhtvAPDhhx+yfv16Pv30U4sLNaNHj+aFF17Ic6wJEyYYF15EREREREREREQehO7Yt8Ldd956enqSnp7+wH2UK1cOBwcHi6R5uXLl8tVn48aNMZlMxvfAwEBOnDhBVlaW8bf69etb7HP06FHj4kK2pk2bGvsdPHgQGxsbnn322XuOmZiYyObNm3FycjI+1apVAyA5OZnk5GSuX79Oo0aNjH3c3NwskqP5cWf8v/32G8nJyXTv3t1i/LFjxxrlcbp27crBgwfx8/OjX79+bNy4MV/j3b1GADVr1rT42++//27cYZ2YmMjo0aMt4unZsydpaWlGWaVvvvmG559/Hi8vL5ydnenSpQvnzp2zKLvk4OBgJPUh/+dX7dq1cXBwML4HBgaSkZHBmTNnAOjZsycbN27kxx9/BG6X/+natavF+ZOXihUrGkn97P5v3rxp3NH+yy+/0LNnT3x8fHB1dcXFxYWMjAxSU1OtPgZr1jfbnevk6ekJkO/f493u7DP7wsDdfQYGBhr/trW1pX79+hw9etSizd2/uXsZOnQoFy9eND7Z6yQiIiIiIiIiImIt3bFvheLFi1t8N5lM3Lx5k2LFbl8XubO2fW4veb2zD5PJlGufBcnR0TFf7e3t7fPcnpGRwSuvvMLEiRNzbPP09OTkyZNWjWMymSzmDO49b3fGn12X/pNPPrG4cABgY2MDQN26dTl16hTr1q3jm2++ISQkhObNm/PFF19YFdfda5Tb37LXKSMjg1GjRlk8VZCtZMmSpKSk8PLLL/POO+8wbtw43Nzc2L59O927d+f69etGMv5e58Ld8/MwAgICqF27NgsWLODFF1/kyJEjrFmzpsD6f/PNNzl37hwzZsygUqVKlChRgsDAwHy9sNma9c2W15o8qIL6PVrzmytRogQlSpTId98iIiIiIiIiIiLZlNh/CNklRtLS0ggICACweJHuH2n37t0W37Nrm9+dBL2Tv78/CQkJFn9LSEjA19cXGxsbatasyc2bN9m6datRiudOdevW5csvv8RsNmNrm/PUefLJJylevDi7d++mYsWKAPz6668cP37c4ikAd3d3i5fDnjhx4r4vDi5Xrhzly5fnP//5D507d861nYuLC+3bt6d9+/a0bduWFi1acP78edzc3PLs/0HUrVuXpKQkqlates/t+/fv5+bNm0RHRxsXgZYtW1bgcSQmJnL16lXjwsyuXbtwcnLC29vbaNOjRw+mT5/Ojz/+SPPmzS223U9qaio//fQT5cuXN/ovVqyY8SRGQkICc+fO5aWXXgLgzJkzFi9UhtuJ8zufJrmbtet7P3Z2dnmO8zB27drFM888A8CNGzfYv3+/xTsXREREREREREREHhUl9h+Cvb09jRs3JioqisqVK5Oens7w4cMfydipqakMGDCAXr168d133zFr1iyio6Pz3GfgwIE0aNCAMWPG0L59e3bu3Mns2bONeu9ms5k333yTt956i5kzZ1K7dm1Onz5Neno6ISEh9O3bl08++YSOHTsyaNAg3NzcOHnyJEuXLmXevHk4OTnRvXt33n//fUqXLk3ZsmUZNmyYkdTO1qxZM2bPnk1gYCBZWVkMHjw4xx3T9zJq1Cj69euHq6srLVq04Nq1a+zbt49ff/2VAQMGMHXqVDw9PQkICKBYsWIsX74cDw8PSpUq9cDznJcPPviAl19+mYoVK9K2bVuKFStGYmIi33//PWPHjqVq1apkZmYya9YsXnnlFRISEvjoo48KPI7r16/TvXt3hg8fTkpKCiNHjiQsLMxi3jt16kRERASffPIJCxYsyFf/JUuW5M0332TKlClcunSJfv36ERISYtSx9/HxYeHChdSvX59Lly7x/vvv53j6w2w2Ex8fT9OmTSlRogRPPPFEjnHut77WMJvNZGRkEB8fb5QourNM0cOYM2cOPj4++Pv7M23aNH799VerX0AsIiIiIiIiIiJSkFRj/yHNnz+fGzduUK9ePcLDwxk7duwjGTc0NJSrV6/SsGFD+vbtS//+/Xn77bfz3Kdu3bosW7aMpUuX8tRTT/HBBx8wevRounbtarT58MMPadu2LX369KFatWr07NmT3377DYDy5cuTkJBAVlYWL774IjVr1iQ8PJxSpUoZSeTJkyfz9NNP88orr9C8eXP+9re/Ua9ePYs4oqOj8fb25umnnzYSztYkX3v06MG8efOIiYmhZs2aPPvss8TGxlK5cmUAnJ2dmTRpEvXr16dBgwakpKSwdu3aHBcWCkpwcDCrV69m48aNNGjQgMaNGzNt2jTjpb21a9dm6tSpTJw4kaeeeopFixYxYcKEAo/j+eefx8fHh2eeeYb27dvz6quvEhkZadHG1dWVN954AycnJ1q3bp2v/qtWrUqbNm146aWXePHFF6lVq5bFy38//fRTfv31V+rWrUuXLl3o168fZcuWtegjOjqaTZs24e3tbTzdcrf7ra81mjRpQu/evWnfvj3u7u5MmjQpX8eal6ioKKKioqhduzbbt29n1apVlClTpsD6FxERERERERERsZbpVkEW85ZHIigoiDp16jB9+vTCDkWKkOeff54aNWowc+ZMq/eJjIxk5cqVj6zE1F/RpUuXcHV1xTt8GcVKFMzTBSIiUjBSoloVdggiIiIiIvIXkp0nunjxIi4uLnm2VSkekcfcr7/+ypYtW9iyZYvFnfYiIiIiIiIiIiJSNCmx/yeTmppK9erVc93+ww8/PMJoHg+LFi2iV69e99xWqVIljhw58ogjsp6Tk1Ou29atW8fTTz993z4CAgL49ddfmThxovHC22w1atTg9OnT99zv448/zl+wf0Lbtm2jZcuWuW7PyMh4hNGIiIiIiIiIiIgUDJXi+ZO5ceMGKSkpuW43m83Y2up6TH5cvnyZX3755Z7bihcvbtTE/zM6efJkrtu8vLxyvKQ2v06fPk1mZuY9t5UrVw5nZ+eH6r+wXb16lR9//DHX7VWrVn2E0dxbfh6xEhERERERERGRx1d+8kRK7IuIFCIl9kVEREREREREBPKXJyr2iGISEREREREREREREZECoMS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRYlvYAYiICDw1cgPFSjgUdhgiIn8pKVGtCjsEERERERGRB6I79kVEREREREREREREihAl9kVEREREREREREREihAl9kVEREREREREREREihAl9h+BLVu2YDKZuHDhQqHFEBsbS6lSpQqsv6CgIMLDwwusvwcRGRlJnTp1/jT9FIY/w7n1oFJSUjCZTBw8eLCwQ7mvP8P5LiIiIiIiIiIikk2J/T/A3UnAJk2akJaWhqura6HF1L59e44fP15o4/8RIiIiiI+PN7537dqV1q1bF15Akqt7rY23tzdpaWk89dRTBTqWyWRi5cqVBdqniIiIiIiIiIjIn4ltYQfwV2BnZ4eHh0ehxmBvb4+9vX2hxlDQnJyccHJyKuww5AHZ2NgU+u/ij3T9+nXs7OwKOwwREREREREREXkM6Y79Ata1a1e2bt3KjBkzMJlMmEwmYmNjLcqlZJfFWb16NX5+fjg4ONC2bVuuXLlCXFwcZrOZJ554gn79+pGVlWX0fe3aNSIiIvDy8sLR0ZFGjRqxZcsWq+K6uxRPdvmZhQsXYjabcXV1pUOHDly+fNnqY7158yaDBg3Czc0NDw8PIiMjLbanpqby2muv4eTkhIuLCyEhIfzyyy/G9sTERJ577jmcnZ1xcXGhXr167Nu3zyLelStX4uPjQ8mSJQkODubMmTM5jiH733FxcXz99dfGvGfPzeDBg/H19cXBwYEqVaowYsQIMjMzrT7OO23ZsoWGDRvi6OhIqVKlaNq0KadPnwbufVd6eHg4QUFBxvegoCDeffddwsPDeeKJJyhXrhyffPIJv/32G926dcPZ2ZmqVauybt26fMWVkJBArVq1KFmyJI0bN+b7778H4LfffsPFxYUvvvjCov3KlStxdHS873pnl8tZunQpTZo0oWTJkjz11FNs3brVaJOVlUX37t2pXLky9vb2+Pn5MWPGDGN7bmtzr1I833//PS1btsTJyYly5crRpUsXzp49azF//fr1y/W8M5vNALz++uuYTCbje16s/S3cuHGDsLAwXF1dKVOmDCNGjODWrVsWY48ZM4bQ0FBcXFx4++237zu2iIiIiIiIiIjIg1Biv4DNmDGDwMBAevbsSVpaGmlpaXh7e+dod+XKFWbOnMnSpUtZv349W7Zs4fXXX2ft2rWsXbuWhQsX8vHHH1skZMPCwti5cydLly7l0KFDtGvXjhYtWnDixIkHijU5OZmVK1eyevVqVq9ezdatW4mKirJ6/7i4OBwdHdm9ezeTJk1i9OjRbNq0Cbid9H/ttdc4f/48W7duZdOmTfznP/+hffv2xv6dO3emQoUK7N27l/379zNkyBCKFy9uMUfjxo1jwYIFJCQkcOHCBTp06HDPWCIiIggJCaFFixbGvDdp0gQAZ2dnYmNj+eGHH5gxYwaffPIJ06ZNy/d83bhxg9atW/Pss89y6NAhdu7cydtvv43JZMpXP3FxcZQpU4Y9e/bw7rvv8s4779CuXTuaNGnCd999x4svvkiXLl24cuWK1X2+//77REdHs3fvXtzd3XnllVfIzMzE0dGRDh06EBMTY9E+JiaGtm3b4uzsbHX/AwcO5MCBAwQGBvLKK69w7tw54PZaV6hQgeXLl/PDDz/wwQcf8I9//INly5YBea/NnS5cuECzZs0ICAhg3759rF+/nl9++YWQkJAc85fbebd3717j+NLS0ozv92PNbyEuLg5bW1v27NnDjBkzmDp1KvPmzbNoM2XKFGrXrs2BAwcYMWLEPce6du0aly5dsviIiIiIiIiIiIjkh0rxFDBXV1fs7OxwcHAwyowcO3YsR7vMzEw+/PBDnnzySQDatm3LwoUL+eWXX3BycqJ69eo899xzbN68mfbt25OamkpMTAypqamUL18euJ0wXb9+PTExMYwfPz7fsd68eZPY2FgjudulSxfi4+MZN26cVfvXqlWLkSNHAuDj48Ps2bOJj4/nhRdeID4+nsOHD3Pq1CnjwsaCBQuoUaMGe/fupUGDBqSmpvL+++9TrVo1o4+752j27Nk0atQIuJ1Y9ff3Z8+ePTRs2NCirZOTE/b29ly7di1HeZfhw4cb/zabzURERLB06VIGDRpk7VQBcOnSJS5evMjLL79srJu/v3+++gCoXbu2EdPQoUOJioqiTJky9OzZE4APPviADz/8kEOHDtG4cWOr+hw5ciQvvPACcHueKlSowFdffUVISAg9evQw3vPg6elJeno6a9eu5ZtvvrE65rCwMN544w0APvzwQ9avX8+nn37KoEGDKF68OKNGjTLaVq5cmZ07d7Js2TJCQkLyXJs7zZ49m4CAAItzef78+Xh7e3P8+HF8fX2BvM87d3d3AEqVKpWvMj/W/Ba8vb2ZNm0aJpMJPz8/Dh8+zLRp04x1A2jWrBkDBw7Mc6wJEyZYzJeIiIiIiIiIiEh+6Y79QuLg4GAkhwHKlSuH2Wy2qBlfrlw50tPTATh8+DBZWVn4+voateWdnJzYunUrycnJDxSD2Wy2uGM7O+lrrVq1all8v3P/o0eP4u3tbfG0QvXq1SlVqhRHjx4FYMCAAfTo0YPmzZsTFRWV4zhsbW1p0KCB8b1atWoW+1vr888/p2nTpnh4eODk5MTw4cNJTU3NVx8Abm5udO3aleDgYF555RVmzJhBWlpavvu5c95sbGwoXbo0NWvWNP5Wrlw5gHytRWBgoEWcfn5+xjw1bNiQGjVqEBcXB8Bnn31GpUqVeOaZZx6of1tbW+rXr2+xDnPmzKFevXq4u7vj5OTEP//5z3zPcWJiIps3b7Y4v7Mv+tx5buR13j0oa34LjRs3tng6IzAwkBMnTliUy6pfv/59xxo6dCgXL140PneWlxIREREREREREbGGEvuF5M6SMwAmk+mef7t58yYAGRkZ2NjYsH//fg4ePGh8jh49alHP/GFjyB7vUewfGRnJkSNHaNWqFf/+97+pXr06X331ldX7W2Pnzp107tyZl156idWrV3PgwAGGDRvG9evXH6i/mJgYdu7cSZMmTfj888/x9fVl165dABQrVsyi5jpwz1r+91v77ORxfubyfnr06EFsbKxxDN26dct3CaHcLF26lIiICLp3787GjRs5ePAg3bp1y/ccZ2Rk8Morr1ic3wcPHuTEiRMWFyEe9ry7l4Lq09HR8b5tSpQogYuLi8VHREREREREREQkP5TY/wPY2dlZ3MVbEAICAsjKyiI9PZ2qVatafPJTcuRR8ff358yZMxZ3I//www9cuHCB6tWrG3/z9fXlvffeY+PGjbRp08aiFvyNGzeMl+kCJCUlceHChVzL39xr3nfs2EGlSpUYNmwY9evXx8fHx3jZ7YMKCAhg6NCh7Nixg6eeeorFixcD4O7unuMO/jtfDPtHyr64APDrr79y/Phxi3n6+9//zunTp5k5cyY//PADb7755gP3f+PGDfbv32/0n5CQQJMmTejTpw8BAQFUrVo1x9MX1vwm6taty5EjRzCbzTnOcWsS5tmKFy9e4L8/gN27d1t837VrFz4+PtjY2BT4WCIiIiIiIiIiInlRYv8PYDab2b17NykpKZw9e7ZA7rz29fWlc+fOhIaGsmLFCk6dOsWePXuYMGECa9asKYCoC1bz5s2pWbMmnTt35rvvvmPPnj2Ehoby7LPPUr9+fa5evUpYWBhbtmzh9OnTJCQksHfvXotkdPHixXn33XfZvXs3+/fvp2vXrjRu3DhHff1sZrOZQ4cOkZSUxNmzZ8nMzMTHx4fU1FSWLl1KcnIyM2fOfOCnAk6dOsXQoUPZuXMnp0+fZuPGjZw4ccKIuVmzZuzbt48FCxZw4sQJRo4cyffff/9AY+XX6NGjiY+P5/vvv6dr166UKVOG1q1bG9ufeOIJ2rRpw/vvv8+LL75IhQoV8tX/nDlz+Oqrrzh27Bh9+/bl119/5a233gJu17nft28fGzZs4Pjx44wYMSLHS2vvtTZ369u3L+fPn6djx47s3buX5ORkNmzYQLdu3fKVqDebzcTHx/Pzzz/z66+/5us485KamsqAAQNISkpiyZIlzJo1i/79+xdY/yIiIiIiIiIiItZSYv8PEBERgY2NDdWrV8fd3f2B6rnfS0xMDKGhoQwcOBA/Pz9at27N3r17qVixYoH0X5BMJhNff/01TzzxBM888wzNmzenSpUqfP7558Dt2vLnzp0jNDQUX19fQkJCaNmypcVLRR0cHBg8eDCdOnWiadOmODk5GfvfS8+ePfHz86N+/fq4u7uTkJDAq6++ynvvvUdYWBh16tRhx44djBgx4oGOycHBgWPHjvHGG2/g6+vL22+/Td++fenVqxcAwcHBjBgxgkGDBtGgQQMuX75MaGjoA42VX1FRUfTv35969erx888/869//Qs7OzuLNt27d+f69etGQj6//UdFRVG7dm22b9/OqlWrKFOmDAC9evWiTZs2tG/fnkaNGnHu3Dn69Oljsf+91uZu5cuXJyEhgaysLF588UVq1qxJeHg4pUqVolgx6/+rio6OZtOmTXh7exMQEJDvY81NaGgoV69epWHDhvTt25f+/fvz9ttvF1j/IiIiIiIiIiIi1jLdursouMifQGxsLOHh4Vy4cKGwQ3lsLFy4kPfee4+ffvopR9I/NykpKVSuXJkDBw5Qp06dPzbAv6hLly7h6uqKd/gyipVwKOxwRET+UlKiWhV2CCIiIiIiIobsPNHFixfv+15G20cUk4gUkitXrpCWlkZUVBS9evWyOqkvIiIiIiIiIiIif04qxfOYaNmyJU5OTvf8jB8/Pl99paam5tqXk5NTgZUW+jPK67i3bdv2yOPp3bt3rvH07t3bqj4mTZpEtWrV8PDwYOjQoRbbxo8fn2v/LVu2/CMO6ZGrUaNGrse4aNGiwg5PREREREREREQk31SK5zHx448/cvXq1Xtuc3Nzw83Nzeq+bty4QUpKSq7bzWYztraP58MeJ0+ezHWbl5cX9vb2jzAaSE9P59KlS/fc5uLiQtmyZR+q//Pnz3P+/Pl7brO3t8fLy+uh+v8zOH369D1f1gtQrlw5nJ2dH3FElvLziJWIiIiIiIiIiDy+8pMnUmJfRKQQKbEvIiIiIiIiIiKQvzyRSvGIiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhSuyLiIiIiIiIiIiIiBQhtoUdgIiIwFMjN1CshENhhyEi8thKiWpV2CGIiIiIiIgUGN2xLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixX8iCgoIIDw8v7DAA6Nq1K61btza+/5lik3szmUysXLmysMN4IGazmenTpxd2GPcVGRlJnTp1CjsMERERERERERERg16eK7lasWIFxYsXL+wwpIiLjY0lPDycCxcuWPx97969ODo6FuhYQUFB1KlTp0hcMBAREREREREREXlQSuw/hrKysjCZTBQr9nAPZLi5uRVQRCI5ubu7F3YIf5jr169jZ2dX2GGIiIiIiIiIiMhjSqV4/r+goCD69evHoEGDcHNzw8PDg8jISABSUlIwmUwcPHjQaH/hwgVMJhNbtmwBYMuWLZhMJjZs2EBAQAD29vY0a9aM9PR01q1bh7+/Py4uLnTq1IkrV65YjH3jxg3CwsJwdXWlTJkyjBgxglu3bhnbr127RkREBF5eXjg6OtKoUSNjXLh9R3SpUqVYtWoV1atXp0SJEqSmpuZ5vFlZWQwYMIBSpUpRunRpBg0aZDFm9pzcWYpn4cKF1K9fH2dnZzw8POjUqRPp6ekW+6xatQofHx9KlizJc889R1xcHCaTybhbOzvWDRs24O/vj5OTEy1atCAtLc3o4+bNm4wePZoKFSpQokQJ6tSpw/r1643t169fJywsDE9PT0qWLEmlSpWYMGGCxdr06NEDd3d3XFxcaNasGYmJicb2xMREnnvuOZydnXFxcaFevXrs27cvz/kCOH36NK+88gpPPPEEjo6O1KhRg7Vr11oc151WrlyJyWQyvmeXdJk/fz4VK1bEycmJPn36kJWVxaRJk/Dw8KBs2bKMGzfuvrHcKS0tjZYtW2Jvb0+VKlX44osvjG3NmjUjLCzMov3//vc/7OzsiI+Pv2/fZrOZMWPG0LFjRxwdHfHy8mLOnDkWbaZOnUrNmjVxdHTE29ubPn36kJGRAdz+XXTr1o2LFy9iMpkwmUzG7+ruUjz3W7fs+Vu4cCFmsxlXV1c6dOjA5cuXgdulpLZu3cqMGTOMsVJSUvI8vuzfbXx8PPXr18fBwYEmTZqQlJSUo+3HH3+Mt7c3Dg4OhISEcPHiRWNbdhmrcePGUb58efz8/O47tyIiIiIiIiIiIg9Kif07xMXF4ejoyO7du5k0aRKjR49m06ZN+eojMjKS2bNns2PHDs6cOUNISAjTp09n8eLFrFmzho0bNzJr1qwc49ra2rJnzx5mzJjB1KlTmTdvnrE9LCyMnTt3snTpUg4dOkS7du1o0aIFJ06cMNpcuXKFiRMnMm/ePI4cOULZsmXzjDM6OprY2Fjmz5/P9u3bOX/+PF999VWe+2RmZjJmzBgSExNZuXIlKSkpdO3a1dh+6tQp2rZtS+vWrUlMTKRXr14MGzYsRz9XrlxhypQpLFy4kG+//ZbU1FQiIiKM7TNmzCA6OpopU6Zw6NAhgoODefXVV43jnTlzJqtWrWLZsmUkJSWxaNEizGazsX+7du2MCyr79++nbt26PP/885w/fx6Azp07U6FCBfbu3cv+/fsZMmSIVSWH+vbty7Vr1/j22285fPgwEydOxMnJ6b773Sk5OZl169axfv16lixZwqeffkqrVq3473//y9atW5k4cSLDhw9n9+7dVvc5YsQI3njjDRITE+ncuTMdOnTg6NGjAPTo0YPFixdz7do1o/1nn32Gl5cXzZo1s6r/yZMnU7t2bQ4cOMCQIUPo37+/xe+iWLFizJw5kyNHjhAXF8e///1vBg0aBECTJk2YPn06Li4upKWlkZaWZrHWd7rfumXP38qVK1m9ejWrV69m69atREVFAbfPm8DAQHr27GmM5e3tbdUxDhs2jOjoaPbt24etrS1vvfWWxfaTJ0+ybNky/vWvf7F+/XoOHDhAnz59LNrEx8eTlJTEpk2bWL16da5jXbt2jUuXLll8RERERERERERE8kOleO5Qq1YtRo4cCYCPjw+zZ88mPj4eHx8fq/sYO3YsTZs2BaB79+4MHTqU5ORkqlSpAkDbtm3ZvHkzgwcPNvbx9vZm2rRpmEwm/Pz8OHz4MNOmTaNnz56kpqYSExNDamoq5cuXByAiIoL169cTExPD+PHjgdtJ97lz51K7dm2r4pw+fTpDhw6lTZs2AHz00Uds2LAhz33uTHZWqVKFmTNn0qBBAzIyMnBycuLjjz/Gz8+PyZMnA+Dn58f333+f4w70zMxMPvroI5588kng9oWL0aNHG9unTJnC4MGD6dChAwATJ05k8+bNTJ8+nTlz5pCamoqPjw9/+9vfMJlMVKpUydh3+/bt7Nmzh/T0dEqUKGH0t3LlSr744gvefvttUlNTef/996lWrRqA1eubmprKG2+8Qc2aNY05yK+bN28yf/58nJ2dqV69Os899xxJSUmsXbuWYsWK4efnZxxvo0aNrOqzXbt29OjRA4AxY8awadMmZs2axdy5c2nTpg1hYWF8/fXXhISEALefLujatavF0wR5adq0KUOGDAHA19eXhIQEpk2bxgsvvABg8VSH2Wxm7Nix9O7dm7lz52JnZ4erqysmkwkPD49cx7Bm3bLnLzY2FmdnZwC6dOlCfHw848aNw9XVFTs7OxwcHPIc617GjRvHs88+C8CQIUNo1aoVv//+OyVLlgTg999/Z8GCBXh5eQEwa9YsWrVqRXR0tDGWo6Mj8+bNu28JngkTJjBq1Kh8xSciIiIiIiIiInIn3bF/h1q1all89/T0zFFqJj99lCtXDgcHB4sEcLly5XL02bhxY4ska2BgICdOnCArK4vDhw+TlZWFr68vTk5Oxmfr1q0kJycb+9jZ2eWIPzcXL14kLS3NInFsa2tL/fr189xv//79vPLKK1SsWBFnZ2cjEZpd9icpKYkGDRpY7NOwYcMc/Tg4OBhJfbCc50uXLvHTTz8ZF0eyNW3a1LgLvWvXrhw8eBA/Pz/69evHxo0bjXaJiYlkZGRQunRpi/k6deqUMV8DBgygR48eNG/enKioKIt5zEu/fv2MCzcjR47k0KFDVu13J7PZbCSl4fb5UL16dYv3IdzrHMlLYGBgju/Zc1WyZEm6dOnC/PnzAfjuu+/4/vvvLZ60eJj+Ab755huef/55vLy8cHZ2pkuXLpw7dy5Hyam8WLNukHP+HuQ3ei93/nY8PT0BLPqtWLGikdSH23Nw8+ZNi5I9NWvWtKqu/tChQ7l48aLxOXPmzEPHLyIiIiIiIiIify26Y/8Od5djMZlM3Lx500i63lmDPjMz8759mEymXPu0VkZGBjY2Nuzfvx8bGxuLbXeWgbG3t7f6DuwH8dtvvxEcHExwcDCLFi3C3d2d1NRUgoODuX79er76utec3F3fPy9169bl1KlTrFu3jm+++YaQkBCaN2/OF198QUZGBp6enhbvIMiWXQM/MjKSTp06sWbNGtatW8fIkSNZunQpr7/+ep7j9ujRg+DgYKOk0oQJE4iOjubdd9+lWLFiOY7hXufIvY79Yc+R++nRowd16tThv//9LzExMTRr1sziKYeHkZKSwssvv8w777zDuHHjcHNzY/v27XTv3p3r16/j4OBgVT/WrBvk/ht9WHf/boF89+vo6GhVuxIlShhPJYiIiIiIiIiIiDwI3bFvBXd3dwCLF7ze+SLdh3V3PfVdu3bh4+ODjY0NAQEBZGVlkZ6eTtWqVS0++S03ks3V1RVPT0+LcW/cuMH+/ftz3efYsWOcO3eOqKgonn76aapVq5bjTmk/P78cL6Hdu3dvvmJzcXGhfPnyJCQkWPw9ISGB6tWrW7Rr3749n3zyCZ9//jlffvkl58+fp27duvz888/Y2trmmK8yZcoY+/v6+vLee++xceNG2rRpQ0xMjFXxeXt707t3b1asWMHAgQP55JNPgNvnyOXLl/ntt9+MtgV5juRl165dOb77+/sb32vWrEn9+vX55JNPWLx4cY768Q/T//79+7l58ybR0dE0btwYX19ffvrpJ4v2dnZ2ZGVl5TmGtet2P9aM9SBSU1MtjmvXrl1G6SQREREREREREZFHTYl9K9jb29O4cWOioqI4evQoW7duZfjw4QXWf2pqKgMGDCApKYklS5Ywa9Ys+vfvD9xOQHfu3JnQ0FBWrFjBqVOn2LNnDxMmTGDNmjUPPGb//v2Jiopi5cqVHDt2jD59+nDhwoVc21esWBE7OztmzZrFf/7zH1atWsWYMWMs2vTq1Ytjx44xePBgjh8/zrJly4iNjQXI19ME77//PhMnTuTzzz8nKSmJIUOGcPDgQWNOpk6dypIlSzh27BjHjx9n+fLleHh4UKpUKZo3b05gYCCtW7dm48aNpKSksGPHDoYNG8a+ffu4evUqYWFhbNmyhdOnT5OQkMDevXstEuG5CQ8PZ8OGDZw6dYrvvvuOzZs3G/s1atQIBwcH/vGPf5CcnMzixYuNY/+jLV++nPnz53P8+HFGjhzJnj17CAsLs2jTo0cPoqKiuHXr1n2fTLhbQkICkyZN4vjx48yZM4fly5cba1G1alUyMzON82LhwoV89NFHFvubzWYyMjKIj4/n7Nmz9yzRc791s5bZbGb37t2kpKRw9uzZAnvyoWTJkrz55pskJiaybds2+vXrR0hIyANfXBMREREREREREXkYSuxbaf78+dy4cYN69eoRHh7O2LFjC6zv0NBQrl69SsOGDenbty/9+/c3XhYKEBMTQ2hoKAMHDsTPz4/WrVuzd+9eKlas+MBjDhw4kC5duvDmm28SGBiIs7Nznglfd3d3YmNjWb58OdWrVycqKoopU6ZYtKlcuTJffPEFK1asoFatWnz44YcMGzYMIF+lR/r168eAAQMYOHAgNWvWZP369axatcp4ya2zszOTJk2ifv36NGjQgJSUFOPlsyaTibVr1/LMM8/QrVs3fH196dChA6dPn6ZcuXLY2Nhw7tw5QkND8fX1JSQkhJYtW1r1MtOsrCz69u2Lv78/LVq0wNfXl7lz5wLg5ubGZ599xtq1a6lZsyZLliwhMjLS6mN+GKNGjWLp0qXUqlWLBQsWsGTJEounGwA6duyIra0tHTt2NF4Ia62BAweyb98+AgICGDt2LFOnTiU4OBiA2rVrM3XqVCZOnMhTTz3FokWLmDBhgsX+TZo0oXfv3rRv3x53d3cmTZqUY4z7rZu1IiIisLGxoXr16ka5qIJQtWpV2rRpw0svvcSLL75IrVq1jLUXERERERERERF51Ey38lPcXCSfxo0bx0cffaQXhBaylJQUnnzySfbu3UvdunWt3s9sNhMeHk54ePgfF9xf3KVLl3B1dcU7fBnFSlj3TgIREcm/lKhWhR2CiIiIiIhInrLzRBcvXsTFxSXPtnp5rhSouXPn0qBBA0qXLk1CQgKTJ0/OURZGHp3MzEzOnTvH8OHDady4cb6S+iIiIiIiIiIiIvLnpFI8jyknJ6dcP9u2bfvDxj1x4gSvvfYa1atXZ8yYMQwcOPCRlaR5WC1btsx1zsaPH//I41m0aFGu8dSoUcOqPhISEvD09GTv3r05at9v27Ytz/PkcdC7d+9cj693796FHZ6IiIiIiIiIiMgDUSmex9TJkydz3ebl5YW9vf0jjKZo+PHHH7l69eo9t7m5ueHm5vZI47l8+TK//PLLPbcVL16cSpUqPVT/V69e5ccff8x1e9WqVR+q/z+D9PR0Ll26dM9tLi4ulC1b9hFHlFN+HrESEREREREREZHHV37yRErsi4gUIiX2RUREREREREQE8pcnUikeEREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEiRIl9EREREREREREREZEixLawAxAREXhq5AaKlXAo7DBERIqUlKhWhR2CiIiIiIhIodAd+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+3+QoKAgwsPDCzsMALp27Urr1q2N73+m2OThmEwmVq5cWdhhPBCz2cz06dMLO4z7ioyMpE6dOoUdhoiIiIiIiIiIiEEvz/0LWrFiBcWLFy/sMOQvIjY2lvDwcC5cuGDx97179+Lo6FigYwUFBVGnTp0iccFARERERERERETkQSmxX4RkZWVhMpkoVuzhHrRwc3MroIhEHpy7u3thh/CHuX79OnZ2doUdhoiIiIiIiIiIPKYe+1I8QUFB9OvXj0GDBuHm5oaHhweRkZEApKSkYDKZOHjwoNH+woULmEwmtmzZAsCWLVswmUxs2LCBgIAA7O3tadasGenp6axbtw5/f39cXFzo1KkTV65csRj7xo0bhIWF4erqSpkyZRgxYgS3bt0ytl+7do2IiAi8vLxwdHSkUaNGxrhw+07nUqVKsWrVKqpXr06JEiVITU3N83izsrIYMGAApUqVonTp0gwaNMhizOw5ubMUz8KFC6lfvz7Ozs54eHjQqVMn0tPTLfZZtWoVPj4+lCxZkueee464uDhMJpNxF3Z2rBs2bMDf3x8nJydatGhBWlqa0cfNmzcZPXo0FSpUoESJEtSpU4f169cb269fv05YWBienp6ULFmSSpUqMWHCBIu16dGjB+7u7ri4uNCsWTMSExON7YmJiTz33HM4Ozvj4uJCvXr12LdvX57zdWfsq1evxs/PDwcHB9q2bcuVK1eIi4vDbDbzxBNP0K9fP7Kysoz97rd+586do2PHjnh5eeHg4EDNmjVZsmRJjrXI7fy0VlpaGi1btsTe3p4qVarwxRdfGNuaNWtGWFiYRfv//e9/2NnZER8ff9++zWYzY8aMoWPHjjg6OuLl5cWcOXMs2kydOpWaNWvi6OiIt7c3ffr0ISMjA7j9++nWrRsXL17EZDJhMpmM47u7FM/91je7JM7ChQsxm824urrSoUMHLl++DNwuObV161ZmzJhhjJWSkpLn8WX/vuPj46lfvz4ODg40adKEpKSkHG0//vhjvL29cXBwICQkhIsXLxrbsstdjRs3jvLly+Pn53ffuRUREREREREREXlQj31iHyAuLg5HR0d2797NpEmTGD16NJs2bcpXH5GRkcyePZsdO3Zw5swZQkJCmD59OosXL2bNmjVs3LiRWbNm5RjX1taWPXv2MGPGDKZOncq8efOM7WFhYezcuZOlS5dy6NAh2rVrR4sWLThx4oTR5sqVK0ycOJF58+Zx5MgRypYtm2ec0dHRxMbGMn/+fLZv38758+f56quv8twnMzOTMWPGkJiYyMqVK0lJSaFr167G9lOnTtG2bVtat25NYmIivXr1YtiwYTn6uXLlClOmTGHhwoV8++23pKamEhERYWyfMWMG0dHRTJkyhUOHDhEcHMyrr75qHO/MmTNZtWoVy5YtIykpiUWLFmE2m43927VrZ1xQ2b9/P3Xr1uX555/n/PnzAHTu3JkKFSqwd+9e9u/fz5AhQ6wuOXTlyhVmzpzJ0qVLWb9+PVu2bOH1119n7dq1rF27loULF/Lxxx9bJM3vt36///479erVY82aNXz//fe8/fbbdOnShT179liM/bDn54gRI3jjjTdITEykc+fOdOjQgaNHjwLQo0cPFi9ezLVr14z2n332GV5eXjRr1syq/idPnkzt2rU5cOAAQ4YMoX///hbxFStWjJkzZ3LkyBHi4uL497//zaBBgwBo0qQJ06dPx8XFhbS0NNLS0izOiTvdb30BkpOTWblyJatXr2b16tVs3bqVqKgo4Pb5FRgYSM+ePY2xvL29rTrGYcOGER0dzb59+7C1teWtt96y2H7y5EmWLVvGv/71L9avX8+BAwfo06ePRZv4+HiSkpLYtGkTq1evznWsa9eucenSJYuPiIiIiIiIiIhIfphu3X0792MmKCiIrKwstm3bZvytYcOGNGvWjN69e1O5cmUOHDhgvBzzwoULPPHEE2zevJmgoCC2bNnCc889xzfffMPzzz8PQFRUFEOHDiU5OZkqVaoA0Lt3b1JSUow70IOCgkhPT+fIkSOYTCYAhgwZwqpVq/jhhx9ITU2lSpUqpKamUr58eSO25s2b07BhQ8aPH09sbCzdunXj4MGD1K5d26rjLV++PO+99x7vv/8+cPupgcqVK1OvXj3jJav3q0O+b98+GjRowOXLl3FycmLIkCGsWbOGw4cPG22GDx/OuHHj+PXXXylVqpQR68mTJ3nyyScBmDt3LqNHj+bnn38GwMvLi759+/KPf/zDYi0aNGjAnDlz6NevH0eOHOGbb74x5izb9u3badWqFenp6ZQoUcL4e9WqVRk0aBBvv/02Li4uzJo1izfffNOqucp2r9h79+7NwoUL+eWXX3BycgKgRYsWmM1mPvroI6vW715efvllqlWrxpQpU4C8z8/shHVeTCYTvXv35sMPPzT+1rhxY+rWrcvcuXP5/fffKV++PB999BEhISEA1K5dmzZt2jBy5Mj79m82m/H392fdunXG3zp06MClS5dYu3btPff54osv6N27N2fPngVyr7FvNpsJDw8nPDzcqvWNjIxk8uTJ/Pzzzzg7OwMwaNAgvv32W3bt2gXkv8b+vX7fa9eupVWrVly9epWSJUsSGRnJ2LFjOX36NF5eXgCsX7+eVq1a8eOPP+Lh4UHXrl1Zv349qamp9y3BExkZyahRo3L83Tt8GcVKOFgVt4iI3JYS1aqwQxARERERESkwly5dwtXVlYsXL+Li4pJn27/EHfu1atWy+O7p6Zmj1Ex++ihXrhwODg5GUj/7b3f32bhxY4sEdWBgICdOnCArK4vDhw+TlZWFr68vTk5Oxmfr1q0kJycb+9jZ2eWIPzcXL14kLS2NRo0aGX+ztbWlfv36ee63f/9+XnnlFSpWrIizszPPPvssgFH2JykpiQYNGljs07Bhwxz9ODg4GIlxsJznS5cu8dNPP9G0aVOLfZo2bWrcXd61a1cOHjyIn58f/fr1Y+PGjUa7xMREMjIyKF26tMV8nTp1ypivAQMG0KNHD5o3b05UVJTFPN7P3bGXK1cOs9lsJPWz/5Z9PNasX1ZWFmPGjKFmzZq4ubnh5OTEhg0bcpRTetjzMzAwMMf37DktWbIkXbp0Yf78+QB89913fP/99xZPZDxM/4CRFPfy8sLZ2ZkuXbpw7ty5HKWp8mLN+sLtiwHZSX14sN/yvdy5Bp6engAW/VasWNFI6sPtObh586ZFyZ6aNWtaVVd/6NChXLx40ficOXPmoeMXEREREREREZG/lr/Ey3PvLsdiMpm4efOm8RLaOx9ayMzMvG8fJpMp1z6tlZGRgY2NDfv378fGxsZi253JZHt7+xx3rxek3377jeDgYIKDg1m0aBHu7u6kpqYSHBzM9evX89XXveYkPw+E1K1bl1OnTrFu3Tq++eYbQkJCaN68OV988QUZGRl4enpa1LDPVqpUKeD2ndCdOnVizZo1rFu3jpEjR7J06VJef/31B4o9rzW2Zv0mT57MjBkzmD59ulGDPjw8PMe8Puy5dD89evSgTp06/Pe//yUmJoZmzZpRqVKlAuk7JSWFl19+mXfeeYdx48bh5ubG9u3b6d69O9evX8fBwbo70K1ZX/jj5uru3zeQ734dHR2taleiRAmLpxJERERERERERETy6y+R2M+Nu7s7cPvlowEBAQAWL9J9WLt377b4vmvXLnx8fLCxsSEgIICsrCzS09N5+umnC2Q8V1dXPD092b17N8888wxwuxRPdr3yezl27Bjnzp0jKirKqEd+9wtn/fz8cpRd2bt3b75ic3FxoXz58iQkJBhPBAAkJCRY3P3v4uJC+/btad++PW3btqVFixacP3+eunXr8vPPP2Nra2tRd/9uvr6++Pr68t5779GxY0diYmKsSuznlzXrl5CQwGuvvcbf//534Hai+Pjx41SvXr1AY9m1axehoaEW37PPZ7h9J3n9+vX55JNPWLx4MbNnz853/3d/9/f3B24/7XHz5k2io6ONC2XLli2zaG9nZ2fx0uF7sXZ978easR5EamoqP/30k1F2adeuXRQrVkwvyRURERERERERkULxlyjFkxt7e3saN25MVFQUR48eZevWrQwfPrzA+k9NTWXAgAEkJSWxZMkSZs2aRf/+/YHbCejOnTsTGhrKihUrOHXqFHv27GHChAmsWbPmgcfs378/UVFRrFy5kmPHjtGnT58ctc3vVLFiRezs7Jg1axb/+c9/WLVqFWPGjLFo06tXL44dO8bgwYM5fvw4y5YtIzY2FiBfTxO8//77TJw4kc8//5ykpCSGDBnCwYMHjTmZOnUqS5Ys4dixYxw/fpzly5fj4eFBqVKlaN68OYGBgbRu3ZqNGzeSkpLCjh07GDZsGPv27ePq1auEhYWxZcsWTp8+TUJCAnv37jUS0AXNmvXz8fFh06ZN7Nixg6NHj9KrVy9++eWXAo9l+fLlzJ8/n+PHjzNy5Ej27NlDWFiYRZsePXoQFRXFrVu38n2hIyEhgUmTJnH8+HHmzJnD8uXLjTWrWrUqmZmZxvmzcOFCPvroI4v9zWYzGRkZxMfHc/bs2XuW6Lnf+lrLbDaze/duUlJSOHv2bIE9+VCyZEnefPNNEhMT2bZtG/369SMkJAQPD48C6V9ERERERERERCQ//tKJfYD58+dz48YN6tWrR3h4OGPHji2wvkNDQ7l69SoNGzakb9++9O/fn7ffftvYHhMTQ2hoKAMHDsTPz4/WrVuzd+9eKlas+MBjDhw4kC5duvDmm28SGBiIs7Nznolcd3d3YmNjWb58OdWrVycqKsp4sWu2ypUr88UXX7BixQpq1arFhx9+yLBhwwDyVVKkX79+DBgwgIEDB1KzZk3Wr1/PqlWr8PHxAcDZ2ZlJkyZRv359GjRoQEpKCmvXrqVYsWKYTCbWrl3LM888Q7du3fD19aVDhw6cPn2acuXKYWNjw7lz5wgNDcXX15eQkBBatmx5z5eUFpT7rd/w4cOpW7cuwcHBBAUF4eHhQevWrQs8jlGjRrF06VJq1arFggULWLJkSY6nAjp27IitrS0dO3akZMmS+ep/4MCB7Nu3j4CAAMaOHcvUqVMJDg4Gbr+Id+rUqUycOJGnnnqKRYsWMWHCBIv9mzRpQu/evWnfvj3u7u5MmjQpxxj3W19rRUREYGNjQ/Xq1Y2yUgWhatWqtGnThpdeeokXX3yRWrVqMXfu3ALpW0REREREREREJL9Mt/JTBF3k/xs3bhwfffSRXvxZRKSkpPDkk0+yd+/eXMsy3YvZbCY8PJzw8PA/Lri/uOy3nXuHL6NYCeveSSAiIrelRLUq7BBEREREREQKTHae6OLFi7i4uOTZ9i9dY1+sN3fuXBo0aEDp0qVJSEhg8uTJOcq9yJ9PZmYm586dY/jw4TRu3DhfSX0RERERERERERH5c/rLl+IpapycnHL9bNu27Q8b98SJE7z22mtUr16dMWPGMHDgQCIjI/+w8QpSy5Ytc52z8ePHF3Z4uVq0aFGucdeoUcOqPhISEvD09GTv3r05at9v27Ytz/PpcdC7d+9cj693796FHZ6IiIiIiIiIiMgDUSmeIubkyZO5bvPy8sLe3v4RRlM0/Pjjj1y9evWe29zc3HBzc3vEEVnn8uXLub5st3jx4lSqVOmh+r969So//vhjrturVq36UP3/GaSnp3Pp0qV7bnNxcaFs2bKPOKKc8vOIlYiIiIiIiIiIPL7ykydSYl9EpBApsS8iIiIiIiIiIpC/PJFK8YiIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCFK7IuIiIiIiIiIiIiIFCG2hR2AiIjAUyM3UKyEQ2GHISLyp5US1aqwQxAREREREfnT0B37IiIiIiIiIiIiIiJFiBL7IiIiIiIiIiIiIiJFiBL7IiIiIiIiIiIiIiJFiBL7hSQoKIjw8PBHPm7Xrl1p3br1Ix83NyaTiZUrVxZ2GEVWUZ4/s9nM9OnTCzuM+4qMjKROnTqFHYaIiIiIiIiIiIhBif2/mBkzZhAbG/vIx80tOZqWlkbLli0LdKyikjD+q4iNjaVUqVI5/r53717efvvtAh2rsC6YiYiIiIiIiIiIPEq2hR2AFJysrCxMJhPFiuV+vcbV1fURRnR/Hh4ehR2CFBJ3d/fCDuEPc/36dezs7Ao7DBEREREREREReUz95e/YDwoKol+/fgwaNAg3Nzc8PDyIjIwEICUlBZPJxMGDB432Fy5cwGQysWXLFgC2bNmCyWRiw4YNBAQEYG9vT7NmzUhPT2fdunX4+/vj4uJCp06duHLlisXYN27cICwsDFdXV8qUKcOIESO4deuWsf3atWtERETg5eWFo6MjjRo1MsaF/7sTetWqVVSvXp0SJUqQmpqa5/HeXYonr+PPZjKZ+PDDD2nZsiX29vZUqVKFL774wqLN4MGD8fX1xcHBgSpVqjBixAgyMzONOEeNGkViYiImkwmTyWQ8NXB3KZkzZ84QEhJCqVKlcHNz47XXXiMlJSVH/FOmTMHT05PSpUvTt29fY6ygoCBOnz7Ne++9Z4x1P9nzuHr1avz8/HBwcKBt27ZcuXKFuLg4zGYzTzzxBP369SMrK8vY737rc+7cOTp27IiXlxcODg7UrFmTJUuWWIxtzfzfT/ZTD/dam2bNmhEWFmbR/n//+x92dnbEx8fft2+z2cyYMWPo2LEjjo6OeHl5MWfOHIs2U6dOpWbNmjg6OuLt7U2fPn3IyMgAbv8+unXrxsWLF431yD6+u5+suHDhAj169MDd3R0XFxeaNWtGYmKisT37qY+FCxdiNptxdXWlQ4cOXL58Gbh9bmzdupUZM2YYY9157txL9u83Pj6e+vXr4+DgQJMmTUhKSsrR9uOPP8bb2xsHBwdCQkK4ePGisS37vBw3bhzly5fHz8/vvnMrIiIiIiIiIiLyoP7yiX2AuLg4HB0d2b17N5MmTWL06NFs2rQpX31ERkYye/ZsduzYYSSnp0+fzuLFi1mzZg0bN25k1qxZOca1tbVlz549zJgxg6lTpzJv3jxje1hYGDt37mTp0qUcOnSIdu3a0aJFC06cOGG0uXLlChMnTmTevHkcOXKEsmXL/iHHP2LECN544w0SExPp3LkzHTp04OjRo8Z2Z2dnYmNj+eGHH5gxYwaffPIJ06ZNA6B9+/YMHDiQGjVqkJaWRlpaGu3bt88RR2ZmJsHBwTg7O7Nt2zYSEhJwcnKiRYsWXL9+3Wi3efNmkpOT2bx5M3FxccTGxhoXClasWEGFChUYPXq0MZY1rly5wsyZM1m6dCnr169ny5YtvP7666xdu5a1a9eycOFCPv74Y4uk+f3W5/fff6devXqsWbOG77//nrfffpsuXbqwZ8+efM9/XvJamx49erB48WKuXbtmtP/ss8/w8vKiWbNmVvU/efJkateuzYEDBxgyZAj9+/e3iK9YsWLMnDmTI0eOEBcXx7///W8GDRoEQJMmTZg+fTouLi7GekRERNxznHbt2hkXxPbv30/dunV5/vnnOX/+vNEmOTmZlStXsnr1alavXs3WrVuJiooCbpeZCgwMpGfPnsZY3t7eVh3jsGHDiI6OZt++fdja2vLWW29ZbD958iTLli3jX//6F+vXr+fAgQP06dPHok18fDxJSUls2rSJ1atX5zrWtWvXuHTpksVHREREREREREQkP5TYB2rVqsXIkSPx8fEhNDSU+vXrW3U3853Gjh1L06ZNCQgIoHv37mzdupUPP/yQgIAAnn76adq2bcvmzZst9vH29mbatGn4+fnRuXNn3n33XSMZnpqaSkxMDMuXL+fpp5/mySefJCIigr/97W/ExMQYfWRmZjJ37lyaNGli3G3+Rxx/u3bt6NGjB76+vowZM4b69etbXKgYPnw4TZo0wWw288orrxAREcGyZcsAsLe3x8nJCVtbWzw8PPDw8MDe3j5HHJ9//jk3b95k3rx51KxZE39/f2JiYkhNTbW4E/6JJ55g9uzZVKtWjZdffplWrVoZ8bq5uWFjY4Ozs7MxljUyMzON9XrmmWdo27Yt27dv59NPP6V69eq8/PLLPPfcc8YaWrM+Xl5eREREUKdOHapUqcK7775LixYtjHnJz/znJa+1adOmDQBff/210T42NpauXbta9TQDQNOmTRkyZAi+vr68++67tG3b1jhPAcLDw3nuuecwm800a9aMsWPHGsdoZ2eHq6srJpPJWA8nJ6ccY2zfvp09e/awfPly6tevj4+PD1OmTKFUqVIWF1Nu3rxJbGwsTz31FE8//TRdunQx5srV1RU7OzscHByMsWxsbKw6xnHjxvHss89SvXp1hgwZwo4dO/j999+N7b///jsLFiygTp06PPPMM8yaNYulS5fy888/G20cHR2ZN28eNWrUoEaNGrmONWHCBFxdXY2PtRcfREREREREREREsqnGPrcTq3fy9PQkPT39gfsoV66cUZLmzr/dfad248aNLZKrgYGBREdHk5WVxeHDh8nKysLX19din2vXrlG6dGnju52dXY7488ua4w8MDMzx/c4SRZ9//jkzZ84kOTmZjIwMbty4gYuLS77iSExM5OTJkzg7O1v8/ffffyc5Odn4XqNGDYuEraenJ4cPH87XWHdzcHDgySefNL6XK1cOs9lskYQuV66cMS/WrE9WVhbjx49n2bJl/Pjjj1y/fp1r167luPjysOdfXmtTsmRJunTpwvz58wkJCeG7777j+++/Z9WqVQ/V/50ldL755hsmTJjAsWPHuHTpEjdu3OD333/nypUrVl9oSkxMJCMjw+LcBrh69arF2pvNZovz40F+q/dy5xp4enoCkJ6eTsWKFQGoWLEiXl5eRpvAwEBu3rxJUlKScfGoZs2aVtXVHzp0KAMGDDC+X7p0Scl9ERERERERERHJFyX2geLFi1t8N5lM3Lx503gJ7Z1177NruefVh8lkyrVPa2VkZGBjY8P+/ftz3HV8Z7LZ3t7e6juvc/Owse7cuZPOnTszatQogoODcXV1ZenSpURHR+crjoyMDOrVq8eiRYtybLvzRasPG++93KvPvMaxZn0mT57MjBkzmD59ulGDPjw83KKs0B91PHfq0aMHderU4b///S8xMTE0a9aMSpUqFUjfKSkpvPzyy7zzzjuMGzcONzc3tm/fTvfu3bl+/brVif2MjAw8PT0tnszIVqpUKePff9Rc3f37BfLdr6Ojo1XtSpQoQYkSJfLVt4iIiIiIiIiIyJ2U2M9DdjI5LS2NgIAAAIu71B/W7t27Lb7v2rULHx8fbGxsCAgIICsri/T0dJ5++ukCG/NB7dq1i9DQUIvv2XOyY8cOKlWqxLBhw4ztp0+fttjfzs7O4sWz91K3bl0+//xzypYtm++7/fM71sOyZn0SEhJ47bXX+Pvf/w7cThQfP36c6tWrF2gsea0N3L6TvH79+nzyyScsXryY2bNn57v/u7/7+/sDsH//fm7evEl0dLRxIezuUkPWrv3PP/+Mra0tZrM5X/Hld6wHkZqayk8//UT58uWB23NQrFgxvSRXREREREREREQKhWrs58He3p7GjRsTFRXF0aNH2bp1K8OHDy+w/lNTUxkwYABJSUksWbKEWbNm0b9/fwB8fX3p3LkzoaGhrFixglOnTrFnzx4mTJjAmjVrCiwGay1fvpz58+dz/PhxRo4cyZ49ewgLCwPAx8eH1NRUli5dSnJyMjNnzuSrr76y2N9sNnPq1CkOHjzI2bNnLV7mmq1z586UKVOG1157jW3btnHq1Cm2bNlCv379+O9//2t1rGazmW+//ZYff/yRs2fPPtyB58Ka9fHx8WHTpk3s2LGDo0eP0qtXL3755ZcCjyWvtcnWo0cPoqKiuHXrFq+//nq++k9ISGDSpEkcP36cOXPmsHz5cuM8rVq1KpmZmcyaNYv//Oc/LFy4kI8++shif7PZTEZGBvHx8Zw9e5YrV67kGKN58+YEBgbSunVrNm7cSEpKCjt27GDYsGHs27fP6ljNZjO7d+8mJSWFs2fPFtiTDyVLluTNN98kMTGRbdu20a9fP0JCQqx+h4OIiIiIiIiIiEhBUmL/PubPn8+NGzeoV68e4eHhjB07tsD6Dg0N5erVqzRs2JC+ffvSv39/3n77bWN7TEwMoaGhDBw4ED8/P1q3bs3evXuNut+P0qhRo1i6dCm1atViwYIFLFmyxLjz/NVXX+W9994jLCyMOnXqsGPHDkaMGGGx/xtvvEGLFi147rnncHd3Z8mSJTnGcHBw4Ntvv6VixYq0adMGf39/unfvzu+//56vO/hHjx5NSkoKTz75pEUJn4J2v/UZPnw4devWJTg4mKCgIDw8PGjdunWBx5HX2mTr2LEjtra2dOzYkZIlS+ar/4EDB7Jv3z4CAgIYO3YsU6dOJTg4GIDatWszdepUJk6cyFNPPcWiRYuYMGGCxf5NmjShd+/etG/fHnd3dyZNmpRjDJPJxNq1a3nmmWfo1q0bvr6+dOjQgdOnT1OuXDmrY42IiMDGxobq1avj7u5Oampqvo41N1WrVqVNmza89NJLvPjii9SqVYu5c+cWSN8iIiIiIiIiIiL5Zbp1ZwF5kXswmUx89dVXf0hSWh6N7Asde/fupW7dulbvZzabCQ8PJzw8/I8L7i/u0qVLuLq64h2+jGIlrHsngYjIX1FKVKvCDkFEREREROQPlZ0nunjx4n1vdFaNfZHHWGZmJufOnWP48OE0btw4X0l9ERERERERERER+XNSKZ7HjJOTU66fbdu2FXZ4haJly5a5zsn48eMLO7xcLVq0KNe4a9SoYVUfCQkJeHp6snfv3hy177dt25bn+fI46N27d67H17t378IOT0RERERERERE5IGoFM9j5uTJk7lu8/Lywt7e/hFG8+fw448/cvXq1Xtuc3Nzw83N7RFHZJ3Lly/n+rLd4sWLU6lSpYfq/+rVq/z444+5bq9atepD9f9nkJ6ezqVLl+65zcXFhbJlyz7iiHLKzyNWIiIiIiIiIiLy+MpPnkiJfRGRQqTEvoiIiIiIiIiIQP7yRCrFIyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShCixLyIiIiIiIiIiIiJShNgWdgAiIgJPjdxAsRIOhR2GiMgfLiWqVWGHICIiIiIiUuTpjn0RERERERERERERkSJEiX0RERERERERERERkSJEiX0RERERERERERERkSJEif0CFhQURHh4eGGHUWSYzWamT59e2GEUWUV5/orKbyU2NpZSpUoVdhgiIiIiIiIiIiIGJfbF8EcmMHPre+/evbz99tsFOlZRSRj/VWzZsgWTycSFCxcs/r5ixQrGjBlToGN17dqV1q1bF2ifIiIiIiIiIiIifza2hR2A3F9WVhYmk4lixR6/6zDu7u6FHYIUEjc3t8IO4Q9z/fp17OzsCjsMERERERERERF5TD1+meL/LygoiH79+jFo0CDc3Nzw8PAgMjISgJSUFEwmEwcPHjTaX7hwAZPJxJYtW4D/u8t4w4YNBAQEYG9vT7NmzUhPT2fdunX4+/vj4uJCp06duHLlisXYN27cICwsDFdXV8qUKcOIESO4deuWsf3atWtERETg5eWFo6MjjRo1MsaF/7u7fdWqVVSvXp0SJUqQmpqa5/HevHmT0aNHU6FCBUqUKEGdOnVYv369sf1ed00fPHgQk8lESkoKW7ZsoVu3bly8eBGTyYTJZDLmy2w2M2bMGDp27IijoyNeXl7MmTPHYvypU6dSs2ZNHB0d8fb2pk+fPmRkZBhj59X3naVkLly4QI8ePXB3d8fFxYVmzZqRmJhobI+MjKROnTosXLgQs9mMq6srHTp04PLly8DtO7a3bt3KjBkzjLFSUlLynLsHXeubN28yYcIEKleujL29PbVr1+aLL74wtmdlZdG9e3dju5+fHzNmzLAYO/sO8ylTpuDp6Unp0qXp27cvmZmZecZ8p8uXL+e6Nm+99RYvv/yyRfvMzEzKli3Lp59+et++g4KCCAsLy/N8XrhwIfXr18fZ2RkPDw86depEeno6cPu39txzzwHwxBNPYDKZ6Nq1q9H3nU9WWPu72LBhA/7+/jg5OdGiRQvS0tKA2+dGXFwcX3/9tbH2d+5/L9n/F6xYsYLnnnsOBwcHateuzc6dO3O0XblyJT4+PpQsWZLg4GDOnDljbMs+L+fNm0flypUpWbLkfedWRERERERERETkQT22iX2AuLg4HB0d2b17N5MmTWL06NFs2rQpX31ERkYye/ZsduzYwZkzZwgJCWH69OksXryYNWvWsHHjRmbNmpVjXFtbW/bs2cOMGTOYOnUq8+bNM7aHhYWxc+dOli5dyqFDh2jXrh0tWrTgxIkTRpsrV64wceJE5s2bx5EjRyhbtmyecc6YMYPo6GimTJnCoUOHCA4O5tVXX7XoMy9NmjRh+vTpuLi4kJaWRlpaGhEREcb2yZMnU7t2bQ4cOMCQIUPo37+/xVwWK1aMmTNncuTIEeLi4vj3v//NoEGDrOr7Tu3atTMS6vv376du3bo8//zznD9/3miTnJzMypUrWb16NatXr2br1q1ERUUZ8xAYGEjPnj2Nsby9va2ag/yu9YQJE1iwYAEfffQRR44c4b333uPvf/87W7duBW4n/itUqMDy5cv54Ycf+OCDD/jHP/7BsmXLLMbdvHkzycnJbN68mbi4OGJjY4mNjbUqZsh7bXr06MH69euN5DfA6tWruXLlCu3bt7eq//udz5mZmYwZM4bExERWrlxJSkqKkbz39vbmyy+/BCApKYm0tLQcFzeyWfu7mDJlCgsXLuTbb78lNTXVOJciIiIICQkxkv1paWk0adLEqmMcNmwYERERHDx4EF9fXzp27MiNGzcsxh03bhwLFiwgISGBCxcu0KFDB4s+Tp48yZdffsmKFSssLhre7dq1a1y6dMniIyIiIiIiIiIikh+PdSmeWrVqMXLkSAB8fHyYPXs28fHx+Pj4WN3H2LFjadq0KQDdu3dn6NChJCcnU6VKFQDatm3L5s2bGTx4sLGPt7c306ZNw2Qy4efnx+HDh5k2bRo9e/YkNTWVmJgYUlNTKV++PHA7Ibl+/XpiYmIYP348cDtZOnfuXGrXrm1VnFOmTGHw4MFGsnHixIls3ryZ6dOn57i7/l7s7OxwdXXFZDLh4eGRY3vTpk0ZMmQIAL6+viQkJDBt2jReeOEFAIs7r81mM2PHjqV3797MnTv3vn1n2759O3v27CE9PZ0SJUoYx7Vy5Uq++OILoxb/zZs3iY2NxdnZGYAuXboQHx/PuHHjcHV1xc7ODgcHhzzHupf8rPW1a9cYP34833zzDYGBgQBUqVKF7du38/HHH/Pss89SvHhxRo0aZfRfuXJldu7cybJlywgJCTH+/sQTTzB79mxsbGyoVq0arVq1Ij4+np49e1oVd15r06RJE/z8/Fi4cKFxoSUmJoZ27drh5ORkVf95nc9w+6mAbFWqVGHmzJk0aNCAjIwMnJycjJI7ZcuWzfUdDvn5XXz00Uc8+eSTwO2LAaNHjwbAyckJe3t7rl27lu+1j4iIoFWrVgCMGjWKGjVqcPLkSapVq2aMO3v2bBo1agTcvtjh7+/Pnj17aNiwIXC7/M6CBQvuW15qwoQJFueFiIiIiIiIiIhIfj3Wd+zXqlXL4runp6dRIuRB+ihXrhwODg5Gojf7b3f32bhxY0wmk/E9MDCQEydOkJWVxeHDh8nKysLX1xcnJyfjs3XrVpKTk4197OzscsSfm0uXLvHTTz8ZSelsTZs25ejRo/k63txkJ6/v/H5n39988w3PP/88Xl5eODs706VLF86dO5ejTFFeEhMTycjIoHTp0hZzc+rUKYu5MZvNRlIfHmxd7yU/a33y5EmuXLnCCy+8YBHrggULLGKdM2cO9erVw93dHScnJ/75z3/mKKtUo0YNbGxsHvh47rc2PXr0ICYmBoBffvmFdevWWSTj7yev8xlg//79vPLKK1SsWBFnZ2eeffZZgPuWj7qTtb8LBwcHI6kPf8zae3p6Alj0a2trS4MGDYzv1apVo1SpUhbzXKlSJaveGTF06FAuXrxofO4s6SMiIiIiIiIiImKNx/qO/eLFi1t8N5lM3Lx503gJ7Z11wnOraX5nHyaTKdc+rZWRkYGNjQ379++3SOYCFndQ29vbWyRTH1Z+jjm/UlJSePnll3nnnXcYN24cbm5ubN++ne7du3P9+nUcHBys6icjIwNPT8971kW/807vh12D3ORnrbPfH7BmzRq8vLws2mU/bbB06VIiIiKIjo4mMDAQZ2dnJk+ezO7du3MdtyCPJ1toaChDhgxh586d7Nixg8qVK/P0008XSN+//fYbwcHBBAcHs2jRItzd3UlNTSU4OJjr169b3Y+1v4t7zdWd5/SDunvtgXyvgaOjo1XtSpQoYZwjIiIiIiIiIiIiD+KxTuznJvuu2rS0NAICAgDyrImdX3cnbnft2oWPjw82NjYEBASQlZVFenp6gSVXXVxcKF++PAkJCcbd0gAJCQlGmZA7j/mJJ54Ach6znZ2dcRf23Xbt2pXju7+/P3D7ju2bN28SHR1tXEC4u458Xn1nq1u3Lj///DO2traYzeY82+bFmrEe1p0vNb5zzu+UkJBAkyZN6NOnj/G3O+8+Lyh5rQ1A6dKlad26NTExMezcuZNu3brlq/+8zudjx45x7tw5oqKijHcZ7Nu3z6K9nZ0dQJ5rUlC/iz9q7W/cuMG+ffuM31NSUhIXLlywmGcREREREREREZFH5bEuxZMbe3t7GjduTFRUFEePHmXr1q0MHz68wPpPTU1lwIABJCUlsWTJEmbNmkX//v2B2zXQO3fuTGhoKCtWrODUqVPs2bOHCRMmsGbNmgce8/3332fixIl8/vnnJCUlMWTIEA4ePGiMW7VqVby9vYmMjOTEiROsWbOG6Ohoiz7MZjMZGRnEx8dz9uxZizI6CQkJTJo0iePHjzNnzhyWL19u0XdmZiazZs3iP//5DwsXLuSjjz6yuu9szZs3JzAwkNatW7Nx40ZSUlLYsWMHw4YNy5EszovZbGb37t2kpKRw9uzZAr37PZuzszMRERG89957xMXFkZyczHfffcesWbOIi4sDbr/XYd++fWzYsIHjx48zYsQI9u7dW+Cx5LU22Xr06EFcXBxHjx7lzTffzFf/eZ3PFStWxM7Ozlj7VatWMWbMGIv9K1WqhMlkYvXq1fzvf/8znna4U0H9LsxmM4cOHSIpKYmzZ88W2FMpxYsX591332X37t3s37+frl270rhxYyPRLyIiIiIiIiIi8ij9JRP7APPnz+fGjRvUq1eP8PBwxo4dW2B9h4aGcvXqVRo2bEjfvn3p37+/8eJXuP3y0tDQUAYOHIifnx+tW7dm7969VKxY8YHH7NevHwMGDGDgwIHUrFmT9evXs2rVKuNFwcWLF2fJkiUcO3aMWrVqMXHixBzH3KRJE3r37k379u1xd3dn0qRJxraBAweyb98+AgICGDt2LFOnTiU4OBiA2rVrM3XqVCZOnMhTTz3FokWLmDBhgtV9ZzOZTKxdu5ZnnnmGbt264evrS4cOHTh9+jTlypWzei4iIiKwsbGhevXqRmmYP8KYMWMYMWIEEyZMwN/fnxYtWrBmzRoqV64MQK9evWjTpg3t27enUaNGnDt3zuLu/YKS19pka968OZ6engQHBxsvp7VWXuezu7s7sbGxLF++nOrVqxMVFcWUKVMs9vfy8mLUqFEMGTKEcuXKERYWds9xCuJ30bNnT/z8/Khfvz7u7u4kJCTk61hz4+DgwODBg+nUqRNNmzbFycmJzz//vED6FhERERERERERyS/TrYIoUC2PNbPZTHh4OOHh4YUdijygjIwMvLy8iImJoU2bNlbvFxQURJ06dZg+ffofF9xf3KVLl3B1dcU7fBnFSlj3PgoRkaIsJapVYYcgIiIiIiLyp5SdJ7p48SIuLi55tv1L1tgX+au4efMmZ8+eJTo6mlKlSvHqq68WdkgiIiIiIiIiIiLykP6ypXiKGicnp1w/27ZtK+zw/tR69+6d69z17t27sMPL1bZt2/Jcd2ukpqZSrlw5Fi9ezPz587G1tbXYllf/f1QJo0dp/PjxuR5fy5YtCzs8ERERERERERGRB6JSPEXEyZMnc93m5eWFvb39I4ymaElPT+fSpUv33Obi4kLZsmUfcUTWuXr1Kj/++GOu26tWrfpQ/d+4cYOUlJRct5vNZosLAUXR+fPnOX/+/D232dvb4+Xl9Ygjyik/j1iJiIiIiIiIiMjjKz95IiX2RUQKkRL7IiIiIiIiIiIC+csTqRSPiIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRosS+iIiIiIiIiIiIiEgRYlvYAYiICDw1cgPFSjgUdhgiUsSlRLUq7BBERERERETkEdAd+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yIiIiIiIiIiIiIiRYgS+yJ/IUFBQYSHhz/ycbt27Urr1q0f+bi5MZlMrFy5srDDEBEREREREREReSBK7IvIH27GjBnExsY+8nEjIyOpU6dOjr+npaXRsmXLAh3LbDYzffr0Au1TRERERERERETkXmwLOwARKdqysrIwmUwUK5b7dUJXV9dHGNH9eXh4FHYIIiIiIiIiIiIiD0x37IsUgqCgIPr168egQYNwc3PDw8ODyMhIAFJSUjCZTBw8eNBof+HCBUwmE1u2bAFgy5YtmEwmNmzYQEBAAPb29jRr1oz09HTWrVuHv78/Li4udOrUiStXrliMfePGDcLCwnB1daVMmTKMGDGCW7duGduvXbtGREQEXl5eODo60qhRI2NcgNjYWEqVKsWqVauoXr06JUqUIDU1Nc/jvbsUT17Hn81kMvHhhx/SsmVL7O3tqVKlCl988YVFm8GDB+Pr64uDgwNVqlRhxIgRZGZmGnGOGjWKxMRETCYTJpPJeGrg7lI8Z86cISQkhFKlSuHm5sZrr71GSkpKjvinTJmCp6cnpUuXpm/fvsZYQUFBnD59mvfee88YS0RERERERERE5I+ixL5IIYmLi8PR0ZHdu3czadIkRo8ezaZNm/LVR2RkJLNnz2bHjh1Gcnr69OksXryYNWvWsHHjRmbNmpVjXFtbW/bs2cOMGTOYOnUq8+bNM7aHhYWxc+dOli5dyqFDh2jXrh0tWrTgxIkTRpsrV64wceJE5s2bx5EjRyhbtuwfcvwjRozgjTfeIDExkc6dO9OhQweOHj1qbHd2diY2NpYffviBGTNm8MknnzBt2jQA2rdvz8CBA6lRowZpaWmkpaXRvn37HHFkZmYSHByMs7Mz27ZtIyEhAScnJ1q0aMH169eNdps3byY5OZnNmzcTFxdHbGyscaFgxYoVVKhQgdGjRxtj5ebatWtcunTJ4iMiIiIiIiIiIpIfKsUjUkhq1arFyJEjAfDx8WH27NnEx8fj4+NjdR9jx46ladOmAHTv3p2hQ4eSnJxMlSpVAGjbti2bN29m8ODBxj7e3t5MmzYNk8mEn58fhw8fZtq0afTs2ZPU1FRiYmJITU2lfPnyAERERLB+/XpiYmIYP348cDsZPnfuXGrXrl3gx//CCy8Ybdq1a0ePHj0AGDNmDJs2bWLWrFnMnTsXgOHDhxttzWYzERERLF26lEGDBmFvb4+TkxO2trZ5lt75/PPPuXnzJvPmzTPutI+JiaFUqVJs2bKF/9fenUdVXe3/H38dhsMgkwOTJmLiPONIqWWa6KWS8t7ML0uzKEtlOZbValAarlxNb+EtS7tmdVXUSm/XHDIHzJxRjNRIDcMSIjVEHBH2748Wn58nHBM9As/HWmctPp/9Pnu/z1nsw2e9z2Z/evXqJUmqXr26/vWvf8nV1VVNmjRRTEyMVq1apccff1w1atSQq6urfH19L7vNz8SJE5WYmPgn3jEAAAAAAADgdxT2ASdp1aqVw3FoaKjy8vL+dB/BwcHWljTnn9uyZYvDczp37uywVUxUVJSmTJmi4uJiZWRkqLi4WI0aNXJ4zpkzZ1SzZk3r2G63l8n/al3J64+KiipzfP4WRfPnz1dycrL279+vwsJCnTt3Tn5+fleVx86dO7Vv3z75+vo6nD99+rT2799vHTdv3lyurq4O+WZkZFzVWJL03HPPacyYMdZxQUGB6tate9X9AAAAAAAAoOqisA84ibu7u8OxzWZTSUmJdRPa8/e9L93L/VJ92Gy2i/Z5pQoLC+Xq6qq0tDSHIrYk+fj4WD97eXld8z7y15rrxo0bFRcXp8TEREVHR8vf318pKSmaMmXKVeVRWFiodu3aac6cOWXaAgMDyy3fUh4eHvLw8Ljq5wEAAAAAAAClKOwDN5nSYnJOTo7atm0rSQ6r1K/V5s2bHY43bdqkhg0bytXVVW3btlVxcbHy8vLUtWvXchvzz9q0aZMGDRrkcFz6nmzYsEH16tXT888/b7X/+OOPDs+32+0qLi6+5BiRkZGaP3++goKCrnq1/9WOBQAAAAAAAJQHbp4L3GS8vLzUuXNnJSUlac+ePUpNTXXYS/5aZWdna8yYMcrMzNS8efM0bdo0jRw5UpLUqFEjxcXFadCgQfr000+VlZWlLVu2aOLEifr888/LLYcrtXDhQs2aNUvff/+9xo8fry1btighIUHS7/vyZ2dnKyUlRfv371dycrIWLVrk8Pzw8HBlZWUpPT1dhw8f1pkzZ8qMERcXp1q1aqlv37766quvlJWVpbVr12rEiBH66aefrjjX8PBwrVu3Tj///LMOHz58bS8cAAAAAAAAuAQK+8BNaNasWTp37pzatWunUaNG6dVXXy23vgcNGqRTp06pY8eOGj58uEaOHKkhQ4ZY7e+//74GDRqksWPHqnHjxoqNjdXWrVsVFhZWbjlcqcTERKWkpKhVq1b68MMPNW/ePDVr1kySdN9992n06NFKSEhQmzZttGHDBr344osOz+/Xr5969+6t7t27KzAwUPPmzSszhre3t9atW6ewsDA98MADatq0qeLj43X69OmrWsH/8ssv68CBA2rQoIHDFj4AAAAAAABAebOZ8zfyBoCbhM1m06JFixQbG+vsVK6rgoIC+fv7q+6oBXLx8HZ2OgAquANJMc5OAQAAAADwJ5XWiY4dO3bZBaes2AcAAAAAAAAAoAKhsA/gmvn4+Fz08dVXXzk7PQAAAAAAAKBScXN2AgAqvvT09Iu21alT50/1WdV2Cfs2Mfqq9vQHAAAAAABA1UVhH8A1i4iIcHYKAAAAAAAAQJXBVjwAAAAAAAAAAFQgFPYBAAAAAAAAAKhAKOwDAAAAAAAAAFCBUNgHAAAAAAAAAKACobAPAAAAAAAAAEAFQmEfAAAAAAAAAIAKhMI+AAAAAAAAAAAVCIV9AAAAAAAAAAAqEAr7AAAAAAAAAABUIBT2AQAAAAAAAACoQCjsAwAAAAAAAABQgbg5OwEAAAAAAAAAuJGKi4tVVFTk7DRQxbi7u8vV1bVc+qKwDwAAAAAAAKBKMMYoNzdX+fn5zk4FVVRAQIBCQkJks9muqR8K+wAAAAAAAACqhNKiflBQkLy9va+5uApcKWOMTp48qby8PElSaGjoNfVHYR8AAAAAAABApVdcXGwV9WvWrOnsdFAFeXl5SZLy8vIUFBR0TdvycPNcAAAAAAAAAJVe6Z763t7eTs4EVVnp79+13uOBwj4AAAAAAACAKoPtd+BM5fX7x1Y8AHATaDF+hVw8WDEAoKwDSTHOTgEAAAAAcJNhxT4AAAAAAAAA4KJsNpsWL17s7DRwHlbsAwAAAAAAAKjSwp/9/IaNVRH/KzcnJ0fVq1d3dhoXNWHCBC1evFjp6enOTuWGYcU+gArjzjvv1KhRo27IWGvXrpXNZlN+fr4kafbs2QoICLghYwMAAAAAANxMQkJC5OHh4ew0yjDG6Ny5c85Owyko7AOoMD799FO98sorThm7f//++v77750yNgAAAAAAqNqWL1+uLl26KCAgQDVr1tQ999yj/fv3S5Juu+02PfPMMw7xv/76q9zd3bVu3TpJv6+4j4mJkZeXl+rXr6+5c+cqPDxcb7zxxhWNf/5WPAcOHJDNZtOCBQvUtWtXeXl5qUOHDvr++++1detWtW/fXj4+PurTp49+/fVXq4/BgwcrNjZWiYmJCgwMlJ+fn5588kmdPXvWijlz5oxGjBihoKAgeXp6qkuXLtq6davVXroQc9myZWrXrp08PDz0n//8R4mJidq5c6dsNptsNptmz54tSZo6dapatmypatWqqW7duho2bJgKCwut/koXcq5YsUJNmzaVj4+PevfurZycHIfXP2vWLDVv3lweHh4KDQ1VQkKC1Zafn6/HHnvMek133XWXdu7ceUXv67WgsA+gwqhRo4Z8fX2dMraXl5eCgoKcMjYAAAAAAKjaTpw4oTFjxmjbtm1atWqVXFxcdP/996ukpERxcXFKSUmRMcaKnz9/vmrXrq2uXbtKkgYNGqRDhw5p7dq1+uSTTzRjxgzl5eVdU07jx4/XCy+8oO3bt8vNzU3/93//p3HjxunNN9/UV199pX379umll15yeM6qVau0Z88erV27VvPmzdOnn36qxMREq33cuHH65JNP9MEHH2j79u2KiIhQdHS0jh496tDPs88+q6SkJO3Zs0d33323xo4dq+bNmysnJ0c5OTnq37+/JMnFxUXJycnatWuXPvjgA61evVrjxo1z6OvkyZN6/fXX9dFHH2ndunXKzs7WU089ZbVPnz5dw4cP15AhQ5SRkaHPPvtMERERVvvf/vY35eXladmyZUpLS1NkZKR69OhRJufyRmEfQIVx/lY84eHh+vvf/65HH31Uvr6+CgsL04wZM6zYs2fPKiEhQaGhofL09FS9evU0ceJESf//m+Xz913Lz8+XzWbT2rVrLzj2H7fimTBhgtq0aaOPPvpI4eHh8vf310MPPaTjx4+X98sGAAAAAABVXL9+/fTAAw8oIiJCbdq00axZs5SRkaHdu3frwQcf1KFDh7R+/Xorfu7cuRowYIBsNpu+++47ffnll5o5c6Y6deqkyMhIvffeezp16tQ15fTUU08pOjpaTZs21ciRI5WWlqYXX3xRt99+u9q2bav4+HitWbPG4Tl2u91a/R4TE6OXX35ZycnJKikp0YkTJzR9+nRNnjxZffr0UbNmzTRz5kx5eXnp3//+t0M/L7/8su6++241aNBAderUkY+Pj9zc3BQSEqKQkBB5eXlJkkaNGqXu3bsrPDxcd911l1599VUtWLDAoa+ioiK98847at++vSIjI5WQkKBVq1ZZ7a+++qrGjh2rkSNHqlGjRurQoYNVn1q/fr22bNmihQsXqn379mrYsKFef/11BQQE6OOPP76m9/dyKOwDqLCmTJmi9u3ba8eOHRo2bJiGDh2qzMxMSVJycrI+++wzLViwQJmZmZozZ47Cw8PLdfz9+/dr8eLFWrJkiZYsWaLU1FQlJSWV6xgAAAAAAAB79+7VgAEDdOutt8rPz8+qcWRnZyswMFC9evXSnDlzJElZWVnauHGj4uLiJEmZmZlyc3NTZGSk1V9ERMQ13wy3VatW1s/BwcGSpJYtWzqc++N/BbRu3Vre3t7WcVRUlAoLC3Xw4EHt379fRUVFuv322612d3d3dezYUXv27HHop3379leU45dffqkePXqoTp068vX11cCBA3XkyBGdPHnSivH29laDBg2s49DQUCvvvLw8HTp0SD169Lhg/zt37lRhYaFq1qwpHx8f65GVlWVtlXS9uF3X3gHgOvrLX/6iYcOGSZKeeeYZ/fOf/9SaNWvUuHFjZWdnq2HDhurSpYtsNpvq1atX7uOXlJRo9uzZ1vZAAwcO1KpVq/Taa69d9DlnzpzRmTNnrOOCgoJyzwsAAAAAAFQu9957r+rVq6eZM2eqdu3aKikpUYsWLaz96ePi4jRixAhNmzZNc+fOVcuWLR2K7NeDu7u79bPNZrvguZKSkusydrVq1S4bc+DAAd1zzz0aOnSoXnvtNdWoUUPr169XfHy8zp49a33BcH7OpXmXbmtUuvL/YgoLCxUaGnrBHSDO3/nhemDFPoAK6/xvhm02m0JCQqxvVAcPHqz09HQ1btxYI0aM0BdffFHu44eHhzvs+X/+N7oXM3HiRPn7+1uPunXrlnteAAAAAACg8jhy5IgyMzP1wgsvqEePHmratKl+++03h5i+ffvq9OnTWr58uebOnWut1pekxo0b69y5c9qxY4d1bt++fWX6uBF27tzpsAXQpk2b5OPjo7p166pBgway2+36+uuvrfaioiJt3bpVzZo1u2S/drtdxcXFDufS0tJUUlKiKVOmqHPnzmrUqJEOHTp0Vfn6+voqPDzcYWue80VGRio3N1dubm6KiIhweNSqVeuqxrpaFPYBVFgX+ka19JvgyMhIZWVl6ZVXXtGpU6f04IMP6q9//auk32+cIsnhpjJFRUXlOv7FPPfcczp27Jj1OHjw4FWPCwAAAAAAqo7q1aurZs2amjFjhvbt26fVq1drzJgxDjHVqlVTbGysXnzxRe3Zs0cDBgyw2po0aaKePXtqyJAh2rJli3bs2KEhQ4bIy8vLWml/o5w9e1bx8fHavXu3li5dqvHjxyshIUEuLi6qVq2ahg4dqqefflrLly/X7t279fjjj+vkyZOKj4+/ZL/h4eHKyspSenq6Dh8+rDNnzigiIkJFRUWaNm2afvjhB3300Ud65513rjrnCRMmaMqUKUpOTtbevXu1fft2TZs2TZLUs2dPRUVFKTY2Vl988YUOHDigDRs26Pnnn9e2bdv+1Ht0pSjsA6i0/Pz81L9/f82cOVPz58/XJ598oqNHjyowMFCSlJOTY8WefyPd68nDw0N+fn4ODwAAAAAAgItxcXFRSkqK0tLS1KJFC40ePVqTJ08uExcXF6edO3eqa9euCgsLc2j78MMPFRwcrG7duun+++/X448/Ll9fX3l6et6olyFJ6tGjhxo2bKhu3bqpf//+uu+++zRhwgSrPSkpSf369dPAgQMVGRmpffv2acWKFZe9H0C/fv3Uu3dvde/eXYGBgZo3b55at26tqVOn6h//+IdatGihOXPmaOLEiVed88MPP6w33nhDb7/9tpo3b6577rlHe/fulfT7Is+lS5eqW7dueuSRR9SoUSM99NBD+vHHH637Dlwv7LEPoFKaOnWqQkND1bZtW7m4uGjhwoUKCQlRQECAXFxc1LlzZyUlJal+/frKy8vTCy+84OyUAQAAAACAkxxIinF2CpfUs2dP7d692+Hc+TsRSFKfPn3KnCsVGhqqpUuXWsc//fST8vLyFBERcUXjn99veHh4mXHuvPPOMucGDx6swYMHl+krMTFRiYmJFxzH09NTycnJSk5OvmD7hcaRfl9I+fHHH5c5P3r0aI0ePdrh3MCBAy+ZY2xsbJkxnnjiCT3xxBMXzMnX1/eSOV8vFPYBVEq+vr6aNGmS9u7dK1dXV3Xo0EFLly61tuGZNWuW4uPj1a5dOzVu3FiTJk1Sr169nJw1AAAAAABA+Vu9erUKCwvVsmVL5eTkaNy4cQoPD1e3bt2cnRr+JJu52Nc4AIDrrqCg4Peb6I5aIBcPb2enA+AmdLOvHAIAAAAqitOnTysrK0v169e/4VvQONuKFSs0duxY/fDDD/L19dVtt92mN954Q/Xq1dOcOXMuuhq9Xr162rVrV7nkMHjwYOXn52vx4sXl0l9Fdanfw9I60bFjxy67fTMr9gEAAAAAAACgEouOjlZ0dPQF2+677z516tTpgm3u7u7llsPs2bPLrS9Q2AcAAAAAAACAKsvX11e+vr7OTgNXycXZCQAAAAAAAAAAgCvHin0AuAl8mxh92b3TAAAAAADAtSspKXF2CqjCyuv3j8I+AAAAAAAAgErPbrfLxcVFhw4dUmBgoOx2u2w2m7PTQhVhjNHZs2f166+/ysXFRXa7/Zr6o7APAAAAAAAAoNJzcXFR/fr1lZOTo0OHDjk7HVRR3t7eCgsLk4vLte2ST2EfAAAAAAAAQJVgt9sVFhamc+fOqbi42NnpoIpxdXWVm5tbufynCIV9AAAAAAAAAFWGzWaTu7u73N3dnZ0K8Kdd23p/AAAAAAAAAABwQ1HYBwAAAAAAAACgAqGwDwAAAAAAAABABcIe+wDgRMYYSVJBQYGTMwEAAAAAAIAzldaHSutFl0JhHwCc6MiRI5KkunXrOjkTAAAAAAAA3AyOHz8uf3//S8ZQ2AcAJ6pRo4YkKTs7+7If2AAqnoKCAtWtW1cHDx6Un5+fs9MBUM6Y40DlxzwHKjfmOG42xhgdP35ctWvXvmwshX0AcCIXl99vdeLv789FBFCJ+fn5MceBSow5DlR+zHOgcmOO42ZypQs/uXkuAAAAAAAAAAAVCIV9AAAAAAAAAAAqEAr7AOBEHh4eGj9+vDw8PJydCoDrgDkOVG7McaDyY54DlRtzHBWZzRhjnJ0EAAAAAAAAAAC4MqzYBwAAAAAAAACgAqGwDwAAAAAAAABABUJhHwAAAAAAAACACoTCPgAAAAAAAAAAFQiFfQBwkrfeekvh4eHy9PRUp06dtGXLFmenBEDSunXrdO+996p27dqy2WxavHixQ7sxRi+99JJCQ0Pl5eWlnj17au/evQ4xR48eVVxcnPz8/BQQEKD4+HgVFhY6xHzzzTfq2rWrPD09VbduXU2aNKlMLgsXLlSTJk3k6empli1baunSpeX+eoGqZOLEierQoYN8fX0VFBSk2NhYZWZmOsScPn1aw4cPV82aNeXj46N+/frpl19+cYjJzs5WTEyMvL29FRQUpKefflrnzp1ziFm7dq0iIyPl4eGhiIgIzZ49u0w+XAsA5W/69Olq1aqV/Pz85Ofnp6ioKC1btsxqZ44DlUtSUpJsNptGjRplnWOeo6qgsA8ATjB//nyNGTNG48eP1/bt29W6dWtFR0crLy/P2akBVd6JEyfUunVrvfXWWxdsnzRpkpKTk/XOO+9o8+bNqlatmqKjo3X69GkrJi4uTrt27dLKlSu1ZMkSrVu3TkOGDLHaCwoK1KtXL9WrV09paWmaPHmyJkyYoBkzZlgxGzZs0IABAxQfH68dO3YoNjZWsbGx+vbbb6/fiwcqudTUVA0fPlybNm3SypUrVVRUpF69eunEiRNWzOjRo/W///1PCxcuVGpqqg4dOqQHHnjAai8uLlZMTIzOnj2rDRs26IMPPtDs2bP10ksvWTFZWVmKiYlR9+7dlZ6erlGjRumxxx7TihUrrBiuBYDr45ZbblFSUpLS0tK0bds23XXXXerbt6927doliTkOVCZbt27Vu+++q1atWjmcZ56jyjAAgBuuY8eOZvjw4dZxcXGxqV27tpk4caITswLwR5LMokWLrOOSkhITEhJiJk+ebJ3Lz883Hh4eZt68ecYYY3bv3m0kma1bt1oxy5YtMzabzfz888/GGGPefvttU716dXPmzBkr5plnnjGNGze2jh988EETExPjkE+nTp3ME088Ua6vEajK8vLyjCSTmppqjPl9Pru7u5uFCxdaMXv27DGSzMaNG40xxixdutS4uLiY3NxcK2b69OnGz8/PmtPjxo0zzZs3dxirf//+Jjo62jrmWgC4capXr27ee+895jhQiRw/ftw0bNjQrFy50txxxx1m5MiRxhj+lqNqYcU+ANxgZ8+eVVpamnr27Gmdc3FxUc+ePbVx40YnZgbgcrKyspSbm+swf/39/dWpUydr/m7cuFEBAQFq3769FdOzZ0+5uLho8+bNVky3bt1kt9utmOjoaGVmZuq3336zYs4fpzSGzwmg/Bw7dkySVKNGDUlSWlqaioqKHOZekyZNFBYW5jDHW7ZsqeDgYCsmOjpaBQUF1orgy81frgWAG6O4uFgpKSk6ceKEoqKimONAJTJ8+HDFxMSUmYvMc1Qlbs5OAACqmsOHD6u4uNjhIkKSgoOD9d133zkpKwBXIjc3V5IuOH9L23JzcxUUFOTQ7ubmpho1ajjE1K9fv0wfpW3Vq1dXbm7uJccBcG1KSko0atQo3X777WrRooWk3+ef3W5XQECAQ+wf5/iF5mZp26ViCgoKdOrUKf32229cCwDXUUZGhqKionT69Gn5+Pho0aJFatasmdLT05njQCWQkpKi7du3a+vWrWXa+FuOqoTCPgAAAIAqZ/jw4fr222+1fv16Z6cCoJw1btxY6enpOnbsmD7++GM9/PDDSk1NdXZaAMrBwYMHNXLkSK1cuVKenp7OTgdwKrbiAYAbrFatWnJ1ddUvv/zicP6XX35RSEiIk7ICcCVK5+il5m9ISEiZG2adO3dOR48edYi5UB/nj3GxGD4ngGuXkJCgJUuWaM2aNbrlllus8yEhITp79qzy8/Md4v84x//s/PXz85OXlxfXAsB1ZrfbFRERoXbt2mnixIlq3bq13nzzTeY4UAmkpaUpLy9PkZGRcnNzk5ubm1JTU5WcnCw3NzcFBwczz1FlUNgHgBvMbrerXbt2WrVqlXWupKREq1atUlRUlBMzA3A59evXV0hIiMP8LSgo0ObNm635GxUVpfz8fKWlpVkxq1evVklJiTp16mTFrFu3TkVFRVbMypUr1bhxY1WvXt2KOX+c0hg+J4A/zxijhIQELVq0SKtXry6zJVa7du3k7u7uMPcyMzOVnZ3tMMczMjIcvsBbuXKl/Pz81KxZMyvmUvOXawHgxiopKdGZM2eY40Al0KNHD2VkZCg9Pd16tG/fXnFxcdbPzHNUGc6+ey8AVEUpKSnGw8PDzJ492+zevdsMGTLEBAQEmNzcXGenBlR5x48fNzt27DA7duwwkszUqVPNjh07zI8//miMMSYpKckEBASY//73v+abb74xffv2NfXr1zenTp2y+ujdu7dp27at2bx5s1m/fr1p2LChGTBggNWen59vgoODzcCBA823335rUlJSjLe3t3n33XetmK+//tq4ubmZ119/3ezZs8eMHz/euLu7m4yMjBv3ZgCVzNChQ42/v79Zu3atycnJsR4nT560Yp588kkTFhZmVq9ebbZt22aioqJMVFSU1X7u3DnTokUL06tXL5Oenm6WL19uAgMDzXPPPWfF/PDDD8bb29s8/fTTZs+ePeatt94yrq6uZvny5VYM1wLA9fHss8+a1NRUk5WVZb755hvz7LPPGpvNZr744gtjDHMcqIzuuOMOM3LkSOuYeY6qgsI+ADjJtGnTTFhYmLHb7aZjx45m06ZNzk4JgDFmzZo1RlKZx8MPP2yMMaakpMS8+OKLJjg42Hh4eJgePXqYzMxMhz6OHDliBgwYYHx8fIyfn5955JFHzPHjxx1idu7cabp06WI8PDxMnTp1TFJSUplcFixYYBo1amTsdrtp3ry5+fzzz6/b6waqggvNbUnm/ffft2JOnTplhg0bZqpXr268vb3N/fffb3Jychz6OXDggOnTp4/x8vIytWrVMmPHjjVFRUUOMWvWrDFt2rQxdrvd3HrrrQ5jlOJaACh/jz76qKlXr56x2+0mMDDQ9OjRwyrqG8McByqjPxb2meeoKmzGGOOc/xUAAAAAAAAAAABXiz32AQAAAAAAAACoQCjsAwAAAAAAAABQgVDYBwAAAAAAAACgAqGwDwAAAAAAAABABUJhHwAAAAAAAACACoTCPgAAAAAAAAAAFQiFfQAAAAAAAAAAKhAK+wAAAAAAAAAAVCAU9gEAAAAAAAAAqEAo7AMAAAAAAAAAUIFQ2AcAAAAAAAAAoAKhsA8AAAAAAAAAQAXy/wA9zc3Rl2I2vwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp_plot = feat_imp.sort_values(by=\"avg_importance\").plot(\n",
    "    kind=\"barh\",\n",
    "    x=\"feature\",\n",
    "    y=\"avg_importance\",\n",
    "    figsize=(15, 12),\n",
    "    title=\"Average feature importance across five folds\",\n",
    ")\n",
    "feat_imp_plot.figure.savefig(\n",
    "    \"../outputs/plots/feature_importance.pdf\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Data\n",
    "\n",
    "Take the average of each model's predictions (cross-validation averaging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20354, 49), (20354,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X, test_y = (\n",
    "    pd.read_parquet(data_path + \"test_X.parquet\"),\n",
    "    pd.read_parquet(data_path + \"test_y.parquet\")\n",
    "    .to_numpy()\n",
    "    .reshape(\n",
    "        -1,\n",
    "    ),\n",
    ")\n",
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = joblib.load(\"../outputs/pipeline/label_encoder.joblib\").fit_transform(test_y)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(shape=(test_X.shape[0], 3))\n",
    "for i in range(5):\n",
    "    # Initialize the model\n",
    "    model = xgb.Booster()\n",
    "    # Load the model\n",
    "    model.load_model(model_path + f\"model_fold_{i + 1}.xgb\")\n",
    "    # Process test set\n",
    "    fold_test_X = joblib.load(\n",
    "        f\"../outputs/pipeline/preprocessor_fold_{i + 1}.joblib\"\n",
    "    ).transform(test_X)\n",
    "    fold_test_X = joblib.load(\n",
    "        f\"../outputs/pipeline/feature_selector_fold_{i + 1}.joblib\"\n",
    "    ).transform(fold_test_X)\n",
    "    # Make predictions on the test set and sum the matrices of probabilities with shape (n_samples, n_classes) element-wise\n",
    "    pred += model.predict(xgb.DMatrix(data=fold_test_X))\n",
    "# Average the predictions\n",
    "pred /= 5\n",
    "pred = pred.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2fb7cf4e50>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(\n",
    "        y_true=test_y,\n",
    "        y_pred=np.argmax(pred, axis=1),\n",
    "        labels=[0, 1, 2],\n",
    "        normalize=\"true\",\n",
    "    )\n",
    ").plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556858181946161"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_true=test_y, y_pred=pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the performance of the model in terms of correctly classifying the within-30 group is still suboptimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.36      0.18      0.96      0.24      0.41      0.16      2272\n",
      "          1       0.60      0.29      0.90      0.39      0.51      0.24      7109\n",
      "          2       0.64      0.92      0.39      0.75      0.60      0.37     10973\n",
      "\n",
      "avg / total       0.59      0.62      0.63      0.57      0.55      0.30     20354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_true=test_y, y_pred=np.argmax(pred, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40fc6ebffc74793621f684cf09d9f3d0a501c91440a6f462aebac8d38ed47133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
